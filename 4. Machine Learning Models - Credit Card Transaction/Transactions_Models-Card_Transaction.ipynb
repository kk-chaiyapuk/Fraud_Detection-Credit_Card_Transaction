{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "start_time = datetime.now()\n",
    "\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "import gc\n",
    "import lightgbm as lgb\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(96397, 27)\n",
      "CPU times: total: 250 ms\n",
      "Wall time: 247 ms\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>card_Merch_num_state_total_14</th>\n",
       "      <th>card_Merchnum_max_30</th>\n",
       "      <th>card_Merch_des_zip_total_1</th>\n",
       "      <th>Merch_description_total_0</th>\n",
       "      <th>card_Merch_state_zip_total_14</th>\n",
       "      <th>card_Merch_des_state_max_30</th>\n",
       "      <th>card_Merch_des_zip_max_30</th>\n",
       "      <th>card_Merch_des_state_zip_max_30</th>\n",
       "      <th>card_Merch_num_des_zip_total_0</th>\n",
       "      <th>card_Merch_des_state_zip_total_30</th>\n",
       "      <th>...</th>\n",
       "      <th>Merch_state_zip_variability_avg_14</th>\n",
       "      <th>card_Merch_num_des_total_0</th>\n",
       "      <th>card_Merch_des_state_total_30</th>\n",
       "      <th>card_Merch_des_state_total_0</th>\n",
       "      <th>card_Merch_description_total_0</th>\n",
       "      <th>card_Merch_zip_total_0</th>\n",
       "      <th>card_Merch_num_des_zip_total_14</th>\n",
       "      <th>card_Merch_description_total_30</th>\n",
       "      <th>Recnum</th>\n",
       "      <th>Fraud</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.62</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.62</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.62</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>31.42</td>\n",
       "      <td>31.42</td>\n",
       "      <td>31.42</td>\n",
       "      <td>31.42</td>\n",
       "      <td>31.42</td>\n",
       "      <td>31.42</td>\n",
       "      <td>31.42</td>\n",
       "      <td>31.42</td>\n",
       "      <td>31.42</td>\n",
       "      <td>31.42</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>31.42</td>\n",
       "      <td>31.42</td>\n",
       "      <td>31.42</td>\n",
       "      <td>31.42</td>\n",
       "      <td>31.42</td>\n",
       "      <td>31.42</td>\n",
       "      <td>31.42</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>178.49</td>\n",
       "      <td>178.49</td>\n",
       "      <td>178.49</td>\n",
       "      <td>178.49</td>\n",
       "      <td>178.49</td>\n",
       "      <td>178.49</td>\n",
       "      <td>178.49</td>\n",
       "      <td>178.49</td>\n",
       "      <td>178.49</td>\n",
       "      <td>178.49</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>178.49</td>\n",
       "      <td>178.49</td>\n",
       "      <td>178.49</td>\n",
       "      <td>178.49</td>\n",
       "      <td>178.49</td>\n",
       "      <td>178.49</td>\n",
       "      <td>178.49</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.62</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.62</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.62</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.24</td>\n",
       "      <td>3.62</td>\n",
       "      <td>7.24</td>\n",
       "      <td>7.24</td>\n",
       "      <td>7.24</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.62</td>\n",
       "      <td>7.24</td>\n",
       "      <td>7.24</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.24</td>\n",
       "      <td>7.24</td>\n",
       "      <td>7.24</td>\n",
       "      <td>7.24</td>\n",
       "      <td>7.24</td>\n",
       "      <td>7.24</td>\n",
       "      <td>7.24</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   card_Merch_num_state_total_14  card_Merchnum_max_30  \\\n",
       "0                           3.62                  3.62   \n",
       "1                          31.42                 31.42   \n",
       "2                         178.49                178.49   \n",
       "3                           3.62                  3.62   \n",
       "4                           7.24                  3.62   \n",
       "\n",
       "   card_Merch_des_zip_total_1  Merch_description_total_0  \\\n",
       "0                        3.62                       3.62   \n",
       "1                       31.42                      31.42   \n",
       "2                      178.49                     178.49   \n",
       "3                        3.62                       3.62   \n",
       "4                        7.24                       7.24   \n",
       "\n",
       "   card_Merch_state_zip_total_14  card_Merch_des_state_max_30  \\\n",
       "0                           3.62                         3.62   \n",
       "1                          31.42                        31.42   \n",
       "2                         178.49                       178.49   \n",
       "3                           3.62                         3.62   \n",
       "4                           7.24                         3.62   \n",
       "\n",
       "   card_Merch_des_zip_max_30  card_Merch_des_state_zip_max_30  \\\n",
       "0                       3.62                             3.62   \n",
       "1                      31.42                            31.42   \n",
       "2                     178.49                           178.49   \n",
       "3                       3.62                             3.62   \n",
       "4                       3.62                             3.62   \n",
       "\n",
       "   card_Merch_num_des_zip_total_0  card_Merch_des_state_zip_total_30  ...  \\\n",
       "0                            3.62                               3.62  ...   \n",
       "1                           31.42                              31.42  ...   \n",
       "2                          178.49                             178.49  ...   \n",
       "3                            3.62                               3.62  ...   \n",
       "4                            7.24                               7.24  ...   \n",
       "\n",
       "   Merch_state_zip_variability_avg_14  card_Merch_num_des_total_0  \\\n",
       "0                                 0.0                        3.62   \n",
       "1                                 0.0                       31.42   \n",
       "2                                 0.0                      178.49   \n",
       "3                                 0.0                        3.62   \n",
       "4                                 0.0                        7.24   \n",
       "\n",
       "   card_Merch_des_state_total_30  card_Merch_des_state_total_0  \\\n",
       "0                           3.62                          3.62   \n",
       "1                          31.42                         31.42   \n",
       "2                         178.49                        178.49   \n",
       "3                           3.62                          3.62   \n",
       "4                           7.24                          7.24   \n",
       "\n",
       "   card_Merch_description_total_0  card_Merch_zip_total_0  \\\n",
       "0                            3.62                    3.62   \n",
       "1                           31.42                   31.42   \n",
       "2                          178.49                  178.49   \n",
       "3                            3.62                    3.62   \n",
       "4                            7.24                    7.24   \n",
       "\n",
       "   card_Merch_num_des_zip_total_14  card_Merch_description_total_30  Recnum  \\\n",
       "0                             3.62                             3.62       1   \n",
       "1                            31.42                            31.42       2   \n",
       "2                           178.49                           178.49       3   \n",
       "3                             3.62                             3.62       4   \n",
       "4                             7.24                             7.24       5   \n",
       "\n",
       "   Fraud  \n",
       "0      0  \n",
       "1      0  \n",
       "2      0  \n",
       "3      0  \n",
       "4      0  \n",
       "\n",
       "[5 rows x 27 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "vars_all = pd.read_csv('2_df_final_with_Y.csv').sort_values(\"Recnum\").reset_index(drop=True)\n",
    "vars_all.rename(columns={'Recnum':'Recnum'},inplace=True)\n",
    "vars_all.rename(columns={'Fraud':'Fraud'},inplace=True)\n",
    "\n",
    "print(vars_all.shape)\n",
    "vars_all.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>card_Merch_num_state_total_14</th>\n",
       "      <th>card_Merchnum_max_30</th>\n",
       "      <th>card_Merch_des_zip_total_1</th>\n",
       "      <th>Merch_description_total_0</th>\n",
       "      <th>card_Merch_state_zip_total_14</th>\n",
       "      <th>card_Merch_des_state_max_30</th>\n",
       "      <th>card_Merch_des_zip_max_30</th>\n",
       "      <th>card_Merch_des_state_zip_max_30</th>\n",
       "      <th>card_Merch_num_des_zip_total_0</th>\n",
       "      <th>card_Merch_des_state_zip_total_30</th>\n",
       "      <th>...</th>\n",
       "      <th>Merch_state_zip_variability_avg_14</th>\n",
       "      <th>card_Merch_num_des_total_0</th>\n",
       "      <th>card_Merch_des_state_total_30</th>\n",
       "      <th>card_Merch_des_state_total_0</th>\n",
       "      <th>card_Merch_description_total_0</th>\n",
       "      <th>card_Merch_zip_total_0</th>\n",
       "      <th>card_Merch_num_des_zip_total_14</th>\n",
       "      <th>card_Merch_description_total_30</th>\n",
       "      <th>Recnum</th>\n",
       "      <th>Fraud</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>96397.000000</td>\n",
       "      <td>96397.000000</td>\n",
       "      <td>96397.000000</td>\n",
       "      <td>96397.000000</td>\n",
       "      <td>96397.000000</td>\n",
       "      <td>96397.000000</td>\n",
       "      <td>96397.000000</td>\n",
       "      <td>96397.000000</td>\n",
       "      <td>96397.000000</td>\n",
       "      <td>96397.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>96397.000000</td>\n",
       "      <td>96397.000000</td>\n",
       "      <td>96397.000000</td>\n",
       "      <td>96397.000000</td>\n",
       "      <td>96397.000000</td>\n",
       "      <td>96397.000000</td>\n",
       "      <td>96397.000000</td>\n",
       "      <td>96397.000000</td>\n",
       "      <td>96397.000000</td>\n",
       "      <td>96397.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>770.509236</td>\n",
       "      <td>517.704051</td>\n",
       "      <td>593.666588</td>\n",
       "      <td>761.885095</td>\n",
       "      <td>803.336711</td>\n",
       "      <td>514.700728</td>\n",
       "      <td>513.497615</td>\n",
       "      <td>513.491474</td>\n",
       "      <td>523.805769</td>\n",
       "      <td>903.627845</td>\n",
       "      <td>...</td>\n",
       "      <td>1.295237</td>\n",
       "      <td>524.479094</td>\n",
       "      <td>908.052192</td>\n",
       "      <td>525.997554</td>\n",
       "      <td>526.063384</td>\n",
       "      <td>532.096813</td>\n",
       "      <td>744.714885</td>\n",
       "      <td>908.660094</td>\n",
       "      <td>48365.481820</td>\n",
       "      <td>0.010986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>4168.658888</td>\n",
       "      <td>1084.028924</td>\n",
       "      <td>4010.097366</td>\n",
       "      <td>2872.816671</td>\n",
       "      <td>4185.964751</td>\n",
       "      <td>1074.829349</td>\n",
       "      <td>1074.519504</td>\n",
       "      <td>1074.520672</td>\n",
       "      <td>2616.296248</td>\n",
       "      <td>4312.348251</td>\n",
       "      <td>...</td>\n",
       "      <td>604.842190</td>\n",
       "      <td>2617.062070</td>\n",
       "      <td>4314.504434</td>\n",
       "      <td>2618.472633</td>\n",
       "      <td>2618.498437</td>\n",
       "      <td>2623.366692</td>\n",
       "      <td>4157.162485</td>\n",
       "      <td>4314.584175</td>\n",
       "      <td>27945.003883</td>\n",
       "      <td>0.104236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>...</td>\n",
       "      <td>-47066.997391</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>77.090000</td>\n",
       "      <td>53.430000</td>\n",
       "      <td>45.900000</td>\n",
       "      <td>66.850000</td>\n",
       "      <td>84.450000</td>\n",
       "      <td>49.100000</td>\n",
       "      <td>48.850000</td>\n",
       "      <td>48.850000</td>\n",
       "      <td>43.350000</td>\n",
       "      <td>63.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>-11.629826</td>\n",
       "      <td>43.400000</td>\n",
       "      <td>64.400000</td>\n",
       "      <td>43.490000</td>\n",
       "      <td>43.490000</td>\n",
       "      <td>47.600000</td>\n",
       "      <td>55.100000</td>\n",
       "      <td>64.450000</td>\n",
       "      <td>24154.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>237.210000</td>\n",
       "      <td>201.050000</td>\n",
       "      <td>162.740000</td>\n",
       "      <td>225.000000</td>\n",
       "      <td>255.000000</td>\n",
       "      <td>200.550000</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>155.000000</td>\n",
       "      <td>246.750000</td>\n",
       "      <td>...</td>\n",
       "      <td>5.564353</td>\n",
       "      <td>155.000000</td>\n",
       "      <td>249.000000</td>\n",
       "      <td>155.570000</td>\n",
       "      <td>155.570000</td>\n",
       "      <td>161.250000</td>\n",
       "      <td>204.080000</td>\n",
       "      <td>249.000000</td>\n",
       "      <td>48365.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>678.000000</td>\n",
       "      <td>597.510000</td>\n",
       "      <td>509.320000</td>\n",
       "      <td>735.000000</td>\n",
       "      <td>713.010000</td>\n",
       "      <td>595.000000</td>\n",
       "      <td>593.230000</td>\n",
       "      <td>593.230000</td>\n",
       "      <td>490.860000</td>\n",
       "      <td>796.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>155.830222</td>\n",
       "      <td>491.850000</td>\n",
       "      <td>800.000000</td>\n",
       "      <td>493.010000</td>\n",
       "      <td>493.020000</td>\n",
       "      <td>496.000000</td>\n",
       "      <td>651.240000</td>\n",
       "      <td>801.660000</td>\n",
       "      <td>72578.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>306633.410000</td>\n",
       "      <td>47900.000000</td>\n",
       "      <td>306633.410000</td>\n",
       "      <td>217467.180000</td>\n",
       "      <td>306633.410000</td>\n",
       "      <td>47900.000000</td>\n",
       "      <td>47900.000000</td>\n",
       "      <td>47900.000000</td>\n",
       "      <td>217467.180000</td>\n",
       "      <td>306633.410000</td>\n",
       "      <td>...</td>\n",
       "      <td>12309.800000</td>\n",
       "      <td>217467.180000</td>\n",
       "      <td>306633.410000</td>\n",
       "      <td>217467.180000</td>\n",
       "      <td>217467.180000</td>\n",
       "      <td>217467.180000</td>\n",
       "      <td>306633.410000</td>\n",
       "      <td>306633.410000</td>\n",
       "      <td>96753.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       card_Merch_num_state_total_14  card_Merchnum_max_30  \\\n",
       "count                   96397.000000          96397.000000   \n",
       "mean                      770.509236            517.704051   \n",
       "std                      4168.658888           1084.028924   \n",
       "min                         0.010000              0.010000   \n",
       "25%                        77.090000             53.430000   \n",
       "50%                       237.210000            201.050000   \n",
       "75%                       678.000000            597.510000   \n",
       "max                    306633.410000          47900.000000   \n",
       "\n",
       "       card_Merch_des_zip_total_1  Merch_description_total_0  \\\n",
       "count                96397.000000               96397.000000   \n",
       "mean                   593.666588                 761.885095   \n",
       "std                   4010.097366                2872.816671   \n",
       "min                      0.010000                   0.010000   \n",
       "25%                     45.900000                  66.850000   \n",
       "50%                    162.740000                 225.000000   \n",
       "75%                    509.320000                 735.000000   \n",
       "max                 306633.410000              217467.180000   \n",
       "\n",
       "       card_Merch_state_zip_total_14  card_Merch_des_state_max_30  \\\n",
       "count                   96397.000000                 96397.000000   \n",
       "mean                      803.336711                   514.700728   \n",
       "std                      4185.964751                  1074.829349   \n",
       "min                         0.010000                     0.010000   \n",
       "25%                        84.450000                    49.100000   \n",
       "50%                       255.000000                   200.550000   \n",
       "75%                       713.010000                   595.000000   \n",
       "max                    306633.410000                 47900.000000   \n",
       "\n",
       "       card_Merch_des_zip_max_30  card_Merch_des_state_zip_max_30  \\\n",
       "count               96397.000000                     96397.000000   \n",
       "mean                  513.497615                       513.491474   \n",
       "std                  1074.519504                      1074.520672   \n",
       "min                     0.010000                         0.010000   \n",
       "25%                    48.850000                        48.850000   \n",
       "50%                   200.000000                       200.000000   \n",
       "75%                   593.230000                       593.230000   \n",
       "max                 47900.000000                     47900.000000   \n",
       "\n",
       "       card_Merch_num_des_zip_total_0  card_Merch_des_state_zip_total_30  ...  \\\n",
       "count                    96397.000000                       96397.000000  ...   \n",
       "mean                       523.805769                         903.627845  ...   \n",
       "std                       2616.296248                        4312.348251  ...   \n",
       "min                          0.010000                           0.010000  ...   \n",
       "25%                         43.350000                          63.500000  ...   \n",
       "50%                        155.000000                         246.750000  ...   \n",
       "75%                        490.860000                         796.000000  ...   \n",
       "max                     217467.180000                      306633.410000  ...   \n",
       "\n",
       "       Merch_state_zip_variability_avg_14  card_Merch_num_des_total_0  \\\n",
       "count                        96397.000000                96397.000000   \n",
       "mean                             1.295237                  524.479094   \n",
       "std                            604.842190                 2617.062070   \n",
       "min                         -47066.997391                    0.010000   \n",
       "25%                            -11.629826                   43.400000   \n",
       "50%                              5.564353                  155.000000   \n",
       "75%                            155.830222                  491.850000   \n",
       "max                          12309.800000               217467.180000   \n",
       "\n",
       "       card_Merch_des_state_total_30  card_Merch_des_state_total_0  \\\n",
       "count                   96397.000000                  96397.000000   \n",
       "mean                      908.052192                    525.997554   \n",
       "std                      4314.504434                   2618.472633   \n",
       "min                         0.010000                      0.010000   \n",
       "25%                        64.400000                     43.490000   \n",
       "50%                       249.000000                    155.570000   \n",
       "75%                       800.000000                    493.010000   \n",
       "max                    306633.410000                 217467.180000   \n",
       "\n",
       "       card_Merch_description_total_0  card_Merch_zip_total_0  \\\n",
       "count                    96397.000000            96397.000000   \n",
       "mean                       526.063384              532.096813   \n",
       "std                       2618.498437             2623.366692   \n",
       "min                          0.010000                0.010000   \n",
       "25%                         43.490000               47.600000   \n",
       "50%                        155.570000              161.250000   \n",
       "75%                        493.020000              496.000000   \n",
       "max                     217467.180000           217467.180000   \n",
       "\n",
       "       card_Merch_num_des_zip_total_14  card_Merch_description_total_30  \\\n",
       "count                     96397.000000                     96397.000000   \n",
       "mean                        744.714885                       908.660094   \n",
       "std                        4157.162485                      4314.584175   \n",
       "min                           0.010000                         0.010000   \n",
       "25%                          55.100000                        64.450000   \n",
       "50%                         204.080000                       249.000000   \n",
       "75%                         651.240000                       801.660000   \n",
       "max                      306633.410000                    306633.410000   \n",
       "\n",
       "             Recnum         Fraud  \n",
       "count  96397.000000  96397.000000  \n",
       "mean   48365.481820      0.010986  \n",
       "std    27945.003883      0.104236  \n",
       "min        1.000000      0.000000  \n",
       "25%    24154.000000      0.000000  \n",
       "50%    48365.000000      0.000000  \n",
       "75%    72578.000000      0.000000  \n",
       "max    96753.000000      1.000000  \n",
       "\n",
       "[8 rows x 27 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vars_all.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NVAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Recnum',\n",
       " 'Fraud',\n",
       " 'card_Merch_num_state_total_14',\n",
       " 'card_Merchnum_max_30',\n",
       " 'card_Merch_des_zip_total_1',\n",
       " 'Merch_description_total_0',\n",
       " 'card_Merch_state_zip_total_14',\n",
       " 'card_Merch_des_state_max_30',\n",
       " 'card_Merch_des_zip_max_30',\n",
       " 'card_Merch_des_state_zip_max_30',\n",
       " 'card_Merch_num_des_zip_total_0',\n",
       " 'card_Merch_des_state_zip_total_30']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# set the number of variables desired here, and set the names of the y and record number properly\n",
    "NVARS = 10\n",
    "numvars = min(NVARS,len(vars_all)-2) # 10\n",
    "final_vars_list = ['Recnum','Fraud']\n",
    "for i in range(numvars):\n",
    "    final_vars_list.append(vars_all.columns[i])\n",
    "    \n",
    "final_vars_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "vars = vars_all.filter(final_vars_list,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Fraud</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Fraud\n",
       "0      0\n",
       "1      0\n",
       "2      0\n",
       "3      0\n",
       "4      0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "record_save = vars['Recnum']\n",
    "Y_save = pd.DataFrame(vars.loc[:,'Fraud'])\n",
    "Y_save.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scale and truncate field values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>card_Merch_num_state_total_14</th>\n",
       "      <th>card_Merchnum_max_30</th>\n",
       "      <th>card_Merch_des_zip_total_1</th>\n",
       "      <th>Merch_description_total_0</th>\n",
       "      <th>card_Merch_state_zip_total_14</th>\n",
       "      <th>card_Merch_des_state_max_30</th>\n",
       "      <th>card_Merch_des_zip_max_30</th>\n",
       "      <th>card_Merch_des_state_zip_max_30</th>\n",
       "      <th>card_Merch_num_des_zip_total_0</th>\n",
       "      <th>card_Merch_des_state_zip_total_30</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>96397.000000</td>\n",
       "      <td>96397.000000</td>\n",
       "      <td>96397.000000</td>\n",
       "      <td>96397.000000</td>\n",
       "      <td>96397.000000</td>\n",
       "      <td>96397.000000</td>\n",
       "      <td>96397.000000</td>\n",
       "      <td>96397.000000</td>\n",
       "      <td>96397.000000</td>\n",
       "      <td>96397.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>770.509236</td>\n",
       "      <td>517.704051</td>\n",
       "      <td>593.666588</td>\n",
       "      <td>761.885095</td>\n",
       "      <td>803.336711</td>\n",
       "      <td>514.700728</td>\n",
       "      <td>513.497615</td>\n",
       "      <td>513.491474</td>\n",
       "      <td>523.805769</td>\n",
       "      <td>903.627845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>4168.658888</td>\n",
       "      <td>1084.028924</td>\n",
       "      <td>4010.097366</td>\n",
       "      <td>2872.816671</td>\n",
       "      <td>4185.964751</td>\n",
       "      <td>1074.829349</td>\n",
       "      <td>1074.519504</td>\n",
       "      <td>1074.520672</td>\n",
       "      <td>2616.296248</td>\n",
       "      <td>4312.348251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.010000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>77.090000</td>\n",
       "      <td>53.430000</td>\n",
       "      <td>45.900000</td>\n",
       "      <td>66.850000</td>\n",
       "      <td>84.450000</td>\n",
       "      <td>49.100000</td>\n",
       "      <td>48.850000</td>\n",
       "      <td>48.850000</td>\n",
       "      <td>43.350000</td>\n",
       "      <td>63.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>237.210000</td>\n",
       "      <td>201.050000</td>\n",
       "      <td>162.740000</td>\n",
       "      <td>225.000000</td>\n",
       "      <td>255.000000</td>\n",
       "      <td>200.550000</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>155.000000</td>\n",
       "      <td>246.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>678.000000</td>\n",
       "      <td>597.510000</td>\n",
       "      <td>509.320000</td>\n",
       "      <td>735.000000</td>\n",
       "      <td>713.010000</td>\n",
       "      <td>595.000000</td>\n",
       "      <td>593.230000</td>\n",
       "      <td>593.230000</td>\n",
       "      <td>490.860000</td>\n",
       "      <td>796.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>306633.410000</td>\n",
       "      <td>47900.000000</td>\n",
       "      <td>306633.410000</td>\n",
       "      <td>217467.180000</td>\n",
       "      <td>306633.410000</td>\n",
       "      <td>47900.000000</td>\n",
       "      <td>47900.000000</td>\n",
       "      <td>47900.000000</td>\n",
       "      <td>217467.180000</td>\n",
       "      <td>306633.410000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       card_Merch_num_state_total_14  card_Merchnum_max_30  \\\n",
       "count                   96397.000000          96397.000000   \n",
       "mean                      770.509236            517.704051   \n",
       "std                      4168.658888           1084.028924   \n",
       "min                         0.010000              0.010000   \n",
       "25%                        77.090000             53.430000   \n",
       "50%                       237.210000            201.050000   \n",
       "75%                       678.000000            597.510000   \n",
       "max                    306633.410000          47900.000000   \n",
       "\n",
       "       card_Merch_des_zip_total_1  Merch_description_total_0  \\\n",
       "count                96397.000000               96397.000000   \n",
       "mean                   593.666588                 761.885095   \n",
       "std                   4010.097366                2872.816671   \n",
       "min                      0.010000                   0.010000   \n",
       "25%                     45.900000                  66.850000   \n",
       "50%                    162.740000                 225.000000   \n",
       "75%                    509.320000                 735.000000   \n",
       "max                 306633.410000              217467.180000   \n",
       "\n",
       "       card_Merch_state_zip_total_14  card_Merch_des_state_max_30  \\\n",
       "count                   96397.000000                 96397.000000   \n",
       "mean                      803.336711                   514.700728   \n",
       "std                      4185.964751                  1074.829349   \n",
       "min                         0.010000                     0.010000   \n",
       "25%                        84.450000                    49.100000   \n",
       "50%                       255.000000                   200.550000   \n",
       "75%                       713.010000                   595.000000   \n",
       "max                    306633.410000                 47900.000000   \n",
       "\n",
       "       card_Merch_des_zip_max_30  card_Merch_des_state_zip_max_30  \\\n",
       "count               96397.000000                     96397.000000   \n",
       "mean                  513.497615                       513.491474   \n",
       "std                  1074.519504                      1074.520672   \n",
       "min                     0.010000                         0.010000   \n",
       "25%                    48.850000                        48.850000   \n",
       "50%                   200.000000                       200.000000   \n",
       "75%                   593.230000                       593.230000   \n",
       "max                 47900.000000                     47900.000000   \n",
       "\n",
       "       card_Merch_num_des_zip_total_0  card_Merch_des_state_zip_total_30  \n",
       "count                    96397.000000                       96397.000000  \n",
       "mean                       523.805769                         903.627845  \n",
       "std                       2616.296248                        4312.348251  \n",
       "min                          0.010000                           0.010000  \n",
       "25%                         43.350000                          63.500000  \n",
       "50%                        155.000000                         246.750000  \n",
       "75%                        490.860000                         796.000000  \n",
       "max                     217467.180000                      306633.410000  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_no_scaling = vars.drop(columns = ['Recnum','Fraud'])\n",
    "X_no_scaling.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>card_Merch_num_state_total_14</th>\n",
       "      <th>card_Merchnum_max_30</th>\n",
       "      <th>card_Merch_des_zip_total_1</th>\n",
       "      <th>Merch_description_total_0</th>\n",
       "      <th>card_Merch_state_zip_total_14</th>\n",
       "      <th>card_Merch_des_state_max_30</th>\n",
       "      <th>card_Merch_des_zip_max_30</th>\n",
       "      <th>card_Merch_des_state_zip_max_30</th>\n",
       "      <th>card_Merch_num_des_zip_total_0</th>\n",
       "      <th>card_Merch_des_state_zip_total_30</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>9.639700e+04</td>\n",
       "      <td>9.639700e+04</td>\n",
       "      <td>9.639700e+04</td>\n",
       "      <td>9.639700e+04</td>\n",
       "      <td>9.639700e+04</td>\n",
       "      <td>9.639700e+04</td>\n",
       "      <td>9.639700e+04</td>\n",
       "      <td>9.639700e+04</td>\n",
       "      <td>9.639700e+04</td>\n",
       "      <td>9.639700e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.632861e-15</td>\n",
       "      <td>-2.943088e-16</td>\n",
       "      <td>-3.105266e-15</td>\n",
       "      <td>9.543076e-16</td>\n",
       "      <td>2.475414e-16</td>\n",
       "      <td>-1.357099e-15</td>\n",
       "      <td>-3.832563e-15</td>\n",
       "      <td>3.024862e-15</td>\n",
       "      <td>-5.718466e-16</td>\n",
       "      <td>1.812779e-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-3.531577e-01</td>\n",
       "      <td>-6.064073e-01</td>\n",
       "      <td>-3.173814e-01</td>\n",
       "      <td>-4.352501e-01</td>\n",
       "      <td>-3.623744e-01</td>\n",
       "      <td>-6.023596e-01</td>\n",
       "      <td>-6.012590e-01</td>\n",
       "      <td>-6.012505e-01</td>\n",
       "      <td>-3.933519e-01</td>\n",
       "      <td>-3.649256e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-3.153007e-01</td>\n",
       "      <td>-5.422421e-01</td>\n",
       "      <td>-2.905632e-01</td>\n",
       "      <td>-3.953644e-01</td>\n",
       "      <td>-3.216869e-01</td>\n",
       "      <td>-5.434950e-01</td>\n",
       "      <td>-5.426602e-01</td>\n",
       "      <td>-5.426519e-01</td>\n",
       "      <td>-3.587629e-01</td>\n",
       "      <td>-3.377712e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-2.366597e-01</td>\n",
       "      <td>-3.649292e-01</td>\n",
       "      <td>-2.222817e-01</td>\n",
       "      <td>-3.009909e-01</td>\n",
       "      <td>-2.395073e-01</td>\n",
       "      <td>-3.618889e-01</td>\n",
       "      <td>-3.613088e-01</td>\n",
       "      <td>-3.613008e-01</td>\n",
       "      <td>-2.696569e-01</td>\n",
       "      <td>-2.593960e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>-2.017084e-02</td>\n",
       "      <td>1.112766e-01</td>\n",
       "      <td>-1.973979e-02</td>\n",
       "      <td>3.343646e-03</td>\n",
       "      <td>-1.881494e-02</td>\n",
       "      <td>1.111025e-01</td>\n",
       "      <td>1.104928e-01</td>\n",
       "      <td>1.105000e-01</td>\n",
       "      <td>-1.612438e-03</td>\n",
       "      <td>-2.448431e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2.049914e+01</td>\n",
       "      <td>1.303617e+01</td>\n",
       "      <td>2.346463e+01</td>\n",
       "      <td>1.716247e+01</td>\n",
       "      <td>2.019480e+01</td>\n",
       "      <td>1.290327e+01</td>\n",
       "      <td>1.290703e+01</td>\n",
       "      <td>1.290702e+01</td>\n",
       "      <td>2.090492e+01</td>\n",
       "      <td>1.846526e+01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       card_Merch_num_state_total_14  card_Merchnum_max_30  \\\n",
       "count                   9.639700e+04          9.639700e+04   \n",
       "mean                    1.632861e-15         -2.943088e-16   \n",
       "std                     1.000000e+00          1.000000e+00   \n",
       "min                    -3.531577e-01         -6.064073e-01   \n",
       "25%                    -3.153007e-01         -5.422421e-01   \n",
       "50%                    -2.366597e-01         -3.649292e-01   \n",
       "75%                    -2.017084e-02          1.112766e-01   \n",
       "max                     2.049914e+01          1.303617e+01   \n",
       "\n",
       "       card_Merch_des_zip_total_1  Merch_description_total_0  \\\n",
       "count                9.639700e+04               9.639700e+04   \n",
       "mean                -3.105266e-15               9.543076e-16   \n",
       "std                  1.000000e+00               1.000000e+00   \n",
       "min                 -3.173814e-01              -4.352501e-01   \n",
       "25%                 -2.905632e-01              -3.953644e-01   \n",
       "50%                 -2.222817e-01              -3.009909e-01   \n",
       "75%                 -1.973979e-02               3.343646e-03   \n",
       "max                  2.346463e+01               1.716247e+01   \n",
       "\n",
       "       card_Merch_state_zip_total_14  card_Merch_des_state_max_30  \\\n",
       "count                   9.639700e+04                 9.639700e+04   \n",
       "mean                    2.475414e-16                -1.357099e-15   \n",
       "std                     1.000000e+00                 1.000000e+00   \n",
       "min                    -3.623744e-01                -6.023596e-01   \n",
       "25%                    -3.216869e-01                -5.434950e-01   \n",
       "50%                    -2.395073e-01                -3.618889e-01   \n",
       "75%                    -1.881494e-02                 1.111025e-01   \n",
       "max                     2.019480e+01                 1.290327e+01   \n",
       "\n",
       "       card_Merch_des_zip_max_30  card_Merch_des_state_zip_max_30  \\\n",
       "count               9.639700e+04                     9.639700e+04   \n",
       "mean               -3.832563e-15                     3.024862e-15   \n",
       "std                 1.000000e+00                     1.000000e+00   \n",
       "min                -6.012590e-01                    -6.012505e-01   \n",
       "25%                -5.426602e-01                    -5.426519e-01   \n",
       "50%                -3.613088e-01                    -3.613008e-01   \n",
       "75%                 1.104928e-01                     1.105000e-01   \n",
       "max                 1.290703e+01                     1.290702e+01   \n",
       "\n",
       "       card_Merch_num_des_zip_total_0  card_Merch_des_state_zip_total_30  \n",
       "count                    9.639700e+04                       9.639700e+04  \n",
       "mean                    -5.718466e-16                       1.812779e-15  \n",
       "std                      1.000000e+00                       1.000000e+00  \n",
       "min                     -3.933519e-01                      -3.649256e-01  \n",
       "25%                     -3.587629e-01                      -3.377712e-01  \n",
       "50%                     -2.696569e-01                      -2.593960e-01  \n",
       "75%                     -1.612438e-03                      -2.448431e-02  \n",
       "max                      2.090492e+01                       1.846526e+01  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = (X_no_scaling - X_no_scaling.mean()) / X_no_scaling.std()\n",
    "\n",
    "# use this to cap variables. For some problems it helps\n",
    "Clip = 10\n",
    "\n",
    "# push in any outlier values, then rescale\n",
    "X.clip(-1*Clip, Clip, inplace=True)\n",
    "\n",
    "# Now redo the zscaling after clipping\n",
    "X = (X - X.mean()) / X.std()\n",
    "X.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# separate data into modeling (traintest) and out of time. Here I'm using the record number to do this separation.\n",
    "# you need to change this oot record number to whatever is appropriate for your data\n",
    "oot_recnum = 84299\n",
    "\n",
    "X_trntst = X[0:oot_recnum]\n",
    "Y_trntst = Y_save[0:oot_recnum]\n",
    "\n",
    "X_oot = X[oot_recnum:]\n",
    "Y_oot = Y_save[oot_recnum:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_oot_orig = X_oot.copy()\n",
    "pd.options.mode.chained_assignment = None  # default='warn'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "340\n",
      "32\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>NVARS</th>\n",
       "      <th>Parameters</th>\n",
       "      <th>Trn</th>\n",
       "      <th>Tst</th>\n",
       "      <th>OOT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>log reg</td>\n",
       "      <td>10.0</td>\n",
       "      <td>penalty='none'</td>\n",
       "      <td>0.608696</td>\n",
       "      <td>0.671815</td>\n",
       "      <td>0.251397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>log reg</td>\n",
       "      <td>10.0</td>\n",
       "      <td>penalty='none'</td>\n",
       "      <td>0.632166</td>\n",
       "      <td>0.634921</td>\n",
       "      <td>0.346369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>log reg</td>\n",
       "      <td>10.0</td>\n",
       "      <td>penalty='none'</td>\n",
       "      <td>0.625600</td>\n",
       "      <td>0.647059</td>\n",
       "      <td>0.284916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>log reg</td>\n",
       "      <td>10.0</td>\n",
       "      <td>penalty='none'</td>\n",
       "      <td>0.635922</td>\n",
       "      <td>0.622137</td>\n",
       "      <td>0.357542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>log reg</td>\n",
       "      <td>10.0</td>\n",
       "      <td>penalty='none'</td>\n",
       "      <td>0.643087</td>\n",
       "      <td>0.608527</td>\n",
       "      <td>0.279330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2995</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2996</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2997</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2998</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2999</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3000 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Model  NVARS      Parameters       Trn       Tst       OOT\n",
       "0     log reg   10.0  penalty='none'  0.608696  0.671815  0.251397\n",
       "1     log reg   10.0  penalty='none'  0.632166  0.634921  0.346369\n",
       "2     log reg   10.0  penalty='none'  0.625600  0.647059  0.284916\n",
       "3     log reg   10.0  penalty='none'  0.635922  0.622137  0.357542\n",
       "4     log reg   10.0  penalty='none'  0.643087  0.608527  0.279330\n",
       "...       ...    ...             ...       ...       ...       ...\n",
       "2995      NaN    NaN             NaN       NaN       NaN       NaN\n",
       "2996      NaN    NaN             NaN       NaN       NaN       NaN\n",
       "2997      NaN    NaN             NaN       NaN       NaN       NaN\n",
       "2998      NaN    NaN             NaN       NaN       NaN       NaN\n",
       "2999      NaN    NaN             NaN       NaN       NaN       NaN\n",
       "\n",
       "[3000 rows x 6 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "try:\n",
    "    Modeling_output = pd.read_csv('Modeling_output.csv').iloc[:, 1:]\n",
    "    counter = Modeling_output[Modeling_output['Model'].isnull()].index[0]\n",
    "    model_counter = len(Modeling_output[['Model', 'NVARS', 'Parameters']].drop_duplicates().dropna(subset='Model'))\n",
    "    print(counter)\n",
    "    print(model_counter)\n",
    "\n",
    "except:\n",
    "    Modeling_output = pd.DataFrame(columns=['Model', 'NVARS', 'Parameters', 'Trn','Tst','OOT'],index=range(3000))\n",
    "    counter = 0\n",
    "    model_counter = 0\n",
    "\n",
    "Modeling_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def model_execution(model_name, algorithm, X, Y, X_oot, Y_oot, test_size = .3, nitermax = 10, Parameters_setting = \"\",\n",
    "                    print_bool = True):\n",
    "    \n",
    "    global Modeling_output, counter, model_counter, NVARS, output\n",
    "\n",
    "    FDR3 = pd.DataFrame(np.zeros((nitermax, 3)), columns=('trn', 'tst', 'oot'))\n",
    "    \n",
    "    if Parameters_setting == \"\": Parameters_setting = str(algorithm)\n",
    "    Parameters_setting = Parameters_setting.replace(' ', '').replace('\\n', '').replace(',', ', ')\n",
    "    Parameters_setting = Parameters_setting.split('(', 1)[1][:-1]\n",
    "    \n",
    "    for niter in range(nitermax):\n",
    "        X_trn, X_tst, Y_trn, Y_tst = train_test_split(X, Y, test_size = test_size)\n",
    "\n",
    "        model = algorithm\n",
    "\n",
    "        X_oot_copied = X_oot.copy()\n",
    "        X_trn_save = X_trn.copy()\n",
    "        Y_trn_save = Y_trn.copy()\n",
    "\n",
    "        model.fit(X_trn, Y_trn.values.ravel())\n",
    "\n",
    "        def prediction_function(X_splited, y_splited, name):\n",
    "\n",
    "            predictions = model.predict_proba(X_splited)[:,1]\n",
    "            X_splited['predicted'] = predictions\n",
    "            X_splited['Fraud'] = y_splited['Fraud']\n",
    "            topRows = int(round(X_splited.shape[0]*0.03))\n",
    "            temp = X_splited.sort_values('predicted',ascending=False).head(topRows)\n",
    "            needed = temp.loc[:,'Fraud']\n",
    "            FDR3.loc[niter, name] = sum(needed)/sum(X_splited.loc[:,'Fraud'])\n",
    "            \n",
    "            return X_splited\n",
    "\n",
    "        X_trn = prediction_function(X_trn, Y_trn_save, 'trn')\n",
    "        X_tst = prediction_function(X_tst, Y_tst, 'tst')\n",
    "        X_oot_copied = prediction_function(X_oot_copied, Y_oot, 'oot')\n",
    "\n",
    "        if print_bool == True: print(niter,\n",
    "                                     FDR3.loc[niter, 'trn'],\n",
    "                                     FDR3.loc[niter, 'tst'],\n",
    "                                     FDR3.loc[niter, 'oot'])\n",
    "\n",
    "        Modeling_output.iloc[counter] = [model_name,\n",
    "                                         NVARS,\n",
    "                                         Parameters_setting,\n",
    "                                         FDR3.loc[niter, 'trn'],\n",
    "                                         FDR3.loc[niter, 'tst'],\n",
    "                                         FDR3.loc[niter, 'oot']]\n",
    "        counter = counter + 1\n",
    "        Modeling_output.to_csv('Modeling_output.csv') # KK: save my progress\n",
    "\n",
    "    if print_bool == True: print(FDR3.mean())\n",
    "    model_counter = model_counter + 1\n",
    "    \n",
    "    df = Modeling_output.dropna()\n",
    "    output = (df.groupby(['Model', 'NVARS', 'Parameters'])\n",
    "              .agg({'Trn':['mean','std'],'Tst':['mean','std'],'OOT':['mean','std']}))\n",
    "    output = output.sort_values(by=['Model', ('Trn', 'mean'), 'NVARS'])\n",
    "    \n",
    "    return output.loc[model_name], {'X_trn': X_trn, 'X_tst': X_tst, 'X_oot': X_oot_copied, 'FDR3': FDR3}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.6275862068965518 0.64 0.3016759776536313\n",
      "1 0.6339144215530903 0.6224899598393574 0.2737430167597765\n",
      "2 0.6331168831168831 0.6287878787878788 0.3407821229050279\n",
      "3 0.6233552631578947 0.6470588235294118 0.25139664804469275\n",
      "4 0.6349453978159126 0.6317991631799164 0.37988826815642457\n",
      "5 0.6291390728476821 0.6231884057971014 0.2905027932960894\n",
      "6 0.6319218241042345 0.6203007518796992 0.2569832402234637\n",
      "7 0.632 0.615686274509804 0.2681564245810056\n",
      "8 0.6311605723370429 0.6254980079681275 0.33519553072625696\n",
      "9 0.6303630363036303 0.6313868613138686 0.35195530726256985\n",
      "trn    0.630750\n",
      "tst    0.628620\n",
      "oot    0.305028\n",
      "dtype: float64\n",
      "CPU times: total: 6.17 s\n",
      "Wall time: 3.87 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">Trn</th>\n",
       "      <th colspan=\"2\" halign=\"left\">Tst</th>\n",
       "      <th colspan=\"2\" halign=\"left\">OOT</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NVARS</th>\n",
       "      <th>Parameters</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">10</th>\n",
       "      <th>penalty='none'</th>\n",
       "      <td>0.626289</td>\n",
       "      <td>0.014962</td>\n",
       "      <td>0.63560</td>\n",
       "      <td>0.032790</td>\n",
       "      <td>0.294972</td>\n",
       "      <td>0.041036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>0.630750</td>\n",
       "      <td>0.003395</td>\n",
       "      <td>0.62862</td>\n",
       "      <td>0.009432</td>\n",
       "      <td>0.305028</td>\n",
       "      <td>0.044397</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Trn                Tst                 OOT  \\\n",
       "                          mean       std     mean       std      mean   \n",
       "NVARS Parameters                                                        \n",
       "10    penalty='none'  0.626289  0.014962  0.63560  0.032790  0.294972   \n",
       "                      0.630750  0.003395  0.62862  0.009432  0.305028   \n",
       "\n",
       "                                \n",
       "                           std  \n",
       "NVARS Parameters                \n",
       "10    penalty='none'  0.041036  \n",
       "                      0.044397  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# Logistic regression\n",
    "model_execution(model_name = 'log reg',\n",
    "                algorithm = LogisticRegression(penalty='none'),\n",
    "                X = X_trntst, Y = Y_trntst,\n",
    "                X_oot = X_oot_orig, Y_oot = Y_oot)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.6942675159235668 0.6865079365079365 0.4692737430167598\n",
      "1 0.7017543859649122 0.6679841897233202 0.41899441340782123\n",
      "2 0.6818181818181818 0.6538461538461539 0.46368715083798884\n",
      "3 0.7070063694267515 0.6547619047619048 0.41899441340782123\n",
      "4 0.7061688311688312 0.6174242424242424 0.39664804469273746\n",
      "5 0.6926751592356688 0.7222222222222222 0.5139664804469274\n",
      "6 0.6847457627118644 0.6862068965517242 0.39664804469273746\n",
      "7 0.7032258064516129 0.6461538461538462 0.4748603351955307\n",
      "8 0.7161936560934892 0.6476868327402135 0.5139664804469274\n",
      "9 0.7104825291181365 0.6559139784946236 0.44692737430167595\n",
      "trn    0.699834\n",
      "tst    0.663871\n",
      "oot    0.451397\n",
      "dtype: float64\n",
      "CPU times: total: 3.94 s\n",
      "Wall time: 3.97 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">Trn</th>\n",
       "      <th colspan=\"2\" halign=\"left\">Tst</th>\n",
       "      <th colspan=\"2\" halign=\"left\">OOT</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NVARS</th>\n",
       "      <th>Parameters</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"16\" valign=\"top\">10</th>\n",
       "      <th>min_impurity_decrease=0.001</th>\n",
       "      <td>0.512820</td>\n",
       "      <td>0.021021</td>\n",
       "      <td>0.505117</td>\n",
       "      <td>0.032347</td>\n",
       "      <td>0.222905</td>\n",
       "      <td>0.015457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min_impurity_decrease=0.0005</th>\n",
       "      <td>0.521784</td>\n",
       "      <td>0.022768</td>\n",
       "      <td>0.520726</td>\n",
       "      <td>0.024889</td>\n",
       "      <td>0.231844</td>\n",
       "      <td>0.011851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min_impurity_decrease=0.0002</th>\n",
       "      <td>0.551049</td>\n",
       "      <td>0.014939</td>\n",
       "      <td>0.557820</td>\n",
       "      <td>0.021647</td>\n",
       "      <td>0.257542</td>\n",
       "      <td>0.026656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min_impurity_decrease=0.0001</th>\n",
       "      <td>0.656209</td>\n",
       "      <td>0.013424</td>\n",
       "      <td>0.624052</td>\n",
       "      <td>0.020888</td>\n",
       "      <td>0.463128</td>\n",
       "      <td>0.046102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min_impurity_decrease=5e-05</th>\n",
       "      <td>0.673367</td>\n",
       "      <td>0.012226</td>\n",
       "      <td>0.646705</td>\n",
       "      <td>0.025946</td>\n",
       "      <td>0.386592</td>\n",
       "      <td>0.068765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min_impurity_decrease=3e-05, min_samples_leaf=60, min_samples_split=120</th>\n",
       "      <td>0.691348</td>\n",
       "      <td>0.010997</td>\n",
       "      <td>0.664404</td>\n",
       "      <td>0.029422</td>\n",
       "      <td>0.455866</td>\n",
       "      <td>0.054750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min_impurity_decrease=3e-05, min_samples_leaf=30, min_samples_split=60</th>\n",
       "      <td>0.691701</td>\n",
       "      <td>0.009895</td>\n",
       "      <td>0.687652</td>\n",
       "      <td>0.019776</td>\n",
       "      <td>0.435754</td>\n",
       "      <td>0.088645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min_impurity_decrease=3.5e-05</th>\n",
       "      <td>0.695014</td>\n",
       "      <td>0.010661</td>\n",
       "      <td>0.654384</td>\n",
       "      <td>0.026308</td>\n",
       "      <td>0.379330</td>\n",
       "      <td>0.071079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min_impurity_decrease=3e-05</th>\n",
       "      <td>0.695579</td>\n",
       "      <td>0.010757</td>\n",
       "      <td>0.667114</td>\n",
       "      <td>0.020939</td>\n",
       "      <td>0.397765</td>\n",
       "      <td>0.087456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min_impurity_decrease=3e-05, min_samples_leaf=15, min_samples_split=30</th>\n",
       "      <td>0.699834</td>\n",
       "      <td>0.011167</td>\n",
       "      <td>0.663871</td>\n",
       "      <td>0.028700</td>\n",
       "      <td>0.451397</td>\n",
       "      <td>0.043418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min_impurity_decrease=2.5e-05</th>\n",
       "      <td>0.703388</td>\n",
       "      <td>0.011972</td>\n",
       "      <td>0.645009</td>\n",
       "      <td>0.032123</td>\n",
       "      <td>0.355866</td>\n",
       "      <td>0.075965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min_impurity_decrease=2e-05</th>\n",
       "      <td>0.710625</td>\n",
       "      <td>0.017125</td>\n",
       "      <td>0.648441</td>\n",
       "      <td>0.018670</td>\n",
       "      <td>0.389944</td>\n",
       "      <td>0.071193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min_impurity_decrease=1e-05</th>\n",
       "      <td>0.744013</td>\n",
       "      <td>0.020672</td>\n",
       "      <td>0.596342</td>\n",
       "      <td>0.018899</td>\n",
       "      <td>0.335754</td>\n",
       "      <td>0.087442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min_impurity_decrease=5e-06</th>\n",
       "      <td>0.764441</td>\n",
       "      <td>0.024999</td>\n",
       "      <td>0.574658</td>\n",
       "      <td>0.066721</td>\n",
       "      <td>0.328492</td>\n",
       "      <td>0.056716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min_impurity_decrease=3e-06</th>\n",
       "      <td>0.813267</td>\n",
       "      <td>0.014243</td>\n",
       "      <td>0.562200</td>\n",
       "      <td>0.030908</td>\n",
       "      <td>0.286034</td>\n",
       "      <td>0.072449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min_impurity_decrease=1e-06</th>\n",
       "      <td>0.878301</td>\n",
       "      <td>0.014125</td>\n",
       "      <td>0.549824</td>\n",
       "      <td>0.024428</td>\n",
       "      <td>0.272067</td>\n",
       "      <td>0.068576</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                               Trn            \\\n",
       "                                                              mean       std   \n",
       "NVARS Parameters                                                               \n",
       "10    min_impurity_decrease=0.001                         0.512820  0.021021   \n",
       "      min_impurity_decrease=0.0005                        0.521784  0.022768   \n",
       "      min_impurity_decrease=0.0002                        0.551049  0.014939   \n",
       "      min_impurity_decrease=0.0001                        0.656209  0.013424   \n",
       "      min_impurity_decrease=5e-05                         0.673367  0.012226   \n",
       "      min_impurity_decrease=3e-05, min_samples_leaf=6...  0.691348  0.010997   \n",
       "      min_impurity_decrease=3e-05, min_samples_leaf=3...  0.691701  0.009895   \n",
       "      min_impurity_decrease=3.5e-05                       0.695014  0.010661   \n",
       "      min_impurity_decrease=3e-05                         0.695579  0.010757   \n",
       "      min_impurity_decrease=3e-05, min_samples_leaf=1...  0.699834  0.011167   \n",
       "      min_impurity_decrease=2.5e-05                       0.703388  0.011972   \n",
       "      min_impurity_decrease=2e-05                         0.710625  0.017125   \n",
       "      min_impurity_decrease=1e-05                         0.744013  0.020672   \n",
       "      min_impurity_decrease=5e-06                         0.764441  0.024999   \n",
       "      min_impurity_decrease=3e-06                         0.813267  0.014243   \n",
       "      min_impurity_decrease=1e-06                         0.878301  0.014125   \n",
       "\n",
       "                                                               Tst            \\\n",
       "                                                              mean       std   \n",
       "NVARS Parameters                                                               \n",
       "10    min_impurity_decrease=0.001                         0.505117  0.032347   \n",
       "      min_impurity_decrease=0.0005                        0.520726  0.024889   \n",
       "      min_impurity_decrease=0.0002                        0.557820  0.021647   \n",
       "      min_impurity_decrease=0.0001                        0.624052  0.020888   \n",
       "      min_impurity_decrease=5e-05                         0.646705  0.025946   \n",
       "      min_impurity_decrease=3e-05, min_samples_leaf=6...  0.664404  0.029422   \n",
       "      min_impurity_decrease=3e-05, min_samples_leaf=3...  0.687652  0.019776   \n",
       "      min_impurity_decrease=3.5e-05                       0.654384  0.026308   \n",
       "      min_impurity_decrease=3e-05                         0.667114  0.020939   \n",
       "      min_impurity_decrease=3e-05, min_samples_leaf=1...  0.663871  0.028700   \n",
       "      min_impurity_decrease=2.5e-05                       0.645009  0.032123   \n",
       "      min_impurity_decrease=2e-05                         0.648441  0.018670   \n",
       "      min_impurity_decrease=1e-05                         0.596342  0.018899   \n",
       "      min_impurity_decrease=5e-06                         0.574658  0.066721   \n",
       "      min_impurity_decrease=3e-06                         0.562200  0.030908   \n",
       "      min_impurity_decrease=1e-06                         0.549824  0.024428   \n",
       "\n",
       "                                                               OOT            \n",
       "                                                              mean       std  \n",
       "NVARS Parameters                                                              \n",
       "10    min_impurity_decrease=0.001                         0.222905  0.015457  \n",
       "      min_impurity_decrease=0.0005                        0.231844  0.011851  \n",
       "      min_impurity_decrease=0.0002                        0.257542  0.026656  \n",
       "      min_impurity_decrease=0.0001                        0.463128  0.046102  \n",
       "      min_impurity_decrease=5e-05                         0.386592  0.068765  \n",
       "      min_impurity_decrease=3e-05, min_samples_leaf=6...  0.455866  0.054750  \n",
       "      min_impurity_decrease=3e-05, min_samples_leaf=3...  0.435754  0.088645  \n",
       "      min_impurity_decrease=3.5e-05                       0.379330  0.071079  \n",
       "      min_impurity_decrease=3e-05                         0.397765  0.087456  \n",
       "      min_impurity_decrease=3e-05, min_samples_leaf=1...  0.451397  0.043418  \n",
       "      min_impurity_decrease=2.5e-05                       0.355866  0.075965  \n",
       "      min_impurity_decrease=2e-05                         0.389944  0.071193  \n",
       "      min_impurity_decrease=1e-05                         0.335754  0.087442  \n",
       "      min_impurity_decrease=5e-06                         0.328492  0.056716  \n",
       "      min_impurity_decrease=3e-06                         0.286034  0.072449  \n",
       "      min_impurity_decrease=1e-06                         0.272067  0.068576  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# Single DT\n",
    "model_execution(model_name = 'DT',\n",
    "                algorithm = DecisionTreeClassifier(min_impurity_decrease=0.00003,\n",
    "                                                   min_samples_leaf=15,\n",
    "                                                   min_samples_split=30),\n",
    "                X = X_trntst, Y = Y_trntst,\n",
    "                X_oot = X_oot_orig, Y_oot = Y_oot)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loop trn tst oot 1 0.6457612381648807 0.6157087910800929 0.42681564245810055\n",
      "loop trn tst oot 2 0.6527797007650386 0.6356667442924123 0.4173184357541899\n",
      "loop trn tst oot 3 0.6503956095570891 0.6373714009772652 0.4357541899441341\n",
      "loop trn tst oot 4 0.6497272275293369 0.6300502096636342 0.42346368715083804\n",
      "loop trn tst oot 5 0.666077752573664 0.6463107523578215 0.4044692737430168\n",
      "loop trn tst oot 6 0.6752294091249414 0.6508048884040297 0.4240223463687151\n",
      "loop trn tst oot 7 0.6937450391872069 0.651086621068394 0.42513966480446924\n",
      "loop trn tst oot 8 0.7040496534865648 0.6477205946356147 0.4374301675977653\n",
      "loop trn tst oot 9 0.7071139165446443 0.6381431137192339 0.34581005586592173\n",
      "loop trn tst oot 10 0.7324094575628987 0.6110259057863864 0.35698324022346367\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "training = []\n",
    "testing = []\n",
    "oot = []\n",
    "for i in range(1,11,1):\n",
    "    \n",
    "    min_imp_decrease = 0.00011 - (i*0.00001)\n",
    "    model_output = model_execution(model_name = 'DT',\n",
    "                                   algorithm = DecisionTreeClassifier(min_impurity_decrease = min_imp_decrease\n",
    "#                                                                       ,min_samples_leaf=15\n",
    "#                                                                       ,min_samples_split=30\n",
    "                                                                     ),\n",
    "                                   X = X_trntst, Y = Y_trntst,\n",
    "                                   X_oot = X_oot_orig, Y_oot = Y_oot,\n",
    "                                   print_bool=False)\n",
    "    results = model_output[1]['FDR3']\n",
    "\n",
    "    results_mean_trn = results['trn'].mean()\n",
    "    results_mean_tst = results['tst'].mean()\n",
    "    results_mean_oot = results['oot'].mean()\n",
    "    print('loop', 'trn', 'tst', 'oot', i, results_mean_trn, results_mean_tst, results_mean_oot)\n",
    "    training.append(results_mean_trn)\n",
    "    testing.append(results_mean_tst)\n",
    "    oot.append(results_mean_oot)\n",
    "\n",
    "table=pd.DataFrame({'min_impurity_decrease * 10,000': range(1,len(training)+1),'training':training,'testing':testing,'oot':oot})\n",
    "table['min_impurity_decrease * 10,000'] = (0.00011 - (table['min_impurity_decrease * 10,000']*0.00001)) * 10_000\n",
    "table.set_index('min_impurity_decrease * 10,000',inplace=True)\n",
    "table.plot().invert_xaxis()\n",
    "plt.savefig('DecisionTree_min_impurity_decrease.pdf', format='pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.7657232704402516 0.7336065573770492 0.553072625698324\n",
      "1 0.757328990228013 0.7330827067669173 0.5195530726256983\n",
      "2 0.7439613526570048 0.7335907335907336 0.5307262569832403\n",
      "3 0.7615894039735099 0.6811594202898551 0.5418994413407822\n",
      "4 0.7738287560581584 0.7318007662835249 0.547486033519553\n",
      "5 0.7658536585365854 0.7358490566037735 0.5642458100558659\n",
      "6 0.7594108019639935 0.7063197026022305 0.553072625698324\n",
      "7 0.7554438860971524 0.7314487632508834 0.5027932960893855\n",
      "8 0.7568438003220612 0.7644787644787645 0.5754189944134078\n",
      "9 0.7339743589743589 0.74609375 0.5642458100558659\n",
      "trn    0.757396\n",
      "tst    0.729743\n",
      "oot    0.545251\n",
      "dtype: float64\n",
      "CPU times: total: 17.6 s\n",
      "Wall time: 18.1 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">Trn</th>\n",
       "      <th colspan=\"2\" halign=\"left\">Tst</th>\n",
       "      <th colspan=\"2\" halign=\"left\">OOT</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NVARS</th>\n",
       "      <th>Parameters</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"18\" valign=\"top\">10</th>\n",
       "      <th>min_impurity_decrease=0.001, n_estimators=20</th>\n",
       "      <td>0.607578</td>\n",
       "      <td>0.020832</td>\n",
       "      <td>0.599715</td>\n",
       "      <td>0.028385</td>\n",
       "      <td>0.370950</td>\n",
       "      <td>0.061323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min_impurity_decrease=0.0005, n_estimators=20</th>\n",
       "      <td>0.610582</td>\n",
       "      <td>0.023764</td>\n",
       "      <td>0.599603</td>\n",
       "      <td>0.025967</td>\n",
       "      <td>0.355307</td>\n",
       "      <td>0.059834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min_impurity_decrease=0.0002, n_estimators=20</th>\n",
       "      <td>0.663884</td>\n",
       "      <td>0.016461</td>\n",
       "      <td>0.668574</td>\n",
       "      <td>0.044979</td>\n",
       "      <td>0.477095</td>\n",
       "      <td>0.061323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min_impurity_decrease=0.0001, n_estimators=20</th>\n",
       "      <td>0.689549</td>\n",
       "      <td>0.013010</td>\n",
       "      <td>0.697797</td>\n",
       "      <td>0.021039</td>\n",
       "      <td>0.525698</td>\n",
       "      <td>0.020476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min_impurity_decrease=5e-05, n_estimators=20</th>\n",
       "      <td>0.730438</td>\n",
       "      <td>0.007634</td>\n",
       "      <td>0.699448</td>\n",
       "      <td>0.021043</td>\n",
       "      <td>0.533520</td>\n",
       "      <td>0.027652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min_impurity_decrease=3e-05, min_samples_leaf=30, min_samples_split=60, n_estimators=20</th>\n",
       "      <td>0.744927</td>\n",
       "      <td>0.014208</td>\n",
       "      <td>0.723578</td>\n",
       "      <td>0.025869</td>\n",
       "      <td>0.548603</td>\n",
       "      <td>0.022928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min_impurity_decrease=2e-05, min_samples_leaf=30, min_samples_split=60, n_estimators=20</th>\n",
       "      <td>0.753169</td>\n",
       "      <td>0.017687</td>\n",
       "      <td>0.736335</td>\n",
       "      <td>0.019346</td>\n",
       "      <td>0.539665</td>\n",
       "      <td>0.017706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min_impurity_decrease=3e-05, min_samples_leaf=15, min_samples_split=30, n_estimators=20</th>\n",
       "      <td>0.754914</td>\n",
       "      <td>0.017924</td>\n",
       "      <td>0.719545</td>\n",
       "      <td>0.033259</td>\n",
       "      <td>0.540223</td>\n",
       "      <td>0.013948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min_impurity_decrease=1e-05, min_samples_leaf=60, min_samples_split=120, n_estimators=20</th>\n",
       "      <td>0.757396</td>\n",
       "      <td>0.011381</td>\n",
       "      <td>0.729743</td>\n",
       "      <td>0.022282</td>\n",
       "      <td>0.545251</td>\n",
       "      <td>0.022222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min_impurity_decrease=3e-05, n_estimators=20</th>\n",
       "      <td>0.764049</td>\n",
       "      <td>0.013384</td>\n",
       "      <td>0.744989</td>\n",
       "      <td>0.033854</td>\n",
       "      <td>0.524581</td>\n",
       "      <td>0.022723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min_impurity_decrease=5e-06, min_samples_leaf=60, min_samples_split=120, n_estimators=20</th>\n",
       "      <td>0.772599</td>\n",
       "      <td>0.009908</td>\n",
       "      <td>0.734021</td>\n",
       "      <td>0.018847</td>\n",
       "      <td>0.558659</td>\n",
       "      <td>0.009854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min_impurity_decrease=1e-05, min_samples_leaf=30, min_samples_split=60, n_estimators=20</th>\n",
       "      <td>0.778692</td>\n",
       "      <td>0.014256</td>\n",
       "      <td>0.760464</td>\n",
       "      <td>0.025871</td>\n",
       "      <td>0.549162</td>\n",
       "      <td>0.017479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min_impurity_decrease=5e-06, min_samples_leaf=30, min_samples_split=60, n_estimators=20</th>\n",
       "      <td>0.794411</td>\n",
       "      <td>0.009152</td>\n",
       "      <td>0.758528</td>\n",
       "      <td>0.021228</td>\n",
       "      <td>0.529609</td>\n",
       "      <td>0.025506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min_impurity_decrease=2e-05, n_estimators=20</th>\n",
       "      <td>0.801828</td>\n",
       "      <td>0.017241</td>\n",
       "      <td>0.735747</td>\n",
       "      <td>0.029652</td>\n",
       "      <td>0.536313</td>\n",
       "      <td>0.019708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min_impurity_decrease=1e-05, n_estimators=20</th>\n",
       "      <td>0.836526</td>\n",
       "      <td>0.010512</td>\n",
       "      <td>0.769749</td>\n",
       "      <td>0.034543</td>\n",
       "      <td>0.532402</td>\n",
       "      <td>0.015812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min_impurity_decrease=5e-06, n_estimators=20</th>\n",
       "      <td>0.873371</td>\n",
       "      <td>0.009299</td>\n",
       "      <td>0.761807</td>\n",
       "      <td>0.025555</td>\n",
       "      <td>0.530168</td>\n",
       "      <td>0.032517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min_impurity_decrease=3e-06, n_estimators=20</th>\n",
       "      <td>0.904986</td>\n",
       "      <td>0.007784</td>\n",
       "      <td>0.776628</td>\n",
       "      <td>0.012723</td>\n",
       "      <td>0.528492</td>\n",
       "      <td>0.019388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min_impurity_decrease=1e-06, n_estimators=20</th>\n",
       "      <td>0.958759</td>\n",
       "      <td>0.008489</td>\n",
       "      <td>0.770538</td>\n",
       "      <td>0.012618</td>\n",
       "      <td>0.515642</td>\n",
       "      <td>0.030718</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                               Trn            \\\n",
       "                                                              mean       std   \n",
       "NVARS Parameters                                                               \n",
       "10    min_impurity_decrease=0.001, n_estimators=20        0.607578  0.020832   \n",
       "      min_impurity_decrease=0.0005, n_estimators=20       0.610582  0.023764   \n",
       "      min_impurity_decrease=0.0002, n_estimators=20       0.663884  0.016461   \n",
       "      min_impurity_decrease=0.0001, n_estimators=20       0.689549  0.013010   \n",
       "      min_impurity_decrease=5e-05, n_estimators=20        0.730438  0.007634   \n",
       "      min_impurity_decrease=3e-05, min_samples_leaf=3...  0.744927  0.014208   \n",
       "      min_impurity_decrease=2e-05, min_samples_leaf=3...  0.753169  0.017687   \n",
       "      min_impurity_decrease=3e-05, min_samples_leaf=1...  0.754914  0.017924   \n",
       "      min_impurity_decrease=1e-05, min_samples_leaf=6...  0.757396  0.011381   \n",
       "      min_impurity_decrease=3e-05, n_estimators=20        0.764049  0.013384   \n",
       "      min_impurity_decrease=5e-06, min_samples_leaf=6...  0.772599  0.009908   \n",
       "      min_impurity_decrease=1e-05, min_samples_leaf=3...  0.778692  0.014256   \n",
       "      min_impurity_decrease=5e-06, min_samples_leaf=3...  0.794411  0.009152   \n",
       "      min_impurity_decrease=2e-05, n_estimators=20        0.801828  0.017241   \n",
       "      min_impurity_decrease=1e-05, n_estimators=20        0.836526  0.010512   \n",
       "      min_impurity_decrease=5e-06, n_estimators=20        0.873371  0.009299   \n",
       "      min_impurity_decrease=3e-06, n_estimators=20        0.904986  0.007784   \n",
       "      min_impurity_decrease=1e-06, n_estimators=20        0.958759  0.008489   \n",
       "\n",
       "                                                               Tst            \\\n",
       "                                                              mean       std   \n",
       "NVARS Parameters                                                               \n",
       "10    min_impurity_decrease=0.001, n_estimators=20        0.599715  0.028385   \n",
       "      min_impurity_decrease=0.0005, n_estimators=20       0.599603  0.025967   \n",
       "      min_impurity_decrease=0.0002, n_estimators=20       0.668574  0.044979   \n",
       "      min_impurity_decrease=0.0001, n_estimators=20       0.697797  0.021039   \n",
       "      min_impurity_decrease=5e-05, n_estimators=20        0.699448  0.021043   \n",
       "      min_impurity_decrease=3e-05, min_samples_leaf=3...  0.723578  0.025869   \n",
       "      min_impurity_decrease=2e-05, min_samples_leaf=3...  0.736335  0.019346   \n",
       "      min_impurity_decrease=3e-05, min_samples_leaf=1...  0.719545  0.033259   \n",
       "      min_impurity_decrease=1e-05, min_samples_leaf=6...  0.729743  0.022282   \n",
       "      min_impurity_decrease=3e-05, n_estimators=20        0.744989  0.033854   \n",
       "      min_impurity_decrease=5e-06, min_samples_leaf=6...  0.734021  0.018847   \n",
       "      min_impurity_decrease=1e-05, min_samples_leaf=3...  0.760464  0.025871   \n",
       "      min_impurity_decrease=5e-06, min_samples_leaf=3...  0.758528  0.021228   \n",
       "      min_impurity_decrease=2e-05, n_estimators=20        0.735747  0.029652   \n",
       "      min_impurity_decrease=1e-05, n_estimators=20        0.769749  0.034543   \n",
       "      min_impurity_decrease=5e-06, n_estimators=20        0.761807  0.025555   \n",
       "      min_impurity_decrease=3e-06, n_estimators=20        0.776628  0.012723   \n",
       "      min_impurity_decrease=1e-06, n_estimators=20        0.770538  0.012618   \n",
       "\n",
       "                                                               OOT            \n",
       "                                                              mean       std  \n",
       "NVARS Parameters                                                              \n",
       "10    min_impurity_decrease=0.001, n_estimators=20        0.370950  0.061323  \n",
       "      min_impurity_decrease=0.0005, n_estimators=20       0.355307  0.059834  \n",
       "      min_impurity_decrease=0.0002, n_estimators=20       0.477095  0.061323  \n",
       "      min_impurity_decrease=0.0001, n_estimators=20       0.525698  0.020476  \n",
       "      min_impurity_decrease=5e-05, n_estimators=20        0.533520  0.027652  \n",
       "      min_impurity_decrease=3e-05, min_samples_leaf=3...  0.548603  0.022928  \n",
       "      min_impurity_decrease=2e-05, min_samples_leaf=3...  0.539665  0.017706  \n",
       "      min_impurity_decrease=3e-05, min_samples_leaf=1...  0.540223  0.013948  \n",
       "      min_impurity_decrease=1e-05, min_samples_leaf=6...  0.545251  0.022222  \n",
       "      min_impurity_decrease=3e-05, n_estimators=20        0.524581  0.022723  \n",
       "      min_impurity_decrease=5e-06, min_samples_leaf=6...  0.558659  0.009854  \n",
       "      min_impurity_decrease=1e-05, min_samples_leaf=3...  0.549162  0.017479  \n",
       "      min_impurity_decrease=5e-06, min_samples_leaf=3...  0.529609  0.025506  \n",
       "      min_impurity_decrease=2e-05, n_estimators=20        0.536313  0.019708  \n",
       "      min_impurity_decrease=1e-05, n_estimators=20        0.532402  0.015812  \n",
       "      min_impurity_decrease=5e-06, n_estimators=20        0.530168  0.032517  \n",
       "      min_impurity_decrease=3e-06, n_estimators=20        0.528492  0.019388  \n",
       "      min_impurity_decrease=1e-06, n_estimators=20        0.515642  0.030718  "
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# RF\n",
    "model_execution(model_name = 'RF',\n",
    "                algorithm = RandomForestClassifier(n_estimators=20, min_impurity_decrease=0.00001,\n",
    "                                                  min_samples_leaf=30, min_samples_split=60),\n",
    "                X = X_trntst, Y = Y_trntst,\n",
    "                X_oot = X_oot_orig, Y_oot = Y_oot)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loop trn tst oot 1 0.6972129146638586 0.6760813424563341 0.5189944134078213\n",
      "loop trn tst oot 2 0.699227659512366 0.6870963708691395 0.5033519553072626\n",
      "loop trn tst oot 3 0.6987705379114497 0.695152131142775 0.5139664804469274\n",
      "loop trn tst oot 4 0.7101820953599175 0.6893919032807113 0.5145251396648044\n",
      "loop trn tst oot 5 0.7129081024701606 0.6877916383663998 0.5318435754189945\n",
      "loop trn tst oot 6 0.7215336003406353 0.7105916080660671 0.5268156424581005\n",
      "loop trn tst oot 7 0.743085267448987 0.7124376358279348 0.5374301675977655\n",
      "loop trn tst oot 8 0.7692985274277016 0.7281438297119807 0.5195530726256985\n",
      "loop trn tst oot 9 0.7962425254618154 0.7664751209174913 0.5329608938547485\n",
      "loop trn tst oot 10 0.8350979561323928 0.772015904979008 0.5312849162011173\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAEKCAYAAAAcgp5RAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAA5xUlEQVR4nO3dd3xc1Z3//9dH3SqWJVlykdxk3G1sy7JxATcw2JBQE9qyCewGBwj72+wuWWCzgU2y3w0J2SzJBgKGACkLhA4JpuOGS7BccMNVNpIs22q2ep35/P64V/JIlqyxLWk048/z8dBjZu49986Zi3nPmXPPPVdUFWOMMaErLNAVMMYY070s6I0xJsRZ0BtjTIizoDfGmBBnQW+MMSHOgt4YY0KcX0EvIotFZI+I7BeRB9pZnygifxaRz0Vkp4jc4bPukIhsF5GtIpLTlZU3xhjTOelsHL2IhAN7gUVAAbARuEVVd/mU+TcgUVXvF5FUYA8wUFUbROQQkK2qJd30GYwxxpxGhB9lZgD7VTUXQEReAq4BdvmUUSBBRASIB8qAprOtVP/+/XX48OFnu7kxxpx3Nm3aVKKqqe2t8yfo04F8n9cFwEVtyvwaeBsoBBKAm1TV665T4AMRUeApVV3W3puIyFJgKcDQoUPJybFeHmOM8ZeIfNnROn/66KWdZW37e64AtgKDgSnAr0Wkr7tujqpmAUuA74jI3PbeRFWXqWq2qmanprb7pWSMMeYs+BP0BcAQn9cZOC13X3cAr6tjP3AQGAugqoXuYxHwBk5XkDHGmB7iT9BvBEaJyAgRiQJuxumm8ZUHXAogIgOAMUCuiMSJSIK7PA64HNjRVZU3xhjTuU776FW1SUTuBd4HwoFnVXWniNzlrn8S+DHwvIhsx+nquV9VS0QkE3jDOUdLBPCCqr53NhVtbGykoKCAurq6s9n8vBETE0NGRgaRkZGBrooxppfodHhlIGRnZ2vbk7EHDx4kISGBlJQU3C8O04aqUlpaSmVlJSNGjAh0dYwxPUhENqlqdnvrgubK2Lq6Ogv5TogIKSkp9qvHGNNK0AQ9YCHvBztGxpi2girojTEmVO07VsnLOfmdFzwLFvR+OnHiBE888cQZb3fllVdy4sSJ05Z56KGH+Oijj86yZsaYYOb1Ks+syeWq//2Un7+/h5qGs55UoEP+XBlrOBn099xzT6vlHo+H8PDwDrdbvnx5p/v+0Y9+dM71M8YEn/yyGv7llc/57GAZl40bwE+un0RsVNfHsrXo/fTAAw9w4MABpkyZwvTp01mwYAG33norkyZNAuDaa69l2rRpTJgwgWXLTs7yMHz4cEpKSjh06BDjxo3jzjvvZMKECVx++eXU1tYCcPvtt/Pqq6+2lH/44YfJyspi0qRJ7N69G4Di4mIWLVpEVlYW3/72txk2bBglJTZPnDHBSFV56bM8Fj+2ml2FFTz6tQt5+hvTSE2I7pb3C8oW/Q//vJNdhRVdus/xg/vy8FcndLj+kUceYceOHWzdupWVK1dy1VVXsWPHjpZhjM8++yzJycnU1tYyffp0brjhBlJSUlrtY9++fbz44os8/fTT3Hjjjbz22mvcdtttp7xX//792bx5M0888QQ///nPeeaZZ/jhD3/IwoULefDBB3nvvfdafZkYY4JHUUUdD7y+nU92FzErM4VHv34hGUmx3fqeQRn0vcGMGTNajVX/1a9+xRtvvAFAfn4++/btOyXoR4wYwZQpUwCYNm0ahw4danff119/fUuZ119/HYBPP/20Zf+LFy8mKSmpKz+OMaYH/GVbIf/+5g5qGzw89JXx3D57OGFh3T9SLiiD/nQt754SFxfX8nzlypV89NFHrF+/ntjYWObPn9/uWPbo6JM/y8LDw1u6bjoqFx4eTlOTc2KmN17YZozxz4maBn7w1k7+/HkhkzMS+e8bp3BBWnyPvb/10fspISGBysrKdteVl5eTlJREbGwsu3fvZsOGDV3+/hdffDEvv/wyAB988AHHjx/v8vcwxnS9FXuKuPx/VvPu9iP8y6LRvHb37B4NeQjSFn0gpKSkMGfOHCZOnEifPn0YMGBAy7rFixfz5JNPcuGFFzJmzBhmzpzZ5e//8MMPc8stt/CnP/2JefPmMWjQIBISErr8fYwxXaO6von/fOcLXvwsj9ED4nn29ulMTE8MSF2CZq6bL774gnHjxgWoRoFXX19PeHg4ERERrF+/nrvvvputW7e2W/Z8P1bGBNpnB8v4l1e2UnC8lqWXZPJPi0YTE9nxMOyucLq5bqxFHyTy8vK48cYb8Xq9REVF8fTTTwe6SsaYNuoaPfziw708vSaXIUmx/GnpLGaMSA50tSzog8WoUaPYsmVLoKthjOnAjsPl/PPLW9l7rIpbLxrK968cR1x074jY3lELY4wJUk0eL0+sPMCvPt5HSnwUz98xnflj0gJdrVYs6I0x5iztL6riX17eyucF5Vw9eTA/umYC/WKjAl2tU1jQG2PMGfJ6lefWHeJn7+0mNiqcx2/N4qoLBwW6Wh2yoDfGmDOQX1bD9179nA25ZVw6No2f3DCJtISYQFfrtOyCKT+d7TTFAI899hg1NTUtr/2ZutgY07uoKi/n5LPkl2vYXlDOT2+YxDPfzO71IQ8W9H7ryqBfvnw5/fr166KaGWO6W1FlHXf+Pod/fXUbEwb35b3vzuWm6UOD5o5u1nXjJ99pihctWkRaWhovv/wy9fX1XHfddfzwhz+kurqaG2+8kYKCAjweDz/4wQ84duwYhYWFLFiwgP79+7NixQqGDx9OTk4OVVVVLFmyhIsvvph169aRnp7OW2+9RZ8+fdi4cSN///d/T1xcHBdffDHvvvsuO3bsCPRhMOa8s3z7Eb7/xnaqGzz8+1Xj+Ls5I3pkIrKu5FfQi8hi4JdAOPCMqj7SZn0i8EdgqLvPn6vqc/5se1befQCObj/n3bQycBIs6bhqvtMUf/DBB7z66qt89tlnqCpXX301q1evpri4mMGDB/POO+8Azhw4iYmJ/OIXv2DFihX079//lP12NHXxHXfcwbJly5g9ezYPPPBA135WY0ynymsaefjtHby5tZALMxL5xY2TuSAtOKcd6bTrRkTCgceBJcB44BYRGd+m2HeAXao6GZgP/LeIRPm5bdD54IMP+OCDD5g6dSpZWVns3r2bffv2MWnSJD766CPuv/9+1qxZQ2Ji5/NatDd18YkTJ6isrGT27NkA3Hrrrd35cYwxbazaW8wVj63mL9uO8N3LRrkTkQVnyIN/LfoZwH5VzQUQkZeAa4BdPmUUSBCnwyoeKAOagIv82PbMnabl3RNUlQcffJBvf/vbp6zbtGkTy5cv58EHH+Tyyy/noYceOu2+2pu6uDfOP2TM+aC6von/Wv4F//fXPEalxfP0N7KZlBGYici6kj8nY9MB31uTF7jLfP0aGAcUAtuBf1RVr5/bAiAiS0UkR0RyiouL/ax+z/GdpviKK67g2WefpaqqCoDDhw9TVFREYWEhsbGx3Hbbbdx3331s3rz5lG39kZSUREJCQst0xy+99FIXfxpjTFs5h8q48ldreOGzPO68ZAR//oeLQyLkwb8WfXtnHdo2Oa8AtgILgZHAhyKyxs9tnYWqy4Bl4Mxe6Ue9epTvNMVLlizh1ltvZdasWQDEx8fzxz/+kf379/O9732PsLAwIiMj+c1vfgPA0qVLWbJkCYMGDWLFihV+vd9vf/tb7rzzTuLi4pg/f75f3UDGmDNX1+jhfz7ay7LVuaT368NLd87kosyUzjcMIp1OUywis4D/UNUr3NcPAqjqT3zKvAM8oqpr3NefAA/gnIA97bbtsWmKoaqqivh45+YEjzzyCEeOHOGXv/ylX9ueb8fKmLNRUdfIH9Z/yXNrD1JS1cAtM4bw/avGE99LJiI7U+c6TfFGYJSIjAAOAzcDbc8O5gGXAmtEZAAwBsgFTvixrWnHO++8w09+8hOampoYNmwYzz//fKCrZExIKKmq59lPD/KH9V9SWd/E3NGp3Lvggl4xnXB36TToVbVJRO4F3sdpoT+rqjtF5C53/ZPAj4HnRWQ7TnfN/apaAtDett3zUULLTTfdxE033RToahgTMgqO1/D06lxe2phPg8fLkokDuWf+BQG761NP8us3iqouB5a3Wfakz/NC4HJ/tzXGmJ6yv6iS36zM5a2thwG4bmo6d80fycjUnr1vayAFZ2eUMcZ0YlvBCZ5YcYD3dx0lOiKM22YO4865maT36xPoqvU4C3pjTMhQVTbklvHEyv2s2VdCQkwE35l/AXfMGU5KfHTnOwhRFvTGmKDn9Sqf7C7i8ZX72ZJ3gv7x0dy/eCy3zRxKQkxkoKsXcBb03eDEiRO88MIL3HPPPYGuijEhrcnj5Z3tR3hixQH2HKskI6kPP75mAl/PHkJMZHigq9drWNB3g+YpjS3ojekedY0eXttcwFOrcskrq2FUWjy/uHEyX508mMhwm329LTsiZ+AXv/gFEydOZOLEiTz22GMdLvOd0vh73/te4CpsTIipqm9i2eoDzP3ZCr7/xg6SYiN56m+n8f5353J9VoaFfAeCskX/089+yu6y3V26z7HJY7l/xv0drt+0aRPPPfccf/3rX1FVLrroIi655JJTls2bN6/VlMbGmHN3vLqB59Yd4nfrDlFe28jskSn8z01TmD0yJWhu/hFIQRn0gfDpp59y3XXXERcXB8D111/f7rI1a9Zw9dVXB7KqxoSMo+V1PL0mlxc/y6OmwcPl4wdwz4ILmDKkX6CrFlSCMuhP1/LuLu3NCVReXt7j9TDmfHCopJonVx3gtc0FeBWunjyYu+ePZPSA4J0TPpCsQ8tPc+fO5c0336Smpobq6mreeOMNrrrqqlOWXXLJJWc8LbExxrGrsIJ7X9jMwv9eyetbDnPT9CGsvG8+/3PTFAv5cxCULfpAyMrK4vbbb2fGjBkAfOtb32LatGmnLJs6dSpAqymNH3300YDV25hgkHOojMdX7GfFnmLioyNYOnckf3fxcNISYgJdta7j9UJNKVQdhcpj7uNRqDp28jEsAu7o+hljOp2mOBBsmuJzY8fKBANVZdXeYp5YeYDPDpaRHBfFHbOH841Zw0mMDaKLnDyNUFXUJsDbeawuAm/TqdtHJ0LCAIgfAEnD4JrHz6oa5zpNsTHGdJnmi5yeXJXLF0cqGJQYw0NfGc/NM4YQG9WLIqmx9tQWd3uPNaW0ez+l2P6QMNAJ8LTxzmPza9/HyO6fe6cXHVVjTCiraWjiTxvzeWbNQQ6fqOWCtHh+9rULuXZKOlERATxdWLIPtvwBKgp9AvwY1Lcz2CIsAuLSnBZ44hDIyIb4gW6L3OcxPg3Ce8+vkqAKelW1MbOd6I1dceb8VlpVz+/WHeL3G77kRE0j04cn8cOrJ7BwbBphYQH8/9nrhb/+Bj7+EagXEgY5LezUsZA536fl7RPgsSkQFnxjWIIm6GNiYigtLSUlxS6Q6IiqUlpaSkxMCJ3AMkErr7SGp9fk8nJOPvVNXhaNH8Bd8zKZNqwX3MmpLBfe/A7krYPRS+CrjzmhHqKCJugzMjIoKCiguLg40FXp1WJiYsjIyAh0Ncx5bHtBOU+tPsDy7UcIDxOun5rBnXMzuSCtF9zow+uFnN/Chw9BWCRc+xuYfAuEeOMxaII+MjKSESNGBLoaxph2qCpr9pXw1OoDrN1fSkJ0BHfOzeTv5oxgQN9e8gvzRB68dS8cXAUjF8LVv4bE9EDXqkcETdAbY3qf5hE0T63KZdeRCtISonlwyVhuuWgofXvLPPCqsPn38P73AYWvPAbTbg/5VrwvC3pjzBmraWji5Y35PPPpQQqO1zIyNY6f3XAh10wdTHREL5oHvqIQ3v7/YP+HMPwSZ4x60rBA16rHWdAbY/xWVt3gjKBZf4jjNY1MG5bEw1+dwKWBHkHTlips+xO8+6/Q1ABLfgbT7wzKETNdwa+gF5HFwC+BcOAZVX2kzfrvAX/js89xQKqqlonIIaAS8ABNHV25ZYzpvfLLTo6gqWv0ctk4ZwRN9vBeMIKmraoi+PN3Yc87MOQi54RryshA1yqgOg16EQkHHgcWAQXARhF5W1V3NZdR1UeBR93yXwX+SVXLfHazQFVLurTmxphut+NwOU+tzuWdbYWEhwnXTU1n6dxMLkjrpROM7XgN3rkPGqrh8v+EmfdAWC/qSgoQf1r0M4D9qpoLICIvAdcAuzoofwvwYtdUzxjT01SVT/eX8NSqXD7dX0J8dAR3XpLJHXNGMDCxl4ygaau6FN75Z9j1JgzOguuehNQxga5Vr+FP0KcD+T6vC4CL2isoIrHAYuBen8UKfCAiCjylqss62HYpsBRg6NChflTLGNOVmjxelu84ylOrDrCz0BlB88CSsdzam0bQtOeLv8Bfvgu1J2DhD2DOdyHcTj/68udotHeGpaPr7L8KrG3TbTNHVQtFJA34UER2q+rqU3bofAEsA2f2Sj/qZYzpArUNHl7ZlM/Ta3LJL6slMzWOn94wiWunpveuETRt1R6Hd+93TroOvBC+8RYMmBDoWvVK/gR9ATDE53UGUNhB2Ztp022jqoXuY5GIvIHTFXRK0BtjelZZdQO/X+/ch/V4TSNZQ/vxg6vGc9m4Ab1rBE179n0Ib/8DVBfDvAdg7n29ahKx3safoN8IjBKREcBhnDC/tW0hEUkE5gG3+SyLA8JUtdJ9fjnwo66ouDHm7OwsLOdPG/N9RtCk8e15I5neG0fQtFVXAe//mzPbZOo4uOUlGDwl0LXq9ToNelVtEpF7gfdxhlc+q6o7ReQud/2TbtHrgA9Utdpn8wHAG+4kZBHAC6r6Xld+AGNM545XN/DW1sO8sqmAnYUVRIWHcfWUwXx7biajguUWfbkrnSkMKg7Dxf8E8x+EiOhA1yooBM0dpowxZ8bjVVbvK+aVnHw+2lVEg8fLxPS+fH3aEK6ZMph+sVGBrqJ/6qucSchyfgspo5xx8UOmB7pWvY7dYcqY80hucRWvbCrg9c0FHKuoJzkuittmDuPr2RmMG9Q30NU7M4fWwlv3wPEvYeZ34NIf9MgdmUKNBb0xIaCyrpF3th3hlU0FbPryOOFhwvzRqfzw6gwWjh0Q2Ds4nY3GWueGIBt+48xNc8dyGDY70LUKWhb0xgQpr1f568EyXtmUz7vbj1Lb6GFkahwPLBnL9VPTSest0wOfqfyN8OZdULofpn8LLvshRPeCueyDmAW9MUHm8IlaXttUwCub8skvqyUhOoJrp6bz9ewMpg7pF7x3YGuqhxX/Bet+BX3TnXHxmfMDXauQYEFvTBCoa/Tw/s6jvJJTwNoDJajC7JEp/MuiMVwxYSB9onrxhU3+KNwCb9wNxV9A1jfg8v8HMUF2PqEXs6A3ppdSVT4vKOeVnHze/ryQyromMpL68I+XjuKGrAyGJMcGuornrqkB1vwcVv8c4tPgb16FUYsCXauQY0FvTC9TXFnPG1sKeCWngH1FVcREhrFk4iC+Pi2DmZkpvf+q1c6oQsk+OPAxbPkjHNsBF94MSx6BPkmBrl1IsqA3phdo9Hj5ZHcRr+QUsGJPER6vMnVoP35y/SSuunBQ755UzB+1xyF3lRPuB1ZAuTtPYsoouPkFGHtVYOsX4izojQmgPUcreSUnnze2HKa0uoHUhGi+dckIvj4to/fO+e4PrwcOb3aCff/HcDgH1AvRfWHEXLjkn2Hkpeflbf0CwYLemB5WXtPI25870xFsKygnMly4bNwAvp6dwdxRqUSEB9mY92blBU6oH/jYma6grhwQSM+CS+6DCy6F9Gk2+VgAWNAb001UlZKqBnKLq8gtqSa3uIr9RVWsPVBKQ5OXcYP68tBXxnPt1HSS44JkOgJfDTXw5bqTrfaSPc7yhEEw9qtwwULIXACxQTBZWoizoDfmHNU1ejhUWk1usRPmucXVHHCDvbKuqaVcdEQYI/rHccv0IXw9ewgT0xMDWOuzoApFu0622r9cD556CI+G4XMg62+d7pi0cRCsY/lDlAW9MX7wepWjFXVOmJe4Ye6GemF5Lb5zAw5KjCEzNY5rp6STmRpHZmo8mf3jSO/XJ/hGzNSUwYFPTv5VHnGWp451rlq9YCEMm2Pzz/RyFvTG+Kiqb2pplecWV3GgpJqDxdUcLKmmttHTUi4uKpzM1HiyhyeR2X+IG+hxjOgfR2xUEP9v5WmEgo1uq/0T50ImFGL6wcgFTot95AJIzAh0Tc0ZCOJ/kcacnSaPl8Mnak+2yktOdrkUVda3lAsTyEiKJTM1jpmZKS1hPjI1nrSE6OCdaqCt44dOBvvB1VBfARIOGdnOnO8XXAqDp0JYkF99ex6zoDdByetVaho9VNc3UV3fRE2Dh6r6Jmoamqiu91DT0ERVvYea+iaqG5xyxyrqyC2pJq+0hgaPt2Vf/WIjyewfx9zRqU6Y949nZGocQ1Nie/c9U9ujCp4GaKqDxjrnsakemmrdR3d5Q6XTx37gEyg74GybOBQmXu+02kfMhT79AvpRTNexoDfdTlWpbXSDuN5DtRvG1Q2+r52wbg7u6oZTw7rGLVdd72nVjdKZqIgw4qLCSY6LIjM1nkvHpTGyf3xL/3mPjng5kef8dRbEZ728DvDzZkKRsTD8Ypix1Gm1p1xgJ1FDlAW96VKVdY3sLKxgx+Fyth8uZ3tBOQdLq/H3RmYRYUJcdARxUeHERke0PO8XG0V8tLssKpzYqAjioyOIjQ4nLiqi1Tbx0c76uChnfWSgx6U3NcCed2DT8874cn9E9HFukxfpPkbE+PxFQ0wiRPq8jvAp1+ly96//KLsV33nCgt6cter6JnYWVrCt4AQ7Dpez7XA5B0tOhvrgxBgmpidy5aRBJMREnCakw1tCOei6Sk6n7CBs/h1s+T+oLoLEIbDg32HIDDfAfQLZN9DDo6xlbbqUBb3xS3V9E7uOVLC9wG2pHy7nQHFVS6gP7BvDpIxErp2SzqSMRCalJ9I//jxsLXoaYc9yp/V+4BOQMBi9GKbd4XSP2AlNEwAW9OYUNQ1N7CqsaOl62X64nP0+oT6gbzST0hP56oWDmZTRl4npiaQlBOndjLrK8S/d1vsfoeoY9M2A+f8GU2+DxPRA186c5/wKehFZDPwSCAeeUdVH2qz/HvA3PvscB6Sqalln25rAqm3wsOuIE+jbDpez43A5+4uq8LqhnpoQzYVu98uFbks9aG9R19U8TbD3Pdj0nDM8UQRGXe603kctsta76TU6DXoRCQceBxYBBcBGEXlbVXc1l1HVR4FH3fJfBf7JDflOtzU9p67R07r7paCcfUWVLaHePz6aSel9WTxxEJPSE7kwI5EBFuqnOpEHm38Pm/8AVUchYTDM+1fnzkh2IZHphfxp0c8A9qtqLoCIvARcA3QU1rcAL57ltr2OqtLg8VLX6KW+0UNdo5e6Jg91jR5qGzzUNXmpa3Re17vr6hudMdoiECZCmEBYmLjP3dciJ9eHNb8+uS5McF+3U77VeggPa7utU7a+ycOuwgq2ucG+r6gKj5vqKXFRTMpI5IoJA5iYnsikjEQG9o0JnYuAupqnCfZ94LTe933oLBu1CKb9j9OKD7deUNN7+fOvMx3I93ldAFzUXkERiQUWA/eexbZLgaUAQ4cO9aNap/prbim1bujWNZ4M4JNh7DzWN7VZ3+ht2a6+qfXyuiaP30MDe6vkuCgmpSdy2bgBLSdKByVaqPulvMBpuW/+PVQWQvxAmHuf03rvd3b/To3paf4EfXtp0FH0fRVYq6plZ7qtqi4DlgFkZ2efVbR+87nPqGv0drg+KjyM6MgwYiLDiYkMIyYivOV5QkwE/eOjiYkMo0/kyeUx7vPoiJPPfbftExVGdETr8tERYYgIXlXUCx5VvO6fKu5z5+rOk6+dZdq8ThVPJ+tP2Z8qqorH6zyPEGXs4H4MtlA/M16P02rf9JzTild1Rsxc+agzgsZa7ybI+PMvtgAY4vM6AyjsoOzNnOy2OdNtz9nv7phBRHhYq4COiQijT5QzPjs82GYO9EddBZTlun8HnLHbZblQesAZu90n2ZkfPGGgz2Pzc/d1fJrdDAKgovBk672iAOIHwMX/5LTek4YHunbGnDV/gn4jMEpERgCHccL81raFRCQRmAfcdqbbdpWLMlO6a9eBVVfuBHdZrhvkB06Ge3Vx67LxAyFlJIy+3AnymjKoPOpML1v0hTP0T9tOHyAQl9rmy6Cdx7j+oTeSxOtxRsxses4ZQaNeGLkQFv8XjLnSvgBNSOg06FW1SUTuBd7HGSL5rKruFJG73PVPukWvAz5Q1erOtu3qDxESao+fDPLSA61b6TWlrcsmDIbkTBizxHlMzoTkkZA8AqLiTv8+Xg9UlzjB3/wF0PaxcIv7BdKmB03CnVZuZ18Iscm9/8rOiiPOmPfNv4fyPOeLbs4/QtY3neNoTAgR7YVnGrOzszUnJyfQ1eh6NWU+AZ7bOtBry1qX7ZvhBE5yptNCbw70pBEQFdv9dfU0QlWRz5dA8xdBmy+FtvUG5xL++IEnu4ni+p+8tD8i2n2M8XnuuyzKuWOR77qI6FOXnc00AV6vc7Xqpudgz7vOL5sR8yD7DhhzlfPexgQpEdmkqtntrbOzSl2toca53VrpgZNdLM2BXnfCp6A4Y66TM2H8Na0DPWl44O/YEx7pXNHZ2VWdTfVOd1BHvw5K9jr3FfU0OGU99aff3xnVsaMvBJ8vC99lhzc5Y+Bj+8Pse53We8rIrquPMb2UBf25qD0BR7fDkc/h6DbnsWSv088LgEC/IU54T7zhZKs8ZST0G+bMJhjsIqKdYYb+DjVsmS+9/uS86S3PfZc1OF8Kfi9zXzc/b36sKTu57+RMuOw/YOxXbNZGc16xoPdXVTEc/dwJ8+a/44dOrk8YDIMudFrnAy+E/qMhaZgFSlsiJ1vaxpgeYUHflipUHPYJdLelXukzKjRpOAya7Ay7GzjZCfj4tIBV2RhjTuf8DnqvF44fbN1KP/L5yROMEua0zEdc4rTSB02GgZPsFmvGmKBy/gS9p8npP28O86PbnNZ6Q6WzPiwS0sbB2KucQB80GQZM6Hy4ojHG9HKhGfSNdc7IF9+TpMd2uvfTxLm92sBJMPlmp9tl0GRIHWfD64wxISl0gr6pAf7yXaeVXvwFeJuc5dGJTphP/9bJlnrKBaF3hacxxnQgdII+IsppvScMcC7/b+5TTxre+6/SNMaYbhQ6QQ9w16eBroExxvQ6YYGugDHGmO5lQW+MMSHOgt4YY0KcBb0xxoQ4C3pjjAlxFvTGGBPiLOiNMSbEWdAbY0yIs6A3xpgQZ0FvjDEhzq+gF5HFIrJHRPaLyAMdlJkvIltFZKeIrPJZfkhEtrvrQvCO38YY07t1OteNiIQDjwOLgAJgo4i8raq7fMr0A54AFqtqnoi0vd3SAlUt6bpqG2OM8Zc/LfoZwH5VzVXVBuAl4Jo2ZW4FXlfVPABVLeraahpjjDlb/gR9OpDv87rAXeZrNJAkIitFZJOIfMNnnQIfuMuXnlt1jTHGnCl/pilubzJ3bWc/04BLgT7AehHZoKp7gTmqWuh253woIrtVdfUpb+J8CSwFGDp06Jl8BmOMMafhT4u+ABji8zoDKGynzHuqWu32xa8GJgOoaqH7WAS8gdMVdApVXaaq2aqanZqaemafwhhjTIf8CfqNwCgRGSEiUcDNwNttyrwFXCIiESISC1wEfCEicSKSACAiccDlwI6uq74xxpjOdNp1o6pNInIv8D4QDjyrqjtF5C53/ZOq+oWIvAdsA7zAM6q6Q0QygTfEuZVfBPCCqr7XXR/GGGPMqUS1bXd74GVnZ2tOjg25N8YYf4nIJlXNbm+dXRlrjDEhzoLeGGNCnAW9McaEOAt6Y4wJcRb0xhgT4izojTEmxFnQG2NMiLOgN8aYEGdBb4wxIc6C3hhjQpwFvTHGhDgLemOMCXEW9MYYE+Is6I0xJsRZ0BtjTIizoDfGmBBnQW+MMSHOgt4YY0KcBb0xxoQ4C3pjjAlxFvTGGBPi/Ap6EVksIntEZL+IPNBBmfkislVEdorIqjPZ1hhjTPeJ6KyAiIQDjwOLgAJgo4i8raq7fMr0A54AFqtqnoik+butMcaY7uVPi34GsF9Vc1W1AXgJuKZNmVuB11U1D0BVi85gW2OMMd3In6BPB/J9Xhe4y3yNBpJEZKWIbBKRb5zBtgCIyFIRyRGRnOLiYv9qb4wxplOddt0A0s4ybWc/04BLgT7AehHZ4Oe2zkLVZcAygOzs7HbLGGOMOXP+BH0BMMTndQZQ2E6ZElWtBqpFZDUw2c9tjTHGdCN/um42AqNEZISIRAE3A2+3KfMWcImIRIhILHAR8IWf2xpjjOlGnbboVbVJRO4F3gfCgWdVdaeI3OWuf1JVvxCR94BtgBd4RlV3ALS3bTd9FmOMMe0Q1d7XHZ6dna05OTmBroYxxgQNEdmkqtntrbMrY40xJsRZ0BtjTIizoDfGmBBnQW+MMSHOgt4YY0KcBb0xxoQ4C3pjjAlxFvTGGBPiLOiNMSbEWdAbY0yIs6A3xpgQZ0FvjDEhzoLeGGNCnAW9McaEOAt6Y4wJcRb0xhgT4izojTEmxFnQG2NMiLOgN8aYEGdBb4wxIc6C3hhjQpxfQS8ii0Vkj4jsF5EH2lk/X0TKRWSr+/eQz7pDIrLdXZ7TlZU3xhjTuYjOCohIOPA4sAgoADaKyNuquqtN0TWq+pUOdrNAVUvOrarGGGPOhj8t+hnAflXNVdUG4CXgmu6tljHGmK7iT9CnA/k+rwvcZW3NEpHPReRdEZngs1yBD0Rkk4gs7ehNRGSpiOSISE5xcbFflTfGGNO5TrtuAGlnmbZ5vRkYpqpVInIl8CYwyl03R1ULRSQN+FBEdqvq6lN2qLoMWAaQnZ3ddv/GGGPOkj8t+gJgiM/rDKDQt4CqVqhqlft8ORApIv3d14XuYxHwBk5XkDHGmB7iT9BvBEaJyAgRiQJuBt72LSAiA0VE3Ocz3P2WikiciCS4y+OAy4EdXfkBjDHGnF6nXTeq2iQi9wLvA+HAs6q6U0Tuctc/CXwNuFtEmoBa4GZVVREZALzhfgdEAC+o6nvd9FmMMca0Q1R7X3d4dna25uTYkHtjjPGXiGxS1ez21tmVscachzxeT6CrYHqQP6NujDFBrLS2lD1le9h9fDe7y3azp2wPhyoOMaLvCBYOXcilQy9lfMp43C5WE4Ks68aYEOHxesirzHNCvWw3u4/vZm/ZXoprT16XMihuEGOSxzAicQQ7S3ay6dgmPOphQOyAltDPGpBFZFhkAD+JORun67qxFr0xQaimsYZ9J/axp2xPS2t93/F91DbVAhAhEYzsN5JZg2cxNnksY5PHMjppNInRia32c6LuBKsKVvFx3se8vu91Xtz9In2j+jJ/yHwWDl3I7MGz6RPRJxAfsUc0ehvZU7aHAycOEBEWQVR4FNHh0USFRxEV5jyPDI90loVFOcvdMpFhkUHzK8ha9CakNXgayDmaw4r8FRTVFJHcJ5mUmBRS+qSQHNP6ed+ovr3yf9yS2hKnhe52u+wu282XFV+i7nWLCVEJjE0ey5ikMYxJHsPY5LFkJmYSFR51Ru9T01jD+sL1fJz3MasKVlHRUEFMeAyzB8/m0mGXMi9j3ilfFMGmprGGz4s/Z0vRFjYXbWZb8baWL8ezccqXgftF0HZ58xfD6cpEhUURHxXPVZlXnVVdTteit6A3Iae8vpzVBatZmb+StYVrqW6spk9EH9Lj0ymrK+N43fGWkPQVGRZJckyy8wXQJ6X1F4L7uvl5UnQS4WHhXVpvj9fDlxVftnS7NLfWS+tKW8qkx6czJskJ8+ZQHxQ3qMu/oBq9jWw6tolP8j7hk7xPOFZzjHAJJ3tANguHLmTh0IUMjBvYpe/ZHUprS1tCffOxzewu241HPQjCmOQxZKVlMXXAVMYmjUVRGjwNNHgaqPfU0+BtaPW60dvoLHeXNXgbWr2u99TT6Gk87bZtyzR5m1rVt3+f/qy4ccVZfVYLehPy8iryWJG/gpX5K9lStAWPekjtk8q8IfNYMGQBMwbOICYiBnAC9Xj9cUprSymrK6O0rvTk89rS1q/rSk/5nxFAEJJiklqC3/fXQdvH5JjkU1rXNY017D2+t6XbZU/ZHvYd30edpw6AiLAIRvUb1RLmY5LGMDp5NH2j+nb7sWxLVdlZupNP8j7h47yPyS3PBWBCyoSWfv3MxMyA/xpSVQoqC9hUtMkJ92ObOVRxCHBa3pNSJ5GVlkXWgCwmp04mISohoPUF8Kq31ZdBk7fprL9ALehNyPF4PWwv2c7K/JWsyF/REj6jk0Yzf8h8FgxZwPiU8YTJuY0gVlUqGipafQm0el578ouitK60w26AhMgE55dATBJldWXkVeS1/KroG9WXccnjGJPsdL2MSRpDZmImkeG984TowfKDLS39bSXbABjedzgLhi7g0qGXMqn/pHM+7v7weD3sPb63pbW+pWhLy4nnvlF9mZo2lawBWWSlZTE+ZfwZd2UFGwt6ExJqm2pZX7ielfkrWVWwirK6MiIkgmkDp7FgyALmZcwjIyEjoHWsaaxp+SXg+yXQsqyujL5RfVtOkI5NHsuA2AEBbw2fraKaIlbkreDjvI/ZeHQjTdpEap9UFgxxQn/6wOld9oVV11TH9pLtLaG+tXgr1Y3VgDOaqDnUs9KyyOyX2SNfNr2JBb0JWiW1JazKX8XK/JWsP7Keek89CZEJXJxxMQuGLGBO+pyAdGeYU1U0VLC6YDWf5H3Cp4c/pbaploTIBC7JuISFQxdySfolxEbG+r2/E3Un2FK0hS1FW9hUtIldpbtautEu6HcB0wZMc1rtaVkMih/UXR8raFjQm6Chquw/sZ+V+StZmb+ypWsgPT6dBUMWMH/IfBvnHQTqmurYcGQDn+R9wsr8lRyvP05UWBSzBs9i4dCFzB8yn+SY5JbyqsqR6iNsOnayf/1A+QHAOUk+sf/EllCfkjYl6Ef/dIfzJuiPVh8N6p/B56tGbyObj21u6W8/XHUYgEn9JzF/yHzmD5nPqH6j7L9rkGryNrGlaEtLv35hdSFhEsaU1CnMHDSTgxUH2XxsM8dqjgEQHxnPlLQpLSdOJ6RMaDmRbjp2XgS9x+th3svziA6LZtbgWcwePJtZg2eRFJPUTbU056KyoZK1h9eyIn8Faw6vobKhkujwaGYOmsn8IfOZlzGP1NjUQFfTdDFVZXfZbj7Jd0bw7Du+j7Q+aWQNyGJq2lSmDZjGBf0u6PKhq+eD8yLoGzwN/CX3L6w9vJYNRzZQ0VCBIIxLGcecwXOYPXg2k1Mn99qRDOeDw1WHW7pkco7m0KRNJMckMzdjLguGLGDmoJln1Idrgl9VQxVxkXH2a60LnBdB78vj9bCzdCfrCtexrnAd24q34VEPsRGxzBg0g9mDZzNn8ByG9h3ahbXufSobKmnyNuFRD6ra7qMXL16v13nU9v/a3R7F4/Wcdrvmv8LqQlbmr2Tv8b0AZCZmtgyBnNR/krXejOkC513Qt1XRUMHGIxtZW7iWdYXrWvqAM+IzmD14NrPTZzNj4IxecQHF2fB4PXxZ+WXL5fHNj75XVAZSmISRlZbV0t8+rO+wQFfJmJBz3ge9L1UlrzKPtYfXsr5wPX89+ldqm2oJl3Amp05m1uBZzBk8h/Ep43tlS7PtFZV7y/ay9/jeU66oHJ00mpH9RhIdHk2YhLX8hUs4ItLuYxhhnZb1Xd/qjzDCwpzHttvFR8YTHxUf4CNnTGizoD+NRk8jW4u3tnTz7CrdBUBidCIzB81kzuA5zBo8q8fn9VDVlsms9hw/2VL3ncyq+cIb38vke/MVlcaY7mNBfwbK6srYULiBtYVOi7/5kuqRic6Ur3PS5zBtwLQunbq1ydvUMplVS/fL8T2U1ZW1lMmIz2gV6sF+RaUxpmtZ0J8lVWXfiX2sO+y09jcd20SDt4GosCiyBmS1tPZHJ432O3CrG6vZe3xvS6jvKdvDvhP7qPfUA87FIaOSRrWacnZ00uigPX9gjOkZFvRdpLapls3HNre09vef2A84U4vOHjyb2YNnM3PQTFL6pKCqFNUUtXS7NAd7XmVey/76RfdzwjzpZEt9eOJwu+rTGHPGzjnoRWQx8EsgHHhGVR9ps34+8BZw0F30uqr+yJ9t29Nbg76to9VHWV+4nnWF61h/ZD3l9eWA081TWlfKifoTLWWHJgxt1e0yOmm0db0YY7rMOQW9iIQDe4FFQAGwEbhFVXf5lJkP3KeqXznTbdsTLEHvy+P18EXZF6w9vJatxVsZEDugVddLXGRcoKtojAlh53rP2BnAflXNdXf2EnANcNqw7oJtg0p4WDgT+09kYv+Jga6KMca04s+EzelAvs/rAndZW7NE5HMReVdEJpzhtojIUhHJEZGc4uLi9ooYY4w5C/4EfXudyG37ezYDw1R1MvC/wJtnsK2zUHWZqmaranZqqk1mZYwxXcWfoC8Ahvi8zgAKfQuoaoWqVrnPlwORItLfn22NMcZ0L3+CfiMwSkRGiEgUcDPwtm8BERko7vAREZnh7rfUn22NMcZ0r05Pxqpqk4jcC7yPM0TyWVXdKSJ3ueufBL4G3C0iTUAtcLM6w3na3babPosxxph22AVTxhgTAk43vPL8uk26McachyzojTEmxPXKrhsRKQa+PMvN+wMlXVidYGbHojU7Hq3Z8TgpFI7FMFVtd2x6rwz6cyEiOR31U51v7Fi0ZsejNTseJ4X6sbCuG2OMCXEW9MYYE+JCMeiXBboCvYgdi9bseLRmx+OkkD4WIddHb4wxprVQbNEbY4zxYUFvjDEhLiiDXkSeFZEiEdnRwXoRkV+JyH4R2SYiWT1dx54kIotFZI/7eR9oZ32iiPzZvV/AThG5IxD17CmdHQ+3zHwR2eoej1U9Xcee4s+xcMtNFxGPiHytJ+vX0/z4f+Vv3MzYJiLrRGRyIOrZ5VQ16P6AuUAWsKOD9VcC7+LMhz8T+Gug69yNxyIcOABkAlHA58D4NmX+Dfip+zwVKAOiAl33AB6Pfjh3ORvqvk4LdL0DdSx8yn0CLAe+Fuh6B/jfxmwgyX2+JFSyIyhb9Kq6GiesOnIN8Ht1bAD6icignqldj2u5XaOqNgDNt2v0pUCCO5V0PM6xa+rZavYYf47HrTg3sM8DUNWiHq5jT/HnWAD8A/AaEKrHoVmnx0NV16nqcfflBpx7aAS9oAx6P/h9C8MQ4M9n/TUwDuemL9uBf1RVb89Ur8f5czxGA0kislJENonIN3qsdj2r02MhIunAdcCTPVivQDnTXPh7nJ6BoOfPzcGDkd+3MAwB/nzWK4CtwEJgJPChiKxR1Ypurlsg+HM8IoBpwKVAH2C9iGxQ1b3dXbke5s+xeAy4X1U97r2DQpnfuSAiC3CC/uJurVEPCdWgP59uYejPZ70DeESdjsf9InIQGAt81jNV7FH+HI8CoERVq4FqEVkNTAZCLej9ORbZwEtuyPcHrhSRJlV9s0dq2LP8ygURuRB4BliiqqU9VLduFapdN28D33BH38wEylX1SKAr1U38uV1jHk7rFREZAIwBcnu0lj3Hn+PxFnCJiESISCxwEfBFD9ezJ3R6LFR1hKoOV9XhwKvAPSEa8uDfbVGHAq8DfxtKv/CCskUvIi8C84H+IlIAPAxEQsutDZfjjLzZD9TgtGhDkvp3q8cfA8+LyHacn6/3q2qwT8naLn+Oh6p+ISLvAdsAL/CMqrY7VDeY+flv47zh5/F4CEgBnnB/5TRpCMxqaVMgGGNMiAvVrhtjjDEuC3pjjAlxFvTGGBPiLOiNMSbEWdAbY0yIs6A3xpgQZ0FvTiEiV59uStvTbDdYRF7tjjp18r7LRaSf+3dPF+1zpYgE3fhpEbldRIZLO/MZiMhcEdksIk1tpyMWkW+KyD7375sd7DtZRD50y3woIkk+6x50p/7dIyJX+CyfJiLb3XW/aq9epvtZ0JtTqOrbqvrIWWxXqKo9Np+5e+VzmKpeqaoncKYf7pKg7woi0mMXJIpIuoj8FhiKMz9LexdD5QG3Ay+02TYZ56LDi3BmeHzYN8R9PAB8rKqjgI/d14jIeJyrTCcAi3EuNgp3t/kNsBQY5f4tPvtPac6WBf15xG3p7RaRZ0Rkh4j8n4hcJiJr3VbaDLfc7SLya/f5825LbJ2I5J7uxhTu/nf47ONNcW54clBE7hWRfxaRLSKywQ2X5pbzY+7+d/jU4T9E5D6ffe9w9z9cRL4QkSeAzcAQETkkIv2BR4CR4txQ5FER+YOIXOOzj/8Tkas7qHsfEXlJnBtO/AlnsrPmdZeLyHq3NfyKiMS7y6e79f5cRD4TkQT3c78iIn8GPhCROHFulLPR/ezX+ByrNe4+N4vIbHf5IBFZ7X6GHSJyyenq0ExVD+Pcd+DvcEL37rafUVUPqWrz1cC+rgA+VNUyd4reD2k/kK8Bfuc+/x1wrc/yl1S1XlUP4lyRPkOcqcH7qup6d56l3/tsY3qQBf355wLgl8CFOBOb3YrTArwPJyjaM8gt8xWcMPXXRHf/M4D/B9So6lRgPeA7NXCcqs7GaY0/68d+x+Dcb2Cqqn7ps/wB4ICqTlHV7+FMTHUHOHfZwrmpxPIO9nm3W78L3bpOc7frD/w7cJmqZgE5wD+LM1fKn3CmfJ4MXAbUuvuaBXxTVRcC3wc+UdXpwALgURGJw5n7fZG7z5uAX7nb3gq8r6pTcCZa29pRHXwrLyKDgf90j9+fgMf9OI7N/J2+d0DznFHuY1on26e7zzvbr+lmQTnXjTknB1V1O4CI7MT5Ka7izIMzvINt3nTnr98lzqRo/lqhqpVApYiUA392l2/H+aJp9iI4N5QRkb4i0q+T/X7p3lDmtFR1lYg8LiJpwPXAa6ra0Q1X5uKGrapuE5Ft7vKZwHhgrdu9HIXzRTUGOKKqG91tKgDcMh+qavONcS4Hrvb5dRKD071SCPxaRKYAHpw58sGZeOtZEYnEOe5bRWReB3Xw/ayFwJ0icjuwBvhjZ8fHx7lO693R9ufTdOG9mgX9+afe57nX57WXjv89+G5zJifT/H2vtv/zK84dsHx/ccb4PK8+gzr8AfgbnO6Mv+ukbHshJDjBfUurhc5Uth2Flm/9BLhBVfe02f4/gGM4rfYwoA5avuzmAlcBfxCRR4Hj7dWh3Q+g+nxnZdpRgDNJYLMMYGU75Y6JyCBVPeJ2yzTfkaqj6X8LaH2HplCeLrxXs64b0xvcBCAiF+NMKV0OHMK5LzDi3Nx9hB/7qQQS2ix7HvgugKruPM22q3G+EBCRiZz8xbEBmCMiF7jrYkVkNLAbGCwi093lCdL+ydf3gX8QtykuIlPd5Yk4vwi8wN/izKaIiAwDilT1aeC3OMegozp0lfeBy0UkSZyTsJe7yxCRn4jIdW65t4HmETnfxJnuuXn5zSISLSIjcE66fuZ271SKyEz383/DZxvTgyzoTW9wXETW4YwU+Xt32WtAsohsxek/73RucPcmEWvdk5iPusuO4cw1/1wnm/8GiHe7bP4V96YsqlqMM1LlRXfdBmCse8/Rm4D/FZHPcU5gxrSz3x/jTKG9TZwT1T92lz8BfFNENuB02zT/CpiP0y+/BbgB+GVHdejseLTlnjwuAL4OPOV23eF2M/0Yp9toI/Ajn66nScBR9/kjwCIR2Qcscl83f4G+jHPD9feA76iqx93mbpxzJftxbswdErfmCzY2TbEJKBFZCdynqjndtP9YnHMCWe4vBXMGROR9Vb2i85KmN7MWvQlZInIZThfL/1rInx0L+dBgLXpzxkRkEs5JTl/1qnpRIOpzJsS5avOnbRYfVNXr2itvTCiwoDfGmBBnXTfGGBPiLOiNMSbEWdAbY0yIs6A3xpgQ9/8DOmBb+MV7QoMAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "training = []\n",
    "testing = []\n",
    "oot = []\n",
    "for i in range(1,11,1):\n",
    "    \n",
    "    min_imp_decrease = 0.00011 - (i*0.00001)\n",
    "    model_output = model_execution(model_name = 'RF',\n",
    "                                   algorithm = RandomForestClassifier(min_impurity_decrease = min_imp_decrease,\n",
    "                                                                      n_estimators=20),\n",
    "                                   X = X_trntst, Y = Y_trntst,\n",
    "                                   X_oot = X_oot_orig, Y_oot = Y_oot,\n",
    "                                   print_bool=False)\n",
    "    results = model_output[1]['FDR3']\n",
    "\n",
    "    results_mean_trn = results['trn'].mean()\n",
    "    results_mean_tst = results['tst'].mean()\n",
    "    results_mean_oot = results['oot'].mean()\n",
    "    print('loop', 'trn', 'tst', 'oot', i, results_mean_trn, results_mean_tst, results_mean_oot)\n",
    "    training.append(results_mean_trn)\n",
    "    testing.append(results_mean_tst)\n",
    "    oot.append(results_mean_oot)\n",
    "\n",
    "table=pd.DataFrame({'min_impurity_decrease * 10,000': range(1,len(training)+1),'training':training,'testing':testing,'oot':oot})\n",
    "table['min_impurity_decrease * 10,000'] = (0.00011 - (table['min_impurity_decrease * 10,000']*0.00001)) * 10_000\n",
    "table.set_index('min_impurity_decrease * 10,000',inplace=True)\n",
    "table.plot().invert_xaxis()\n",
    "plt.savefig('RandomForest_min_impurity_decrease.pdf', format='pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.8003273322422259 0.7397769516728625 0.553072625698324\n",
      "1 0.7801652892561983 0.7781818181818182 0.547486033519553\n",
      "2 0.7860696517412935 0.7220216606498195 0.5139664804469274\n",
      "3 0.7664 0.807843137254902 0.5418994413407822\n",
      "4 0.7983333333333333 0.7285714285714285 0.4972067039106145\n",
      "5 0.7768860353130016 0.7704280155642024 0.5027932960893855\n",
      "6 0.7802907915993538 0.7854406130268199 0.553072625698324\n",
      "7 0.7783171521035599 0.7633587786259542 0.44692737430167595\n",
      "8 0.7934426229508197 0.7481481481481481 0.5586592178770949\n",
      "9 0.7937293729372937 0.7445255474452555 0.5251396648044693\n",
      "trn    0.785396\n",
      "tst    0.758830\n",
      "oot    0.524022\n",
      "dtype: float64\n",
      "CPU times: total: 1min 56s\n",
      "Wall time: 6.53 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">Trn</th>\n",
       "      <th colspan=\"2\" halign=\"left\">Tst</th>\n",
       "      <th colspan=\"2\" halign=\"left\">OOT</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NVARS</th>\n",
       "      <th>Parameters</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"11\" valign=\"top\">10</th>\n",
       "      <th>min_split_gain=3000</th>\n",
       "      <td>0.524156</td>\n",
       "      <td>0.034774</td>\n",
       "      <td>0.507332</td>\n",
       "      <td>0.042278</td>\n",
       "      <td>0.220670</td>\n",
       "      <td>0.013233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min_split_gain=1000</th>\n",
       "      <td>0.554388</td>\n",
       "      <td>0.041244</td>\n",
       "      <td>0.541175</td>\n",
       "      <td>0.032016</td>\n",
       "      <td>0.240223</td>\n",
       "      <td>0.007901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min_split_gain=500</th>\n",
       "      <td>0.558901</td>\n",
       "      <td>0.009521</td>\n",
       "      <td>0.562043</td>\n",
       "      <td>0.021090</td>\n",
       "      <td>0.239665</td>\n",
       "      <td>0.015900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min_split_gain=300</th>\n",
       "      <td>0.611886</td>\n",
       "      <td>0.026274</td>\n",
       "      <td>0.584399</td>\n",
       "      <td>0.034896</td>\n",
       "      <td>0.329609</td>\n",
       "      <td>0.080571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min_split_gain=100</th>\n",
       "      <td>0.681361</td>\n",
       "      <td>0.016564</td>\n",
       "      <td>0.662261</td>\n",
       "      <td>0.032503</td>\n",
       "      <td>0.421788</td>\n",
       "      <td>0.116003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min_child_samples=100, min_split_gain=0.1</th>\n",
       "      <td>0.930131</td>\n",
       "      <td>0.005161</td>\n",
       "      <td>0.788126</td>\n",
       "      <td>0.019355</td>\n",
       "      <td>0.493296</td>\n",
       "      <td>0.051205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min_split_gain=0.1</th>\n",
       "      <td>0.953742</td>\n",
       "      <td>0.006348</td>\n",
       "      <td>0.770856</td>\n",
       "      <td>0.024112</td>\n",
       "      <td>0.455866</td>\n",
       "      <td>0.042644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min_child_samples=30, min_split_gain=0.1</th>\n",
       "      <td>0.953960</td>\n",
       "      <td>0.006071</td>\n",
       "      <td>0.771845</td>\n",
       "      <td>0.024595</td>\n",
       "      <td>0.468715</td>\n",
       "      <td>0.053808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min_split_gain=0.001</th>\n",
       "      <td>0.954213</td>\n",
       "      <td>0.007347</td>\n",
       "      <td>0.772663</td>\n",
       "      <td>0.034079</td>\n",
       "      <td>0.452514</td>\n",
       "      <td>0.047841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min_split_gain=0.01</th>\n",
       "      <td>0.960499</td>\n",
       "      <td>0.006184</td>\n",
       "      <td>0.750139</td>\n",
       "      <td>0.026681</td>\n",
       "      <td>0.455307</td>\n",
       "      <td>0.058961</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>83 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      Trn                 Tst  \\\n",
       "                                                     mean       std      mean   \n",
       "NVARS Parameters                                                                \n",
       "10    min_split_gain=3000                        0.524156  0.034774  0.507332   \n",
       "      min_split_gain=1000                        0.554388  0.041244  0.541175   \n",
       "      min_split_gain=500                         0.558901  0.009521  0.562043   \n",
       "      min_split_gain=300                         0.611886  0.026274  0.584399   \n",
       "      min_split_gain=100                         0.681361  0.016564  0.662261   \n",
       "...                                                   ...       ...       ...   \n",
       "      min_child_samples=100, min_split_gain=0.1  0.930131  0.005161  0.788126   \n",
       "      min_split_gain=0.1                         0.953742  0.006348  0.770856   \n",
       "      min_child_samples=30, min_split_gain=0.1   0.953960  0.006071  0.771845   \n",
       "      min_split_gain=0.001                       0.954213  0.007347  0.772663   \n",
       "      min_split_gain=0.01                        0.960499  0.006184  0.750139   \n",
       "\n",
       "                                                                OOT            \n",
       "                                                      std      mean       std  \n",
       "NVARS Parameters                                                               \n",
       "10    min_split_gain=3000                        0.042278  0.220670  0.013233  \n",
       "      min_split_gain=1000                        0.032016  0.240223  0.007901  \n",
       "      min_split_gain=500                         0.021090  0.239665  0.015900  \n",
       "      min_split_gain=300                         0.034896  0.329609  0.080571  \n",
       "      min_split_gain=100                         0.032503  0.421788  0.116003  \n",
       "...                                                   ...       ...       ...  \n",
       "      min_child_samples=100, min_split_gain=0.1  0.019355  0.493296  0.051205  \n",
       "      min_split_gain=0.1                         0.024112  0.455866  0.042644  \n",
       "      min_child_samples=30, min_split_gain=0.1   0.024595  0.468715  0.053808  \n",
       "      min_split_gain=0.001                       0.034079  0.452514  0.047841  \n",
       "      min_split_gain=0.01                        0.026681  0.455307  0.058961  \n",
       "\n",
       "[83 rows x 6 columns]"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# LGBM\n",
    "model_execution(model_name = 'LGBM',\n",
    "                algorithm = lgb.LGBMClassifier(min_split_gain = 1, min_child_samples = 100,\n",
    "                                               n_estimators = 1000, num_leaves = 10, max_depth=2),\n",
    "                X = X_trntst, Y = Y_trntst,\n",
    "                X_oot = X_oot_orig, Y_oot = Y_oot)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loop trn tst oot 1 0.7521351751387526 0.7339820622922562 0.4094972067039106\n",
      "loop trn tst oot 2 0.7905147881010672 0.7559248546900954 0.5245810055865923\n",
      "loop trn tst oot 3 0.8064650997577122 0.7863479522610545 0.5178770949720671\n",
      "loop trn tst oot 4 0.8207935528187396 0.7831057918317866 0.5217877094972068\n",
      "loop trn tst oot 5 0.8320267818634365 0.7654716455526697 0.5078212290502793\n",
      "loop trn tst oot 6 0.8308660639190828 0.7681370707257043 0.5145251396648045\n",
      "loop trn tst oot 7 0.830387011886273 0.7697114136075573 0.5290502793296089\n",
      "loop trn tst oot 8 0.8384113224766647 0.7568022448424072 0.5351955307262569\n",
      "loop trn tst oot 9 0.8336227616209408 0.7748454260536748 0.46983240223463696\n",
      "loop trn tst oot 10 0.8305791783052783 0.7787159797037433 0.5111731843575419\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "training = []\n",
    "testing = []\n",
    "oot = []\n",
    "for i in range(1,11,1):\n",
    "\n",
    "    model_output = model_execution(model_name = 'LGBM',\n",
    "                                   algorithm = lgb.LGBMClassifier(min_split_gain = 1, min_child_samples = 100,\n",
    "                                               n_estimators = 1000, num_leaves = 10, max_depth=i),\n",
    "                                   X = X_trntst, Y = Y_trntst,\n",
    "                                   X_oot = X_oot_orig, Y_oot = Y_oot,\n",
    "                                   print_bool=False)\n",
    "    results = model_output[1]['FDR3']\n",
    "\n",
    "    results_mean_trn = results['trn'].mean()\n",
    "    results_mean_tst = results['tst'].mean()\n",
    "    results_mean_oot = results['oot'].mean()\n",
    "    print('loop', 'trn', 'tst', 'oot', i, results_mean_trn, results_mean_tst, results_mean_oot)\n",
    "    training.append(results_mean_trn)\n",
    "    testing.append(results_mean_tst)\n",
    "    oot.append(results_mean_oot)\n",
    "\n",
    "table=pd.DataFrame({'max_depth': range(1,len(training)+1),'training':training,'testing':testing,'oot':oot})\n",
    "table.set_index('max_depth',inplace=True) \n",
    "table.plot()\n",
    "plt.savefig('LGBM_max_depth.pdf', format='pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.7362459546925566 0.7480916030534351 0.5363128491620112\n",
      "1 0.734959349593496 0.7509433962264151 0.40782122905027934\n",
      "2 0.7819672131147541 0.7148148148148148 0.5083798882681564\n",
      "3 0.7320819112627986 0.7585034013605442 0.547486033519553\n",
      "4 0.7479935794542536 0.7159533073929961 0.547486033519553\n",
      "5 0.7439613526570048 0.7760617760617761 0.4748603351955307\n",
      "6 0.7411575562700965 0.7596899224806202 0.4748603351955307\n",
      "7 0.7475409836065574 0.7333333333333333 0.4134078212290503\n",
      "8 0.7520525451559934 0.7158671586715867 0.4301675977653631\n",
      "9 0.7539184952978056 0.6983471074380165 0.37988826815642457\n",
      "trn    0.747188\n",
      "tst    0.737161\n",
      "oot    0.472067\n",
      "dtype: float64\n",
      "CPU times: total: 8min 37s\n",
      "Wall time: 3min 35s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">Trn</th>\n",
       "      <th colspan=\"2\" halign=\"left\">Tst</th>\n",
       "      <th colspan=\"2\" halign=\"left\">OOT</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NVARS</th>\n",
       "      <th>Parameters</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"11\" valign=\"top\">10</th>\n",
       "      <th>hidden_layer_sizes=(1, 1)</th>\n",
       "      <td>0.502670</td>\n",
       "      <td>0.251948</td>\n",
       "      <td>0.516264</td>\n",
       "      <td>0.260160</td>\n",
       "      <td>0.273743</td>\n",
       "      <td>0.111141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha=0.01, hidden_layer_sizes=(1, 1)</th>\n",
       "      <td>0.515478</td>\n",
       "      <td>0.253062</td>\n",
       "      <td>0.508224</td>\n",
       "      <td>0.254663</td>\n",
       "      <td>0.290503</td>\n",
       "      <td>0.113853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha=1, hidden_layer_sizes=(15, 15)</th>\n",
       "      <td>0.618112</td>\n",
       "      <td>0.011449</td>\n",
       "      <td>0.630631</td>\n",
       "      <td>0.029666</td>\n",
       "      <td>0.226816</td>\n",
       "      <td>0.003906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha=0.01, hidden_layer_sizes=(20, 20), learning_rate_init=0.1</th>\n",
       "      <td>0.634507</td>\n",
       "      <td>0.019014</td>\n",
       "      <td>0.632911</td>\n",
       "      <td>0.024630</td>\n",
       "      <td>0.374860</td>\n",
       "      <td>0.080332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hidden_layer_sizes=5</th>\n",
       "      <td>0.654032</td>\n",
       "      <td>0.032859</td>\n",
       "      <td>0.657394</td>\n",
       "      <td>0.033828</td>\n",
       "      <td>0.437989</td>\n",
       "      <td>0.105743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha=0.01, hidden_layer_sizes=(10, 10)</th>\n",
       "      <td>0.710103</td>\n",
       "      <td>0.011161</td>\n",
       "      <td>0.709848</td>\n",
       "      <td>0.021295</td>\n",
       "      <td>0.528492</td>\n",
       "      <td>0.038812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hidden_layer_sizes=(10, 10)</th>\n",
       "      <td>0.713078</td>\n",
       "      <td>0.012139</td>\n",
       "      <td>0.714570</td>\n",
       "      <td>0.021527</td>\n",
       "      <td>0.531844</td>\n",
       "      <td>0.021524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha=0.01, hidden_layer_sizes=(15, 15), learning_rate_init=0.01</th>\n",
       "      <td>0.719660</td>\n",
       "      <td>0.009008</td>\n",
       "      <td>0.702218</td>\n",
       "      <td>0.021441</td>\n",
       "      <td>0.553073</td>\n",
       "      <td>0.008734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hidden_layer_sizes=(15, 15)</th>\n",
       "      <td>0.735386</td>\n",
       "      <td>0.017033</td>\n",
       "      <td>0.718689</td>\n",
       "      <td>0.022686</td>\n",
       "      <td>0.505028</td>\n",
       "      <td>0.050671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hidden_layer_sizes=(25, 25)</th>\n",
       "      <td>0.747188</td>\n",
       "      <td>0.014234</td>\n",
       "      <td>0.737161</td>\n",
       "      <td>0.025187</td>\n",
       "      <td>0.472067</td>\n",
       "      <td>0.062056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hidden_layer_sizes=(20, 20)</th>\n",
       "      <td>0.748437</td>\n",
       "      <td>0.022111</td>\n",
       "      <td>0.723648</td>\n",
       "      <td>0.027453</td>\n",
       "      <td>0.500559</td>\n",
       "      <td>0.061717</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                               Trn            \\\n",
       "                                                              mean       std   \n",
       "NVARS Parameters                                                               \n",
       "10    hidden_layer_sizes=(1, 1)                           0.502670  0.251948   \n",
       "      alpha=0.01, hidden_layer_sizes=(1, 1)               0.515478  0.253062   \n",
       "      alpha=1, hidden_layer_sizes=(15, 15)                0.618112  0.011449   \n",
       "      alpha=0.01, hidden_layer_sizes=(20, 20), learni...  0.634507  0.019014   \n",
       "      hidden_layer_sizes=5                                0.654032  0.032859   \n",
       "      alpha=0.01, hidden_layer_sizes=(10, 10)             0.710103  0.011161   \n",
       "      hidden_layer_sizes=(10, 10)                         0.713078  0.012139   \n",
       "      alpha=0.01, hidden_layer_sizes=(15, 15), learni...  0.719660  0.009008   \n",
       "      hidden_layer_sizes=(15, 15)                         0.735386  0.017033   \n",
       "      hidden_layer_sizes=(25, 25)                         0.747188  0.014234   \n",
       "      hidden_layer_sizes=(20, 20)                         0.748437  0.022111   \n",
       "\n",
       "                                                               Tst            \\\n",
       "                                                              mean       std   \n",
       "NVARS Parameters                                                               \n",
       "10    hidden_layer_sizes=(1, 1)                           0.516264  0.260160   \n",
       "      alpha=0.01, hidden_layer_sizes=(1, 1)               0.508224  0.254663   \n",
       "      alpha=1, hidden_layer_sizes=(15, 15)                0.630631  0.029666   \n",
       "      alpha=0.01, hidden_layer_sizes=(20, 20), learni...  0.632911  0.024630   \n",
       "      hidden_layer_sizes=5                                0.657394  0.033828   \n",
       "      alpha=0.01, hidden_layer_sizes=(10, 10)             0.709848  0.021295   \n",
       "      hidden_layer_sizes=(10, 10)                         0.714570  0.021527   \n",
       "      alpha=0.01, hidden_layer_sizes=(15, 15), learni...  0.702218  0.021441   \n",
       "      hidden_layer_sizes=(15, 15)                         0.718689  0.022686   \n",
       "      hidden_layer_sizes=(25, 25)                         0.737161  0.025187   \n",
       "      hidden_layer_sizes=(20, 20)                         0.723648  0.027453   \n",
       "\n",
       "                                                               OOT            \n",
       "                                                              mean       std  \n",
       "NVARS Parameters                                                              \n",
       "10    hidden_layer_sizes=(1, 1)                           0.273743  0.111141  \n",
       "      alpha=0.01, hidden_layer_sizes=(1, 1)               0.290503  0.113853  \n",
       "      alpha=1, hidden_layer_sizes=(15, 15)                0.226816  0.003906  \n",
       "      alpha=0.01, hidden_layer_sizes=(20, 20), learni...  0.374860  0.080332  \n",
       "      hidden_layer_sizes=5                                0.437989  0.105743  \n",
       "      alpha=0.01, hidden_layer_sizes=(10, 10)             0.528492  0.038812  \n",
       "      hidden_layer_sizes=(10, 10)                         0.531844  0.021524  \n",
       "      alpha=0.01, hidden_layer_sizes=(15, 15), learni...  0.553073  0.008734  \n",
       "      hidden_layer_sizes=(15, 15)                         0.505028  0.050671  \n",
       "      hidden_layer_sizes=(25, 25)                         0.472067  0.062056  \n",
       "      hidden_layer_sizes=(20, 20)                         0.500559  0.061717  "
      ]
     },
     "execution_count": 267,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# NN\n",
    "model_execution(model_name = 'NN',\n",
    "                algorithm = MLPClassifier(hidden_layer_sizes=(25, 25)),\n",
    "                X = X_trntst, Y = Y_trntst,\n",
    "                X_oot = X_oot_orig, Y_oot = Y_oot)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "training = []\n",
    "testing = []\n",
    "oot = []\n",
    "for i in range(5,45,5):\n",
    "\n",
    "    model_output = model_execution(model_name = 'NN',\n",
    "                                   algorithm = MLPClassifier(hidden_layer_sizes=(i, i)),\n",
    "                                   X = X_trntst, Y = Y_trntst,\n",
    "                                   X_oot = X_oot_orig, Y_oot = Y_oot,\n",
    "                                   print_bool=False)\n",
    "    results = model_output[1]['FDR3']\n",
    "\n",
    "    results_mean_trn = results['trn'].mean()\n",
    "    results_mean_tst = results['tst'].mean()\n",
    "    results_mean_oot = results['oot'].mean()\n",
    "    print('loop', 'trn', 'tst', 'oot', i, results_mean_trn, results_mean_tst, results_mean_oot)\n",
    "    training.append(results_mean_trn)\n",
    "    testing.append(results_mean_tst)\n",
    "    oot.append(results_mean_oot)\n",
    "\n",
    "table=pd.DataFrame({'layer_sizes_(i_i)': range(1,len(training)+1),'training':training,'testing':testing,'oot':oot})\n",
    "table['layer_sizes_(i_i)'] = table['layer_sizes_(i_i)'] * 5\n",
    "table.set_index('layer_sizes_(i_i)',inplace=True) \n",
    "table.plot()\n",
    "plt.savefig('NN_layer_sizes_(i_i).pdf', format='pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Network on PCA (not used)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# # NN on pc's\n",
    "# model_execution(model_name = 'NN_PCs',\n",
    "#                 algorithm = MLPClassifier(hidden_layer_sizes=(2)),\n",
    "#                 X = X_trntst_pca, Y = Y_trntst,\n",
    "#                 X_oot = X_oot_orig_pca, Y_oot = Y_oot)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boosting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# # GBC\n",
    "# model_execution(model_name = 'GBC',\n",
    "#                 algorithm = GradientBoostingClassifier(max_depth=10, min_samples_leaf=50, min_samples_split=10, n_estimators=10),\n",
    "#                 X = X_trntst, Y = Y_trntst,\n",
    "#                 X_oot = X_oot_orig, Y_oot = Y_oot)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# %%time\n",
    "# # Catboost\n",
    "# model_execution(model_name = 'cat boost',\n",
    "#                 algorithm = CatBoostClassifier(verbose=0, max_depth=5, n_estimators=20),\n",
    "#                 Parameters_setting = \"CatBoostClassifier(verbose=0, max_depth=5, n_estimators=20)\",\n",
    "#                 X = X_trntst, Y = Y_trntst,\n",
    "#                 X_oot = X_oot_orig, Y_oot = Y_oot)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# # XGB\n",
    "# model_execution(model_name = 'XGB',\n",
    "#                 algorithm = xgb.XGBClassifier(max_depth=100, n_estimators=10),\n",
    "#                 Parameters_setting = 'xgb.XGBClassifier(max_depth=10, n_estimators=100)',\n",
    "#                 X = X_trntst, Y = Y_trntst,\n",
    "#                 X_oot = X_oot_orig, Y_oot = Y_oot)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model comparison plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>NVARS</th>\n",
       "      <th>Parameters</th>\n",
       "      <th>Trn</th>\n",
       "      <th>Tst</th>\n",
       "      <th>OOT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>log reg</td>\n",
       "      <td>10.0</td>\n",
       "      <td>penalty='none'</td>\n",
       "      <td>0.608696</td>\n",
       "      <td>0.671815</td>\n",
       "      <td>0.251397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>log reg</td>\n",
       "      <td>10.0</td>\n",
       "      <td>penalty='none'</td>\n",
       "      <td>0.632166</td>\n",
       "      <td>0.634921</td>\n",
       "      <td>0.346369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>log reg</td>\n",
       "      <td>10.0</td>\n",
       "      <td>penalty='none'</td>\n",
       "      <td>0.625600</td>\n",
       "      <td>0.647059</td>\n",
       "      <td>0.284916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>log reg</td>\n",
       "      <td>10.0</td>\n",
       "      <td>penalty='none'</td>\n",
       "      <td>0.635922</td>\n",
       "      <td>0.622137</td>\n",
       "      <td>0.357542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>log reg</td>\n",
       "      <td>10.0</td>\n",
       "      <td>penalty='none'</td>\n",
       "      <td>0.643087</td>\n",
       "      <td>0.608527</td>\n",
       "      <td>0.279330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>log reg</td>\n",
       "      <td>10.0</td>\n",
       "      <td>penalty='none'</td>\n",
       "      <td>0.631173</td>\n",
       "      <td>0.612069</td>\n",
       "      <td>0.279330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>log reg</td>\n",
       "      <td>10.0</td>\n",
       "      <td>penalty='none'</td>\n",
       "      <td>0.609477</td>\n",
       "      <td>0.671642</td>\n",
       "      <td>0.340782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>log reg</td>\n",
       "      <td>10.0</td>\n",
       "      <td>penalty='none'</td>\n",
       "      <td>0.650641</td>\n",
       "      <td>0.585938</td>\n",
       "      <td>0.307263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>log reg</td>\n",
       "      <td>10.0</td>\n",
       "      <td>penalty='none'</td>\n",
       "      <td>0.608280</td>\n",
       "      <td>0.686508</td>\n",
       "      <td>0.256983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>log reg</td>\n",
       "      <td>10.0</td>\n",
       "      <td>penalty='none'</td>\n",
       "      <td>0.617845</td>\n",
       "      <td>0.615385</td>\n",
       "      <td>0.245810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>DT</td>\n",
       "      <td>10.0</td>\n",
       "      <td>min_impurity_decrease=5e-05</td>\n",
       "      <td>0.679549</td>\n",
       "      <td>0.656371</td>\n",
       "      <td>0.497207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>DT</td>\n",
       "      <td>10.0</td>\n",
       "      <td>min_impurity_decrease=5e-05</td>\n",
       "      <td>0.681518</td>\n",
       "      <td>0.653285</td>\n",
       "      <td>0.324022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>DT</td>\n",
       "      <td>10.0</td>\n",
       "      <td>min_impurity_decrease=5e-05</td>\n",
       "      <td>0.681818</td>\n",
       "      <td>0.602273</td>\n",
       "      <td>0.407821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>DT</td>\n",
       "      <td>10.0</td>\n",
       "      <td>min_impurity_decrease=5e-05</td>\n",
       "      <td>0.678797</td>\n",
       "      <td>0.689516</td>\n",
       "      <td>0.296089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>DT</td>\n",
       "      <td>10.0</td>\n",
       "      <td>min_impurity_decrease=5e-05</td>\n",
       "      <td>0.677578</td>\n",
       "      <td>0.654275</td>\n",
       "      <td>0.351955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>DT</td>\n",
       "      <td>10.0</td>\n",
       "      <td>min_impurity_decrease=5e-05</td>\n",
       "      <td>0.686275</td>\n",
       "      <td>0.667910</td>\n",
       "      <td>0.379888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>DT</td>\n",
       "      <td>10.0</td>\n",
       "      <td>min_impurity_decrease=5e-05</td>\n",
       "      <td>0.666139</td>\n",
       "      <td>0.633065</td>\n",
       "      <td>0.458101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>DT</td>\n",
       "      <td>10.0</td>\n",
       "      <td>min_impurity_decrease=5e-05</td>\n",
       "      <td>0.646382</td>\n",
       "      <td>0.610294</td>\n",
       "      <td>0.458101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>DT</td>\n",
       "      <td>10.0</td>\n",
       "      <td>min_impurity_decrease=5e-05</td>\n",
       "      <td>0.660287</td>\n",
       "      <td>0.656126</td>\n",
       "      <td>0.307263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>DT</td>\n",
       "      <td>10.0</td>\n",
       "      <td>min_impurity_decrease=5e-05</td>\n",
       "      <td>0.675325</td>\n",
       "      <td>0.643939</td>\n",
       "      <td>0.385475</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Model  NVARS                   Parameters       Trn       Tst       OOT\n",
       "0   log reg   10.0               penalty='none'  0.608696  0.671815  0.251397\n",
       "1   log reg   10.0               penalty='none'  0.632166  0.634921  0.346369\n",
       "2   log reg   10.0               penalty='none'  0.625600  0.647059  0.284916\n",
       "3   log reg   10.0               penalty='none'  0.635922  0.622137  0.357542\n",
       "4   log reg   10.0               penalty='none'  0.643087  0.608527  0.279330\n",
       "5   log reg   10.0               penalty='none'  0.631173  0.612069  0.279330\n",
       "6   log reg   10.0               penalty='none'  0.609477  0.671642  0.340782\n",
       "7   log reg   10.0               penalty='none'  0.650641  0.585938  0.307263\n",
       "8   log reg   10.0               penalty='none'  0.608280  0.686508  0.256983\n",
       "9   log reg   10.0               penalty='none'  0.617845  0.615385  0.245810\n",
       "20       DT   10.0  min_impurity_decrease=5e-05  0.679549  0.656371  0.497207\n",
       "21       DT   10.0  min_impurity_decrease=5e-05  0.681518  0.653285  0.324022\n",
       "22       DT   10.0  min_impurity_decrease=5e-05  0.681818  0.602273  0.407821\n",
       "23       DT   10.0  min_impurity_decrease=5e-05  0.678797  0.689516  0.296089\n",
       "24       DT   10.0  min_impurity_decrease=5e-05  0.677578  0.654275  0.351955\n",
       "25       DT   10.0  min_impurity_decrease=5e-05  0.686275  0.667910  0.379888\n",
       "26       DT   10.0  min_impurity_decrease=5e-05  0.666139  0.633065  0.458101\n",
       "27       DT   10.0  min_impurity_decrease=5e-05  0.646382  0.610294  0.458101\n",
       "28       DT   10.0  min_impurity_decrease=5e-05  0.660287  0.656126  0.307263\n",
       "29       DT   10.0  min_impurity_decrease=5e-05  0.675325  0.643939  0.385475"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = Modeling_output.dropna()\n",
    "df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(330, 6)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Type</th>\n",
       "      <th>Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>log reg</td>\n",
       "      <td>Trn</td>\n",
       "      <td>0.608696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>log reg</td>\n",
       "      <td>Trn</td>\n",
       "      <td>0.632166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>log reg</td>\n",
       "      <td>Trn</td>\n",
       "      <td>0.625600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>log reg</td>\n",
       "      <td>Trn</td>\n",
       "      <td>0.635922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>log reg</td>\n",
       "      <td>Trn</td>\n",
       "      <td>0.643087</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Model Type     Value\n",
       "0  log reg  Trn  0.608696\n",
       "1  log reg  Trn  0.632166\n",
       "2  log reg  Trn  0.625600\n",
       "3  log reg  Trn  0.635922\n",
       "4  log reg  Trn  0.643087"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_unpivot = df.melt( id_vars='Model', value_vars=['Trn','Tst','OOT'], var_name=['Type'], value_name='Value')\n",
    "df_compare = df_unpivot[(df_unpivot['Type']=='Trn') | (df_unpivot['Type']=='Tst') | (df_unpivot['Type']=='OOT')]\n",
    "df_compare.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = df.groupby(['Model', 'NVARS', 'Parameters']).agg({'Trn':['mean','std'],'Tst':['mean','std'],'OOT':['mean','std']})\n",
    "output.reset_index().to_excel('output.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">Trn</th>\n",
       "      <th colspan=\"2\" halign=\"left\">Tst</th>\n",
       "      <th colspan=\"2\" halign=\"left\">OOT</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <th>NVARS</th>\n",
       "      <th>Parameters</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">DT</th>\n",
       "      <th rowspan=\"6\" valign=\"top\">10.0</th>\n",
       "      <th>min_impurity_decrease=1e-05</th>\n",
       "      <td>0.744013</td>\n",
       "      <td>0.020672</td>\n",
       "      <td>0.596342</td>\n",
       "      <td>0.018899</td>\n",
       "      <td>0.335754</td>\n",
       "      <td>0.087442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min_impurity_decrease=2.5e-05</th>\n",
       "      <td>0.703388</td>\n",
       "      <td>0.011972</td>\n",
       "      <td>0.645009</td>\n",
       "      <td>0.032123</td>\n",
       "      <td>0.355866</td>\n",
       "      <td>0.075965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min_impurity_decrease=2e-05</th>\n",
       "      <td>0.710625</td>\n",
       "      <td>0.017125</td>\n",
       "      <td>0.648441</td>\n",
       "      <td>0.018670</td>\n",
       "      <td>0.389944</td>\n",
       "      <td>0.071193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min_impurity_decrease=3.5e-05</th>\n",
       "      <td>0.695014</td>\n",
       "      <td>0.010661</td>\n",
       "      <td>0.654384</td>\n",
       "      <td>0.026308</td>\n",
       "      <td>0.379330</td>\n",
       "      <td>0.071079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min_impurity_decrease=3e-05</th>\n",
       "      <td>0.695579</td>\n",
       "      <td>0.010757</td>\n",
       "      <td>0.667114</td>\n",
       "      <td>0.020939</td>\n",
       "      <td>0.397765</td>\n",
       "      <td>0.087456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min_impurity_decrease=5e-05</th>\n",
       "      <td>0.673367</td>\n",
       "      <td>0.012226</td>\n",
       "      <td>0.646705</td>\n",
       "      <td>0.025946</td>\n",
       "      <td>0.386592</td>\n",
       "      <td>0.068765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"11\" valign=\"top\">LGBM</th>\n",
       "      <th rowspan=\"11\" valign=\"top\">10.0</th>\n",
       "      <th>min_child_samples=1000, min_split_gain=1</th>\n",
       "      <td>0.825497</td>\n",
       "      <td>0.004667</td>\n",
       "      <td>0.779005</td>\n",
       "      <td>0.010796</td>\n",
       "      <td>0.441341</td>\n",
       "      <td>0.009854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min_child_samples=1000, min_split_gain=5</th>\n",
       "      <td>0.770569</td>\n",
       "      <td>0.016328</td>\n",
       "      <td>0.730580</td>\n",
       "      <td>0.016959</td>\n",
       "      <td>0.397207</td>\n",
       "      <td>0.015680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min_child_samples=500, min_split_gain=1</th>\n",
       "      <td>0.850522</td>\n",
       "      <td>0.008528</td>\n",
       "      <td>0.785728</td>\n",
       "      <td>0.021914</td>\n",
       "      <td>0.461453</td>\n",
       "      <td>0.039696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min_child_samples=500, min_split_gain=1, n_estimators=10</th>\n",
       "      <td>0.758200</td>\n",
       "      <td>0.009633</td>\n",
       "      <td>0.719070</td>\n",
       "      <td>0.021037</td>\n",
       "      <td>0.413408</td>\n",
       "      <td>0.010534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min_child_samples=500, min_split_gain=1, n_estimators=50, num_leaves=15</th>\n",
       "      <td>0.811324</td>\n",
       "      <td>0.010840</td>\n",
       "      <td>0.781816</td>\n",
       "      <td>0.026023</td>\n",
       "      <td>0.454190</td>\n",
       "      <td>0.031055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min_child_samples=500, min_split_gain=1, n_estimators=50, num_leaves=19</th>\n",
       "      <td>0.834033</td>\n",
       "      <td>0.012280</td>\n",
       "      <td>0.784640</td>\n",
       "      <td>0.020491</td>\n",
       "      <td>0.459777</td>\n",
       "      <td>0.036874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min_child_samples=500, min_split_gain=1, n_estimators=50, num_leaves=30</th>\n",
       "      <td>0.850847</td>\n",
       "      <td>0.014004</td>\n",
       "      <td>0.788391</td>\n",
       "      <td>0.030050</td>\n",
       "      <td>0.458659</td>\n",
       "      <td>0.038745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min_child_samples=500, min_split_gain=5</th>\n",
       "      <td>0.782929</td>\n",
       "      <td>0.009246</td>\n",
       "      <td>0.755920</td>\n",
       "      <td>0.025779</td>\n",
       "      <td>0.422905</td>\n",
       "      <td>0.023266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min_split_gain=10</th>\n",
       "      <td>0.797722</td>\n",
       "      <td>0.011248</td>\n",
       "      <td>0.736992</td>\n",
       "      <td>0.031277</td>\n",
       "      <td>0.444134</td>\n",
       "      <td>0.022540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min_split_gain=20</th>\n",
       "      <td>0.762184</td>\n",
       "      <td>0.015578</td>\n",
       "      <td>0.727802</td>\n",
       "      <td>0.029099</td>\n",
       "      <td>0.424022</td>\n",
       "      <td>0.068038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min_split_gain=50</th>\n",
       "      <td>0.729639</td>\n",
       "      <td>0.022413</td>\n",
       "      <td>0.709074</td>\n",
       "      <td>0.022424</td>\n",
       "      <td>0.412291</td>\n",
       "      <td>0.060331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">NN</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">10.0</th>\n",
       "      <th>alpha=0.01, hidden_layer_sizes=(10, 10)</th>\n",
       "      <td>0.710103</td>\n",
       "      <td>0.011161</td>\n",
       "      <td>0.709848</td>\n",
       "      <td>0.021295</td>\n",
       "      <td>0.528492</td>\n",
       "      <td>0.038812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha=0.01, hidden_layer_sizes=(15, 15), learning_rate_init=0.01</th>\n",
       "      <td>0.719660</td>\n",
       "      <td>0.009008</td>\n",
       "      <td>0.702218</td>\n",
       "      <td>0.021441</td>\n",
       "      <td>0.553073</td>\n",
       "      <td>0.008734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hidden_layer_sizes=(10, 10)</th>\n",
       "      <td>0.712017</td>\n",
       "      <td>0.013014</td>\n",
       "      <td>0.712086</td>\n",
       "      <td>0.020862</td>\n",
       "      <td>0.529330</td>\n",
       "      <td>0.026445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hidden_layer_sizes=(15, 15)</th>\n",
       "      <td>0.731442</td>\n",
       "      <td>0.014565</td>\n",
       "      <td>0.707038</td>\n",
       "      <td>0.018274</td>\n",
       "      <td>0.525698</td>\n",
       "      <td>0.033255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hidden_layer_sizes=(20, 20)</th>\n",
       "      <td>0.747975</td>\n",
       "      <td>0.017636</td>\n",
       "      <td>0.721336</td>\n",
       "      <td>0.022990</td>\n",
       "      <td>0.494972</td>\n",
       "      <td>0.056083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"8\" valign=\"top\">RF</th>\n",
       "      <th rowspan=\"8\" valign=\"top\">10.0</th>\n",
       "      <th>min_impurity_decrease=1e-05, min_samples_leaf=30, min_samples_split=60, n_estimators=20</th>\n",
       "      <td>0.778692</td>\n",
       "      <td>0.014256</td>\n",
       "      <td>0.760464</td>\n",
       "      <td>0.025871</td>\n",
       "      <td>0.549162</td>\n",
       "      <td>0.017479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min_impurity_decrease=1e-05, min_samples_leaf=60, min_samples_split=120, n_estimators=20</th>\n",
       "      <td>0.757396</td>\n",
       "      <td>0.011381</td>\n",
       "      <td>0.729743</td>\n",
       "      <td>0.022282</td>\n",
       "      <td>0.545251</td>\n",
       "      <td>0.022222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min_impurity_decrease=2e-05, min_samples_leaf=30, min_samples_split=60, n_estimators=20</th>\n",
       "      <td>0.753169</td>\n",
       "      <td>0.017687</td>\n",
       "      <td>0.736335</td>\n",
       "      <td>0.019346</td>\n",
       "      <td>0.539665</td>\n",
       "      <td>0.017706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min_impurity_decrease=2e-05, n_estimators=20</th>\n",
       "      <td>0.801828</td>\n",
       "      <td>0.017241</td>\n",
       "      <td>0.735747</td>\n",
       "      <td>0.029652</td>\n",
       "      <td>0.536313</td>\n",
       "      <td>0.019708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min_impurity_decrease=3e-05, min_samples_leaf=15, min_samples_split=30, n_estimators=20</th>\n",
       "      <td>0.754914</td>\n",
       "      <td>0.017924</td>\n",
       "      <td>0.719545</td>\n",
       "      <td>0.033259</td>\n",
       "      <td>0.540223</td>\n",
       "      <td>0.013948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min_impurity_decrease=3e-05, min_samples_leaf=30, min_samples_split=60, n_estimators=20</th>\n",
       "      <td>0.744927</td>\n",
       "      <td>0.014208</td>\n",
       "      <td>0.723578</td>\n",
       "      <td>0.025869</td>\n",
       "      <td>0.548603</td>\n",
       "      <td>0.022928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min_impurity_decrease=5e-06, min_samples_leaf=30, min_samples_split=60, n_estimators=20</th>\n",
       "      <td>0.794411</td>\n",
       "      <td>0.009152</td>\n",
       "      <td>0.758528</td>\n",
       "      <td>0.021228</td>\n",
       "      <td>0.529609</td>\n",
       "      <td>0.025506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min_impurity_decrease=5e-06, min_samples_leaf=60, min_samples_split=120, n_estimators=20</th>\n",
       "      <td>0.772599</td>\n",
       "      <td>0.009908</td>\n",
       "      <td>0.734021</td>\n",
       "      <td>0.018847</td>\n",
       "      <td>0.558659</td>\n",
       "      <td>0.009854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>log reg</th>\n",
       "      <th>10.0</th>\n",
       "      <th>penalty='none'</th>\n",
       "      <td>0.626289</td>\n",
       "      <td>0.014962</td>\n",
       "      <td>0.635600</td>\n",
       "      <td>0.032790</td>\n",
       "      <td>0.294972</td>\n",
       "      <td>0.041036</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                       Trn  \\\n",
       "                                                                      mean   \n",
       "Model   NVARS Parameters                                                     \n",
       "DT      10.0  min_impurity_decrease=1e-05                         0.744013   \n",
       "              min_impurity_decrease=2.5e-05                       0.703388   \n",
       "              min_impurity_decrease=2e-05                         0.710625   \n",
       "              min_impurity_decrease=3.5e-05                       0.695014   \n",
       "              min_impurity_decrease=3e-05                         0.695579   \n",
       "              min_impurity_decrease=5e-05                         0.673367   \n",
       "LGBM    10.0  min_child_samples=1000, min_split_gain=1            0.825497   \n",
       "              min_child_samples=1000, min_split_gain=5            0.770569   \n",
       "              min_child_samples=500, min_split_gain=1             0.850522   \n",
       "              min_child_samples=500, min_split_gain=1, n_esti...  0.758200   \n",
       "              min_child_samples=500, min_split_gain=1, n_esti...  0.811324   \n",
       "              min_child_samples=500, min_split_gain=1, n_esti...  0.834033   \n",
       "              min_child_samples=500, min_split_gain=1, n_esti...  0.850847   \n",
       "              min_child_samples=500, min_split_gain=5             0.782929   \n",
       "              min_split_gain=10                                   0.797722   \n",
       "              min_split_gain=20                                   0.762184   \n",
       "              min_split_gain=50                                   0.729639   \n",
       "NN      10.0  alpha=0.01, hidden_layer_sizes=(10, 10)             0.710103   \n",
       "              alpha=0.01, hidden_layer_sizes=(15, 15), learni...  0.719660   \n",
       "              hidden_layer_sizes=(10, 10)                         0.712017   \n",
       "              hidden_layer_sizes=(15, 15)                         0.731442   \n",
       "              hidden_layer_sizes=(20, 20)                         0.747975   \n",
       "RF      10.0  min_impurity_decrease=1e-05, min_samples_leaf=3...  0.778692   \n",
       "              min_impurity_decrease=1e-05, min_samples_leaf=6...  0.757396   \n",
       "              min_impurity_decrease=2e-05, min_samples_leaf=3...  0.753169   \n",
       "              min_impurity_decrease=2e-05, n_estimators=20        0.801828   \n",
       "              min_impurity_decrease=3e-05, min_samples_leaf=1...  0.754914   \n",
       "              min_impurity_decrease=3e-05, min_samples_leaf=3...  0.744927   \n",
       "              min_impurity_decrease=5e-06, min_samples_leaf=3...  0.794411   \n",
       "              min_impurity_decrease=5e-06, min_samples_leaf=6...  0.772599   \n",
       "log reg 10.0  penalty='none'                                      0.626289   \n",
       "\n",
       "                                                                            \\\n",
       "                                                                       std   \n",
       "Model   NVARS Parameters                                                     \n",
       "DT      10.0  min_impurity_decrease=1e-05                         0.020672   \n",
       "              min_impurity_decrease=2.5e-05                       0.011972   \n",
       "              min_impurity_decrease=2e-05                         0.017125   \n",
       "              min_impurity_decrease=3.5e-05                       0.010661   \n",
       "              min_impurity_decrease=3e-05                         0.010757   \n",
       "              min_impurity_decrease=5e-05                         0.012226   \n",
       "LGBM    10.0  min_child_samples=1000, min_split_gain=1            0.004667   \n",
       "              min_child_samples=1000, min_split_gain=5            0.016328   \n",
       "              min_child_samples=500, min_split_gain=1             0.008528   \n",
       "              min_child_samples=500, min_split_gain=1, n_esti...  0.009633   \n",
       "              min_child_samples=500, min_split_gain=1, n_esti...  0.010840   \n",
       "              min_child_samples=500, min_split_gain=1, n_esti...  0.012280   \n",
       "              min_child_samples=500, min_split_gain=1, n_esti...  0.014004   \n",
       "              min_child_samples=500, min_split_gain=5             0.009246   \n",
       "              min_split_gain=10                                   0.011248   \n",
       "              min_split_gain=20                                   0.015578   \n",
       "              min_split_gain=50                                   0.022413   \n",
       "NN      10.0  alpha=0.01, hidden_layer_sizes=(10, 10)             0.011161   \n",
       "              alpha=0.01, hidden_layer_sizes=(15, 15), learni...  0.009008   \n",
       "              hidden_layer_sizes=(10, 10)                         0.013014   \n",
       "              hidden_layer_sizes=(15, 15)                         0.014565   \n",
       "              hidden_layer_sizes=(20, 20)                         0.017636   \n",
       "RF      10.0  min_impurity_decrease=1e-05, min_samples_leaf=3...  0.014256   \n",
       "              min_impurity_decrease=1e-05, min_samples_leaf=6...  0.011381   \n",
       "              min_impurity_decrease=2e-05, min_samples_leaf=3...  0.017687   \n",
       "              min_impurity_decrease=2e-05, n_estimators=20        0.017241   \n",
       "              min_impurity_decrease=3e-05, min_samples_leaf=1...  0.017924   \n",
       "              min_impurity_decrease=3e-05, min_samples_leaf=3...  0.014208   \n",
       "              min_impurity_decrease=5e-06, min_samples_leaf=3...  0.009152   \n",
       "              min_impurity_decrease=5e-06, min_samples_leaf=6...  0.009908   \n",
       "log reg 10.0  penalty='none'                                      0.014962   \n",
       "\n",
       "                                                                       Tst  \\\n",
       "                                                                      mean   \n",
       "Model   NVARS Parameters                                                     \n",
       "DT      10.0  min_impurity_decrease=1e-05                         0.596342   \n",
       "              min_impurity_decrease=2.5e-05                       0.645009   \n",
       "              min_impurity_decrease=2e-05                         0.648441   \n",
       "              min_impurity_decrease=3.5e-05                       0.654384   \n",
       "              min_impurity_decrease=3e-05                         0.667114   \n",
       "              min_impurity_decrease=5e-05                         0.646705   \n",
       "LGBM    10.0  min_child_samples=1000, min_split_gain=1            0.779005   \n",
       "              min_child_samples=1000, min_split_gain=5            0.730580   \n",
       "              min_child_samples=500, min_split_gain=1             0.785728   \n",
       "              min_child_samples=500, min_split_gain=1, n_esti...  0.719070   \n",
       "              min_child_samples=500, min_split_gain=1, n_esti...  0.781816   \n",
       "              min_child_samples=500, min_split_gain=1, n_esti...  0.784640   \n",
       "              min_child_samples=500, min_split_gain=1, n_esti...  0.788391   \n",
       "              min_child_samples=500, min_split_gain=5             0.755920   \n",
       "              min_split_gain=10                                   0.736992   \n",
       "              min_split_gain=20                                   0.727802   \n",
       "              min_split_gain=50                                   0.709074   \n",
       "NN      10.0  alpha=0.01, hidden_layer_sizes=(10, 10)             0.709848   \n",
       "              alpha=0.01, hidden_layer_sizes=(15, 15), learni...  0.702218   \n",
       "              hidden_layer_sizes=(10, 10)                         0.712086   \n",
       "              hidden_layer_sizes=(15, 15)                         0.707038   \n",
       "              hidden_layer_sizes=(20, 20)                         0.721336   \n",
       "RF      10.0  min_impurity_decrease=1e-05, min_samples_leaf=3...  0.760464   \n",
       "              min_impurity_decrease=1e-05, min_samples_leaf=6...  0.729743   \n",
       "              min_impurity_decrease=2e-05, min_samples_leaf=3...  0.736335   \n",
       "              min_impurity_decrease=2e-05, n_estimators=20        0.735747   \n",
       "              min_impurity_decrease=3e-05, min_samples_leaf=1...  0.719545   \n",
       "              min_impurity_decrease=3e-05, min_samples_leaf=3...  0.723578   \n",
       "              min_impurity_decrease=5e-06, min_samples_leaf=3...  0.758528   \n",
       "              min_impurity_decrease=5e-06, min_samples_leaf=6...  0.734021   \n",
       "log reg 10.0  penalty='none'                                      0.635600   \n",
       "\n",
       "                                                                            \\\n",
       "                                                                       std   \n",
       "Model   NVARS Parameters                                                     \n",
       "DT      10.0  min_impurity_decrease=1e-05                         0.018899   \n",
       "              min_impurity_decrease=2.5e-05                       0.032123   \n",
       "              min_impurity_decrease=2e-05                         0.018670   \n",
       "              min_impurity_decrease=3.5e-05                       0.026308   \n",
       "              min_impurity_decrease=3e-05                         0.020939   \n",
       "              min_impurity_decrease=5e-05                         0.025946   \n",
       "LGBM    10.0  min_child_samples=1000, min_split_gain=1            0.010796   \n",
       "              min_child_samples=1000, min_split_gain=5            0.016959   \n",
       "              min_child_samples=500, min_split_gain=1             0.021914   \n",
       "              min_child_samples=500, min_split_gain=1, n_esti...  0.021037   \n",
       "              min_child_samples=500, min_split_gain=1, n_esti...  0.026023   \n",
       "              min_child_samples=500, min_split_gain=1, n_esti...  0.020491   \n",
       "              min_child_samples=500, min_split_gain=1, n_esti...  0.030050   \n",
       "              min_child_samples=500, min_split_gain=5             0.025779   \n",
       "              min_split_gain=10                                   0.031277   \n",
       "              min_split_gain=20                                   0.029099   \n",
       "              min_split_gain=50                                   0.022424   \n",
       "NN      10.0  alpha=0.01, hidden_layer_sizes=(10, 10)             0.021295   \n",
       "              alpha=0.01, hidden_layer_sizes=(15, 15), learni...  0.021441   \n",
       "              hidden_layer_sizes=(10, 10)                         0.020862   \n",
       "              hidden_layer_sizes=(15, 15)                         0.018274   \n",
       "              hidden_layer_sizes=(20, 20)                         0.022990   \n",
       "RF      10.0  min_impurity_decrease=1e-05, min_samples_leaf=3...  0.025871   \n",
       "              min_impurity_decrease=1e-05, min_samples_leaf=6...  0.022282   \n",
       "              min_impurity_decrease=2e-05, min_samples_leaf=3...  0.019346   \n",
       "              min_impurity_decrease=2e-05, n_estimators=20        0.029652   \n",
       "              min_impurity_decrease=3e-05, min_samples_leaf=1...  0.033259   \n",
       "              min_impurity_decrease=3e-05, min_samples_leaf=3...  0.025869   \n",
       "              min_impurity_decrease=5e-06, min_samples_leaf=3...  0.021228   \n",
       "              min_impurity_decrease=5e-06, min_samples_leaf=6...  0.018847   \n",
       "log reg 10.0  penalty='none'                                      0.032790   \n",
       "\n",
       "                                                                       OOT  \\\n",
       "                                                                      mean   \n",
       "Model   NVARS Parameters                                                     \n",
       "DT      10.0  min_impurity_decrease=1e-05                         0.335754   \n",
       "              min_impurity_decrease=2.5e-05                       0.355866   \n",
       "              min_impurity_decrease=2e-05                         0.389944   \n",
       "              min_impurity_decrease=3.5e-05                       0.379330   \n",
       "              min_impurity_decrease=3e-05                         0.397765   \n",
       "              min_impurity_decrease=5e-05                         0.386592   \n",
       "LGBM    10.0  min_child_samples=1000, min_split_gain=1            0.441341   \n",
       "              min_child_samples=1000, min_split_gain=5            0.397207   \n",
       "              min_child_samples=500, min_split_gain=1             0.461453   \n",
       "              min_child_samples=500, min_split_gain=1, n_esti...  0.413408   \n",
       "              min_child_samples=500, min_split_gain=1, n_esti...  0.454190   \n",
       "              min_child_samples=500, min_split_gain=1, n_esti...  0.459777   \n",
       "              min_child_samples=500, min_split_gain=1, n_esti...  0.458659   \n",
       "              min_child_samples=500, min_split_gain=5             0.422905   \n",
       "              min_split_gain=10                                   0.444134   \n",
       "              min_split_gain=20                                   0.424022   \n",
       "              min_split_gain=50                                   0.412291   \n",
       "NN      10.0  alpha=0.01, hidden_layer_sizes=(10, 10)             0.528492   \n",
       "              alpha=0.01, hidden_layer_sizes=(15, 15), learni...  0.553073   \n",
       "              hidden_layer_sizes=(10, 10)                         0.529330   \n",
       "              hidden_layer_sizes=(15, 15)                         0.525698   \n",
       "              hidden_layer_sizes=(20, 20)                         0.494972   \n",
       "RF      10.0  min_impurity_decrease=1e-05, min_samples_leaf=3...  0.549162   \n",
       "              min_impurity_decrease=1e-05, min_samples_leaf=6...  0.545251   \n",
       "              min_impurity_decrease=2e-05, min_samples_leaf=3...  0.539665   \n",
       "              min_impurity_decrease=2e-05, n_estimators=20        0.536313   \n",
       "              min_impurity_decrease=3e-05, min_samples_leaf=1...  0.540223   \n",
       "              min_impurity_decrease=3e-05, min_samples_leaf=3...  0.548603   \n",
       "              min_impurity_decrease=5e-06, min_samples_leaf=3...  0.529609   \n",
       "              min_impurity_decrease=5e-06, min_samples_leaf=6...  0.558659   \n",
       "log reg 10.0  penalty='none'                                      0.294972   \n",
       "\n",
       "                                                                            \n",
       "                                                                       std  \n",
       "Model   NVARS Parameters                                                    \n",
       "DT      10.0  min_impurity_decrease=1e-05                         0.087442  \n",
       "              min_impurity_decrease=2.5e-05                       0.075965  \n",
       "              min_impurity_decrease=2e-05                         0.071193  \n",
       "              min_impurity_decrease=3.5e-05                       0.071079  \n",
       "              min_impurity_decrease=3e-05                         0.087456  \n",
       "              min_impurity_decrease=5e-05                         0.068765  \n",
       "LGBM    10.0  min_child_samples=1000, min_split_gain=1            0.009854  \n",
       "              min_child_samples=1000, min_split_gain=5            0.015680  \n",
       "              min_child_samples=500, min_split_gain=1             0.039696  \n",
       "              min_child_samples=500, min_split_gain=1, n_esti...  0.010534  \n",
       "              min_child_samples=500, min_split_gain=1, n_esti...  0.031055  \n",
       "              min_child_samples=500, min_split_gain=1, n_esti...  0.036874  \n",
       "              min_child_samples=500, min_split_gain=1, n_esti...  0.038745  \n",
       "              min_child_samples=500, min_split_gain=5             0.023266  \n",
       "              min_split_gain=10                                   0.022540  \n",
       "              min_split_gain=20                                   0.068038  \n",
       "              min_split_gain=50                                   0.060331  \n",
       "NN      10.0  alpha=0.01, hidden_layer_sizes=(10, 10)             0.038812  \n",
       "              alpha=0.01, hidden_layer_sizes=(15, 15), learni...  0.008734  \n",
       "              hidden_layer_sizes=(10, 10)                         0.026445  \n",
       "              hidden_layer_sizes=(15, 15)                         0.033255  \n",
       "              hidden_layer_sizes=(20, 20)                         0.056083  \n",
       "RF      10.0  min_impurity_decrease=1e-05, min_samples_leaf=3...  0.017479  \n",
       "              min_impurity_decrease=1e-05, min_samples_leaf=6...  0.022222  \n",
       "              min_impurity_decrease=2e-05, min_samples_leaf=3...  0.017706  \n",
       "              min_impurity_decrease=2e-05, n_estimators=20        0.019708  \n",
       "              min_impurity_decrease=3e-05, min_samples_leaf=1...  0.013948  \n",
       "              min_impurity_decrease=3e-05, min_samples_leaf=3...  0.022928  \n",
       "              min_impurity_decrease=5e-06, min_samples_leaf=3...  0.025506  \n",
       "              min_impurity_decrease=5e-06, min_samples_leaf=6...  0.009854  \n",
       "log reg 10.0  penalty='none'                                      0.041036  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x1080 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(20,15))\n",
    "ax = sns.boxplot(x='Model',y='Value',hue='Type', data=df_compare, palette=['navy','r','g'])\n",
    "\n",
    "# plt.ylim(.4,.6)\n",
    "plt.ylabel('Score (FDR3%)')\n",
    "plt.grid(axis='y')\n",
    "plt.savefig('modeling.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "duration:  0:01:14.413006\n"
     ]
    }
   ],
   "source": [
    "print('duration: ', datetime.now() - start_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final model of choice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.5261406844106464 0.529657477025898 0.5029337803855826\n",
      "1 0.5281856939838939 0.5248386191411731 0.5075440067057837\n",
      "2 0.5263659088203785 0.5302273987798114 0.5029337803855826\n",
      "3 0.5272619047619047 0.5284169670085944 0.5050293378038558\n",
      "4 0.5244349781090996 0.5306524184476941 0.5046102263202011\n",
      "5 0.5325606404588362 0.5167674546454095 0.5075440067057837\n",
      "6 0.5271327014218009 0.5273338940285954 0.5041911148365466\n",
      "7 0.528561270443233 0.5245166713365088 0.5088013411567477\n",
      "8 0.529138915318744 0.522645179216449 0.5029337803855826\n",
      "9 0.5311218335343788 0.519774011299435 0.5075440067057837\n",
      "10 0.5251038575667656 0.5318257956448911 0.5050293378038558\n",
      "11 0.5321888412017167 0.5169936446532192 0.5054484492875104\n",
      "12 0.5238262498536471 0.5377957299480669 0.5046102263202011\n",
      "13 0.5310868533459896 0.5183012014529198 0.5046102263202011\n",
      "14 0.522874251497006 0.5378725731473886 0.5062866722548198\n",
      "15 0.531945270672219 0.5172126596335369 0.5037720033528919\n",
      "16 0.5279770444763271 0.5264891572879495 0.5079631181894384\n",
      "17 0.5264032277204225 0.5290502793296089 0.5058675607711651\n",
      "18 0.5276131784783124 0.5264780050434296 0.5071248952221291\n",
      "19 0.5267878497966993 0.5289437585733882 0.5079631181894384\n",
      "20 0.5256926355671324 0.5310306093793878 0.5067057837384744\n",
      "21 0.5274803711634547 0.5273535129130797 0.5046102263202011\n",
      "22 0.5293282876064334 0.5215432272599267 0.5054484492875104\n",
      "23 0.5273311897106109 0.5282548476454294 0.5046102263202011\n",
      "24 0.5305637982195845 0.5189838079285315 0.5062866722548198\n",
      "25 0.5262271414821944 0.5299052774018944 0.5067057837384744\n",
      "26 0.5262778977681786 0.5298121426626735 0.5050293378038558\n",
      "27 0.5243204577968527 0.5332964907432992 0.5033528918692373\n",
      "28 0.5266666666666666 0.5281397283060715 0.5016764459346186\n",
      "29 0.5273076461409194 0.5277475516866159 0.5079631181894384\n",
      "trn    0.527597\n",
      "tst    0.526729\n",
      "oot    0.505504\n",
      "dtype: float64\n",
      "CPU times: total: 12min 40s\n",
      "Wall time: 51.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# LGBM\n",
    "result_final_model = model_execution(model_name = 'Final_LGBM',\n",
    "                                algorithm = lgb.LGBMClassifier(max_depth=5, n_estimators=200, num_leaves=4),\n",
    "                                X = X_trntst, Y = Y_trntst,\n",
    "                                X_oot = X_oot_orig, Y_oot = Y_oot,\n",
    "                                nitermax = 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_execution(model_name = 'Final',\n",
    "#                 algorithm = CatBoostClassifier(verbose=0, iterations=100), # here's where you put your final model of choice\n",
    "#                 X = X_trntst, Y = Y_trntst,\n",
    "#                 X_oot = X_oot_orig, Y_oot = Y_oot,\n",
    "#                 nitermax = 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fulladdress_day_since</th>\n",
       "      <th>name_dob_count_30</th>\n",
       "      <th>address_unique_count_for_name_homephone_60</th>\n",
       "      <th>fulladdress_unique_count_for_dob_homephone_3</th>\n",
       "      <th>address_unique_count_for_homephone_name_dob_30</th>\n",
       "      <th>address_unique_count_for_ssn_name_dob_14</th>\n",
       "      <th>address_day_since</th>\n",
       "      <th>address_count_14</th>\n",
       "      <th>address_count_7</th>\n",
       "      <th>address_count_0_by_30</th>\n",
       "      <th>predicted</th>\n",
       "      <th>Fraud</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>40287</th>\n",
       "      <td>0.403033</td>\n",
       "      <td>-0.132081</td>\n",
       "      <td>-0.113357</td>\n",
       "      <td>-0.06276</td>\n",
       "      <td>-0.101011</td>\n",
       "      <td>-0.084722</td>\n",
       "      <td>0.428121</td>\n",
       "      <td>-0.113383</td>\n",
       "      <td>-0.092352</td>\n",
       "      <td>0.200213</td>\n",
       "      <td>0.007183</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>699756</th>\n",
       "      <td>0.403033</td>\n",
       "      <td>-0.132081</td>\n",
       "      <td>-0.113357</td>\n",
       "      <td>-0.06276</td>\n",
       "      <td>-0.101011</td>\n",
       "      <td>-0.084722</td>\n",
       "      <td>0.428121</td>\n",
       "      <td>-0.113383</td>\n",
       "      <td>-0.092352</td>\n",
       "      <td>0.200213</td>\n",
       "      <td>0.007183</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>371640</th>\n",
       "      <td>0.403033</td>\n",
       "      <td>-0.132081</td>\n",
       "      <td>-0.113357</td>\n",
       "      <td>-0.06276</td>\n",
       "      <td>-0.101011</td>\n",
       "      <td>-0.084722</td>\n",
       "      <td>0.428121</td>\n",
       "      <td>-0.113383</td>\n",
       "      <td>-0.092352</td>\n",
       "      <td>0.200213</td>\n",
       "      <td>0.007183</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>647858</th>\n",
       "      <td>0.403033</td>\n",
       "      <td>-0.132081</td>\n",
       "      <td>-0.113357</td>\n",
       "      <td>-0.06276</td>\n",
       "      <td>-0.101011</td>\n",
       "      <td>-0.084722</td>\n",
       "      <td>0.428121</td>\n",
       "      <td>-0.113383</td>\n",
       "      <td>-0.092352</td>\n",
       "      <td>0.200213</td>\n",
       "      <td>0.007183</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129081</th>\n",
       "      <td>0.403033</td>\n",
       "      <td>-0.132081</td>\n",
       "      <td>-0.113357</td>\n",
       "      <td>-0.06276</td>\n",
       "      <td>-0.101011</td>\n",
       "      <td>-0.084722</td>\n",
       "      <td>0.428121</td>\n",
       "      <td>-0.113383</td>\n",
       "      <td>-0.092352</td>\n",
       "      <td>0.200213</td>\n",
       "      <td>0.007183</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>719783</th>\n",
       "      <td>0.403033</td>\n",
       "      <td>-0.132081</td>\n",
       "      <td>-0.113357</td>\n",
       "      <td>-0.06276</td>\n",
       "      <td>-0.101011</td>\n",
       "      <td>-0.084722</td>\n",
       "      <td>0.428121</td>\n",
       "      <td>-0.113383</td>\n",
       "      <td>-0.092352</td>\n",
       "      <td>0.200213</td>\n",
       "      <td>0.007183</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>529902</th>\n",
       "      <td>0.403033</td>\n",
       "      <td>-0.132081</td>\n",
       "      <td>-0.113357</td>\n",
       "      <td>-0.06276</td>\n",
       "      <td>-0.101011</td>\n",
       "      <td>-0.084722</td>\n",
       "      <td>0.428121</td>\n",
       "      <td>-0.113383</td>\n",
       "      <td>-0.092352</td>\n",
       "      <td>0.200213</td>\n",
       "      <td>0.007183</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>510490</th>\n",
       "      <td>0.403033</td>\n",
       "      <td>-0.132081</td>\n",
       "      <td>-0.113357</td>\n",
       "      <td>-0.06276</td>\n",
       "      <td>-0.101011</td>\n",
       "      <td>-0.084722</td>\n",
       "      <td>0.428121</td>\n",
       "      <td>-0.113383</td>\n",
       "      <td>-0.092352</td>\n",
       "      <td>0.200213</td>\n",
       "      <td>0.007183</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>739170</th>\n",
       "      <td>0.403033</td>\n",
       "      <td>-0.132081</td>\n",
       "      <td>-0.113357</td>\n",
       "      <td>-0.06276</td>\n",
       "      <td>-0.101011</td>\n",
       "      <td>-0.084722</td>\n",
       "      <td>0.428121</td>\n",
       "      <td>-0.113383</td>\n",
       "      <td>-0.092352</td>\n",
       "      <td>0.200213</td>\n",
       "      <td>0.007183</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22507</th>\n",
       "      <td>0.403033</td>\n",
       "      <td>-0.132081</td>\n",
       "      <td>-0.113357</td>\n",
       "      <td>-0.06276</td>\n",
       "      <td>-0.101011</td>\n",
       "      <td>-0.084722</td>\n",
       "      <td>0.428121</td>\n",
       "      <td>-0.113383</td>\n",
       "      <td>-0.092352</td>\n",
       "      <td>0.200213</td>\n",
       "      <td>0.007183</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>583454 rows Ã— 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        fulladdress_day_since  name_dob_count_30  \\\n",
       "40287                0.403033          -0.132081   \n",
       "699756               0.403033          -0.132081   \n",
       "371640               0.403033          -0.132081   \n",
       "647858               0.403033          -0.132081   \n",
       "129081               0.403033          -0.132081   \n",
       "...                       ...                ...   \n",
       "719783               0.403033          -0.132081   \n",
       "529902               0.403033          -0.132081   \n",
       "510490               0.403033          -0.132081   \n",
       "739170               0.403033          -0.132081   \n",
       "22507                0.403033          -0.132081   \n",
       "\n",
       "        address_unique_count_for_name_homephone_60  \\\n",
       "40287                                    -0.113357   \n",
       "699756                                   -0.113357   \n",
       "371640                                   -0.113357   \n",
       "647858                                   -0.113357   \n",
       "129081                                   -0.113357   \n",
       "...                                            ...   \n",
       "719783                                   -0.113357   \n",
       "529902                                   -0.113357   \n",
       "510490                                   -0.113357   \n",
       "739170                                   -0.113357   \n",
       "22507                                    -0.113357   \n",
       "\n",
       "        fulladdress_unique_count_for_dob_homephone_3  \\\n",
       "40287                                       -0.06276   \n",
       "699756                                      -0.06276   \n",
       "371640                                      -0.06276   \n",
       "647858                                      -0.06276   \n",
       "129081                                      -0.06276   \n",
       "...                                              ...   \n",
       "719783                                      -0.06276   \n",
       "529902                                      -0.06276   \n",
       "510490                                      -0.06276   \n",
       "739170                                      -0.06276   \n",
       "22507                                       -0.06276   \n",
       "\n",
       "        address_unique_count_for_homephone_name_dob_30  \\\n",
       "40287                                        -0.101011   \n",
       "699756                                       -0.101011   \n",
       "371640                                       -0.101011   \n",
       "647858                                       -0.101011   \n",
       "129081                                       -0.101011   \n",
       "...                                                ...   \n",
       "719783                                       -0.101011   \n",
       "529902                                       -0.101011   \n",
       "510490                                       -0.101011   \n",
       "739170                                       -0.101011   \n",
       "22507                                        -0.101011   \n",
       "\n",
       "        address_unique_count_for_ssn_name_dob_14  address_day_since  \\\n",
       "40287                                  -0.084722           0.428121   \n",
       "699756                                 -0.084722           0.428121   \n",
       "371640                                 -0.084722           0.428121   \n",
       "647858                                 -0.084722           0.428121   \n",
       "129081                                 -0.084722           0.428121   \n",
       "...                                          ...                ...   \n",
       "719783                                 -0.084722           0.428121   \n",
       "529902                                 -0.084722           0.428121   \n",
       "510490                                 -0.084722           0.428121   \n",
       "739170                                 -0.084722           0.428121   \n",
       "22507                                  -0.084722           0.428121   \n",
       "\n",
       "        address_count_14  address_count_7  address_count_0_by_30  predicted  \\\n",
       "40287          -0.113383        -0.092352               0.200213   0.007183   \n",
       "699756         -0.113383        -0.092352               0.200213   0.007183   \n",
       "371640         -0.113383        -0.092352               0.200213   0.007183   \n",
       "647858         -0.113383        -0.092352               0.200213   0.007183   \n",
       "129081         -0.113383        -0.092352               0.200213   0.007183   \n",
       "...                  ...              ...                    ...        ...   \n",
       "719783         -0.113383        -0.092352               0.200213   0.007183   \n",
       "529902         -0.113383        -0.092352               0.200213   0.007183   \n",
       "510490         -0.113383        -0.092352               0.200213   0.007183   \n",
       "739170         -0.113383        -0.092352               0.200213   0.007183   \n",
       "22507          -0.113383        -0.092352               0.200213   0.007183   \n",
       "\n",
       "        Fraud  \n",
       "40287     0.0  \n",
       "699756    0.0  \n",
       "371640    0.0  \n",
       "647858    0.0  \n",
       "129081    0.0  \n",
       "...       ...  \n",
       "719783    0.0  \n",
       "529902    0.0  \n",
       "510490    0.0  \n",
       "739170    0.0  \n",
       "22507     0.0  \n",
       "\n",
       "[583454 rows x 12 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_final_model[1]['X_trn']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_trn_eval = result_final_model[1]['X_trn'].copy()\n",
    "X_tst_eval = result_final_model[1]['X_tst'].copy()\n",
    "X_oot_eval = result_final_model[1]['X_oot'].copy()\n",
    "FDR3 = result_final_model[1]['FDR3'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fulladdress_day_since</th>\n",
       "      <th>name_dob_count_30</th>\n",
       "      <th>address_unique_count_for_name_homephone_60</th>\n",
       "      <th>fulladdress_unique_count_for_dob_homephone_3</th>\n",
       "      <th>address_unique_count_for_homephone_name_dob_30</th>\n",
       "      <th>address_unique_count_for_ssn_name_dob_14</th>\n",
       "      <th>address_day_since</th>\n",
       "      <th>address_count_14</th>\n",
       "      <th>address_count_7</th>\n",
       "      <th>address_count_0_by_30</th>\n",
       "      <th>predicted</th>\n",
       "      <th>Fraud</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>865961</th>\n",
       "      <td>-3.280209</td>\n",
       "      <td>-0.132081</td>\n",
       "      <td>14.584262</td>\n",
       "      <td>19.167299</td>\n",
       "      <td>15.749194</td>\n",
       "      <td>16.848748</td>\n",
       "      <td>-3.053486</td>\n",
       "      <td>16.160620</td>\n",
       "      <td>17.222145</td>\n",
       "      <td>0.200213</td>\n",
       "      <td>0.999924</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>835976</th>\n",
       "      <td>-3.280209</td>\n",
       "      <td>-0.132081</td>\n",
       "      <td>14.584262</td>\n",
       "      <td>19.167299</td>\n",
       "      <td>15.749194</td>\n",
       "      <td>16.848748</td>\n",
       "      <td>-3.053486</td>\n",
       "      <td>16.160620</td>\n",
       "      <td>17.222145</td>\n",
       "      <td>0.200213</td>\n",
       "      <td>0.999924</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>865765</th>\n",
       "      <td>-3.280209</td>\n",
       "      <td>-0.132081</td>\n",
       "      <td>14.584262</td>\n",
       "      <td>19.167299</td>\n",
       "      <td>15.749194</td>\n",
       "      <td>16.848748</td>\n",
       "      <td>-3.053486</td>\n",
       "      <td>16.160620</td>\n",
       "      <td>17.222145</td>\n",
       "      <td>0.200213</td>\n",
       "      <td>0.999924</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>884885</th>\n",
       "      <td>-3.280209</td>\n",
       "      <td>-0.132081</td>\n",
       "      <td>14.584262</td>\n",
       "      <td>19.167299</td>\n",
       "      <td>15.749194</td>\n",
       "      <td>16.848748</td>\n",
       "      <td>-3.053486</td>\n",
       "      <td>16.160620</td>\n",
       "      <td>17.222145</td>\n",
       "      <td>0.200213</td>\n",
       "      <td>0.999924</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>884916</th>\n",
       "      <td>-3.280209</td>\n",
       "      <td>-0.132081</td>\n",
       "      <td>14.584262</td>\n",
       "      <td>19.167299</td>\n",
       "      <td>15.749194</td>\n",
       "      <td>16.848748</td>\n",
       "      <td>-3.053486</td>\n",
       "      <td>16.160620</td>\n",
       "      <td>17.222145</td>\n",
       "      <td>0.200213</td>\n",
       "      <td>0.999924</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>884645</th>\n",
       "      <td>-3.280209</td>\n",
       "      <td>-0.132081</td>\n",
       "      <td>14.584262</td>\n",
       "      <td>19.167299</td>\n",
       "      <td>15.749194</td>\n",
       "      <td>16.848748</td>\n",
       "      <td>-3.053486</td>\n",
       "      <td>16.160620</td>\n",
       "      <td>17.222145</td>\n",
       "      <td>0.200213</td>\n",
       "      <td>0.999924</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>937013</th>\n",
       "      <td>-3.280209</td>\n",
       "      <td>-0.132081</td>\n",
       "      <td>14.584262</td>\n",
       "      <td>19.167299</td>\n",
       "      <td>15.749194</td>\n",
       "      <td>16.848748</td>\n",
       "      <td>-3.053486</td>\n",
       "      <td>16.160620</td>\n",
       "      <td>17.222145</td>\n",
       "      <td>0.200213</td>\n",
       "      <td>0.999924</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>865902</th>\n",
       "      <td>-3.280209</td>\n",
       "      <td>-0.132081</td>\n",
       "      <td>14.584262</td>\n",
       "      <td>19.167299</td>\n",
       "      <td>15.749194</td>\n",
       "      <td>16.848748</td>\n",
       "      <td>-3.053486</td>\n",
       "      <td>16.160620</td>\n",
       "      <td>17.222145</td>\n",
       "      <td>0.200213</td>\n",
       "      <td>0.999924</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>915077</th>\n",
       "      <td>-3.280209</td>\n",
       "      <td>-0.132081</td>\n",
       "      <td>14.584262</td>\n",
       "      <td>19.167299</td>\n",
       "      <td>15.749194</td>\n",
       "      <td>16.848748</td>\n",
       "      <td>-3.053486</td>\n",
       "      <td>16.160620</td>\n",
       "      <td>17.222145</td>\n",
       "      <td>0.200213</td>\n",
       "      <td>0.999924</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>957048</th>\n",
       "      <td>-3.270118</td>\n",
       "      <td>17.476308</td>\n",
       "      <td>14.584262</td>\n",
       "      <td>19.167299</td>\n",
       "      <td>15.749194</td>\n",
       "      <td>16.848748</td>\n",
       "      <td>-3.043947</td>\n",
       "      <td>16.160620</td>\n",
       "      <td>17.222145</td>\n",
       "      <td>-8.379301</td>\n",
       "      <td>0.999819</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>835909</th>\n",
       "      <td>-3.280209</td>\n",
       "      <td>3.377843</td>\n",
       "      <td>14.584262</td>\n",
       "      <td>19.167299</td>\n",
       "      <td>15.749194</td>\n",
       "      <td>16.848748</td>\n",
       "      <td>-3.053486</td>\n",
       "      <td>16.160620</td>\n",
       "      <td>17.222145</td>\n",
       "      <td>-1.671681</td>\n",
       "      <td>0.999806</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>880299</th>\n",
       "      <td>-3.209572</td>\n",
       "      <td>17.476308</td>\n",
       "      <td>-0.113357</td>\n",
       "      <td>-0.062760</td>\n",
       "      <td>-0.101011</td>\n",
       "      <td>-0.084722</td>\n",
       "      <td>-2.986715</td>\n",
       "      <td>12.935918</td>\n",
       "      <td>2.842077</td>\n",
       "      <td>-8.119316</td>\n",
       "      <td>0.999792</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>862046</th>\n",
       "      <td>-3.229754</td>\n",
       "      <td>17.476308</td>\n",
       "      <td>-0.113357</td>\n",
       "      <td>-0.062760</td>\n",
       "      <td>-0.101011</td>\n",
       "      <td>-0.084722</td>\n",
       "      <td>-3.005792</td>\n",
       "      <td>12.935918</td>\n",
       "      <td>11.645364</td>\n",
       "      <td>-8.119316</td>\n",
       "      <td>0.999722</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>943613</th>\n",
       "      <td>-3.229754</td>\n",
       "      <td>17.476308</td>\n",
       "      <td>-0.113357</td>\n",
       "      <td>-0.062760</td>\n",
       "      <td>-0.101011</td>\n",
       "      <td>-0.084722</td>\n",
       "      <td>-3.005792</td>\n",
       "      <td>7.716198</td>\n",
       "      <td>2.842077</td>\n",
       "      <td>-8.119316</td>\n",
       "      <td>0.999696</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>909416</th>\n",
       "      <td>-3.199481</td>\n",
       "      <td>17.476308</td>\n",
       "      <td>-0.113357</td>\n",
       "      <td>-0.062760</td>\n",
       "      <td>-0.101011</td>\n",
       "      <td>-0.084722</td>\n",
       "      <td>-2.977176</td>\n",
       "      <td>7.716198</td>\n",
       "      <td>-0.092352</td>\n",
       "      <td>-8.119316</td>\n",
       "      <td>0.999696</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>984814</th>\n",
       "      <td>-3.280209</td>\n",
       "      <td>-0.132081</td>\n",
       "      <td>14.584262</td>\n",
       "      <td>19.167299</td>\n",
       "      <td>15.749194</td>\n",
       "      <td>16.848748</td>\n",
       "      <td>-3.053486</td>\n",
       "      <td>16.160620</td>\n",
       "      <td>17.222145</td>\n",
       "      <td>-1.671681</td>\n",
       "      <td>0.999626</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>881950</th>\n",
       "      <td>-3.280209</td>\n",
       "      <td>-0.132081</td>\n",
       "      <td>14.584262</td>\n",
       "      <td>19.167299</td>\n",
       "      <td>15.749194</td>\n",
       "      <td>16.848748</td>\n",
       "      <td>-3.053486</td>\n",
       "      <td>16.160620</td>\n",
       "      <td>17.222145</td>\n",
       "      <td>-1.501508</td>\n",
       "      <td>0.999626</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>854173</th>\n",
       "      <td>-3.280209</td>\n",
       "      <td>-0.132081</td>\n",
       "      <td>14.584262</td>\n",
       "      <td>19.167299</td>\n",
       "      <td>15.749194</td>\n",
       "      <td>16.848748</td>\n",
       "      <td>-3.053486</td>\n",
       "      <td>16.160620</td>\n",
       "      <td>17.222145</td>\n",
       "      <td>-0.579742</td>\n",
       "      <td>0.999626</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>881968</th>\n",
       "      <td>-3.280209</td>\n",
       "      <td>-0.132081</td>\n",
       "      <td>14.584262</td>\n",
       "      <td>19.167299</td>\n",
       "      <td>15.749194</td>\n",
       "      <td>16.848748</td>\n",
       "      <td>-3.053486</td>\n",
       "      <td>16.160620</td>\n",
       "      <td>17.222145</td>\n",
       "      <td>-1.427521</td>\n",
       "      <td>0.999626</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>854763</th>\n",
       "      <td>-3.280209</td>\n",
       "      <td>-0.132081</td>\n",
       "      <td>14.584262</td>\n",
       "      <td>19.167299</td>\n",
       "      <td>15.749194</td>\n",
       "      <td>16.848748</td>\n",
       "      <td>-3.053486</td>\n",
       "      <td>16.160620</td>\n",
       "      <td>17.222145</td>\n",
       "      <td>-0.384753</td>\n",
       "      <td>0.999626</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        fulladdress_day_since  name_dob_count_30  \\\n",
       "865961              -3.280209          -0.132081   \n",
       "835976              -3.280209          -0.132081   \n",
       "865765              -3.280209          -0.132081   \n",
       "884885              -3.280209          -0.132081   \n",
       "884916              -3.280209          -0.132081   \n",
       "884645              -3.280209          -0.132081   \n",
       "937013              -3.280209          -0.132081   \n",
       "865902              -3.280209          -0.132081   \n",
       "915077              -3.280209          -0.132081   \n",
       "957048              -3.270118          17.476308   \n",
       "835909              -3.280209           3.377843   \n",
       "880299              -3.209572          17.476308   \n",
       "862046              -3.229754          17.476308   \n",
       "943613              -3.229754          17.476308   \n",
       "909416              -3.199481          17.476308   \n",
       "984814              -3.280209          -0.132081   \n",
       "881950              -3.280209          -0.132081   \n",
       "854173              -3.280209          -0.132081   \n",
       "881968              -3.280209          -0.132081   \n",
       "854763              -3.280209          -0.132081   \n",
       "\n",
       "        address_unique_count_for_name_homephone_60  \\\n",
       "865961                                   14.584262   \n",
       "835976                                   14.584262   \n",
       "865765                                   14.584262   \n",
       "884885                                   14.584262   \n",
       "884916                                   14.584262   \n",
       "884645                                   14.584262   \n",
       "937013                                   14.584262   \n",
       "865902                                   14.584262   \n",
       "915077                                   14.584262   \n",
       "957048                                   14.584262   \n",
       "835909                                   14.584262   \n",
       "880299                                   -0.113357   \n",
       "862046                                   -0.113357   \n",
       "943613                                   -0.113357   \n",
       "909416                                   -0.113357   \n",
       "984814                                   14.584262   \n",
       "881950                                   14.584262   \n",
       "854173                                   14.584262   \n",
       "881968                                   14.584262   \n",
       "854763                                   14.584262   \n",
       "\n",
       "        fulladdress_unique_count_for_dob_homephone_3  \\\n",
       "865961                                     19.167299   \n",
       "835976                                     19.167299   \n",
       "865765                                     19.167299   \n",
       "884885                                     19.167299   \n",
       "884916                                     19.167299   \n",
       "884645                                     19.167299   \n",
       "937013                                     19.167299   \n",
       "865902                                     19.167299   \n",
       "915077                                     19.167299   \n",
       "957048                                     19.167299   \n",
       "835909                                     19.167299   \n",
       "880299                                     -0.062760   \n",
       "862046                                     -0.062760   \n",
       "943613                                     -0.062760   \n",
       "909416                                     -0.062760   \n",
       "984814                                     19.167299   \n",
       "881950                                     19.167299   \n",
       "854173                                     19.167299   \n",
       "881968                                     19.167299   \n",
       "854763                                     19.167299   \n",
       "\n",
       "        address_unique_count_for_homephone_name_dob_30  \\\n",
       "865961                                       15.749194   \n",
       "835976                                       15.749194   \n",
       "865765                                       15.749194   \n",
       "884885                                       15.749194   \n",
       "884916                                       15.749194   \n",
       "884645                                       15.749194   \n",
       "937013                                       15.749194   \n",
       "865902                                       15.749194   \n",
       "915077                                       15.749194   \n",
       "957048                                       15.749194   \n",
       "835909                                       15.749194   \n",
       "880299                                       -0.101011   \n",
       "862046                                       -0.101011   \n",
       "943613                                       -0.101011   \n",
       "909416                                       -0.101011   \n",
       "984814                                       15.749194   \n",
       "881950                                       15.749194   \n",
       "854173                                       15.749194   \n",
       "881968                                       15.749194   \n",
       "854763                                       15.749194   \n",
       "\n",
       "        address_unique_count_for_ssn_name_dob_14  address_day_since  \\\n",
       "865961                                 16.848748          -3.053486   \n",
       "835976                                 16.848748          -3.053486   \n",
       "865765                                 16.848748          -3.053486   \n",
       "884885                                 16.848748          -3.053486   \n",
       "884916                                 16.848748          -3.053486   \n",
       "884645                                 16.848748          -3.053486   \n",
       "937013                                 16.848748          -3.053486   \n",
       "865902                                 16.848748          -3.053486   \n",
       "915077                                 16.848748          -3.053486   \n",
       "957048                                 16.848748          -3.043947   \n",
       "835909                                 16.848748          -3.053486   \n",
       "880299                                 -0.084722          -2.986715   \n",
       "862046                                 -0.084722          -3.005792   \n",
       "943613                                 -0.084722          -3.005792   \n",
       "909416                                 -0.084722          -2.977176   \n",
       "984814                                 16.848748          -3.053486   \n",
       "881950                                 16.848748          -3.053486   \n",
       "854173                                 16.848748          -3.053486   \n",
       "881968                                 16.848748          -3.053486   \n",
       "854763                                 16.848748          -3.053486   \n",
       "\n",
       "        address_count_14  address_count_7  address_count_0_by_30  predicted  \\\n",
       "865961         16.160620        17.222145               0.200213   0.999924   \n",
       "835976         16.160620        17.222145               0.200213   0.999924   \n",
       "865765         16.160620        17.222145               0.200213   0.999924   \n",
       "884885         16.160620        17.222145               0.200213   0.999924   \n",
       "884916         16.160620        17.222145               0.200213   0.999924   \n",
       "884645         16.160620        17.222145               0.200213   0.999924   \n",
       "937013         16.160620        17.222145               0.200213   0.999924   \n",
       "865902         16.160620        17.222145               0.200213   0.999924   \n",
       "915077         16.160620        17.222145               0.200213   0.999924   \n",
       "957048         16.160620        17.222145              -8.379301   0.999819   \n",
       "835909         16.160620        17.222145              -1.671681   0.999806   \n",
       "880299         12.935918         2.842077              -8.119316   0.999792   \n",
       "862046         12.935918        11.645364              -8.119316   0.999722   \n",
       "943613          7.716198         2.842077              -8.119316   0.999696   \n",
       "909416          7.716198        -0.092352              -8.119316   0.999696   \n",
       "984814         16.160620        17.222145              -1.671681   0.999626   \n",
       "881950         16.160620        17.222145              -1.501508   0.999626   \n",
       "854173         16.160620        17.222145              -0.579742   0.999626   \n",
       "881968         16.160620        17.222145              -1.427521   0.999626   \n",
       "854763         16.160620        17.222145              -0.384753   0.999626   \n",
       "\n",
       "        Fraud  \n",
       "865961    1.0  \n",
       "835976    1.0  \n",
       "865765    1.0  \n",
       "884885    1.0  \n",
       "884916    1.0  \n",
       "884645    1.0  \n",
       "937013    1.0  \n",
       "865902    1.0  \n",
       "915077    1.0  \n",
       "957048    0.0  \n",
       "835909    1.0  \n",
       "880299    1.0  \n",
       "862046    0.0  \n",
       "943613    1.0  \n",
       "909416    1.0  \n",
       "984814    1.0  \n",
       "881950    1.0  \n",
       "854173    1.0  \n",
       "881968    1.0  \n",
       "854763    1.0  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols = ['bin','#recs','#g','#b','%g','%b','tot','cg','cb','%cg','FDR','KS','FPR']\n",
    "\n",
    "FDR_trn = pd.DataFrame(np.zeros((101, 13)), columns = cols)\n",
    "FDR_tst = pd.DataFrame(np.zeros((101, 13)), columns = cols)\n",
    "FDR_oot = pd.DataFrame(np.zeros((101, 13)), columns = cols)\n",
    "\n",
    "trn_sorted = X_trn_eval.sort_values('predicted',ascending=False)\n",
    "tst_sorted = X_tst_eval.sort_values('predicted',ascending=False)\n",
    "oot_sorted = X_oot_eval.sort_values('predicted',ascending=False)\n",
    "\n",
    "oot_sorted.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FDR_eval(dataframe, X):\n",
    "    \n",
    "    bad_tot = sum(X.loc[:, 'Fraud'])\n",
    "    num_tot = len(X)\n",
    "    good_tot = num_tot - bad_tot\n",
    "    \n",
    "    X_sorted = X.sort_values('predicted',ascending=False)\n",
    "\n",
    "    for i in range(101):\n",
    "\n",
    "        percent_rows = int(round(X.shape[0]*0.01*i))\n",
    "        temp = X_sorted.head(percent_rows)\n",
    "        num_bad = sum(temp.loc[:,'Fraud'])\n",
    "        num_tot = len(temp)\n",
    "        num_good = num_tot - num_bad\n",
    "\n",
    "        dataframe.loc[i, 'bin'] = i\n",
    "        dataframe.loc[i,'#recs'] = 0\n",
    "        dataframe.loc[i, 'tot'] = num_tot\n",
    "        dataframe.loc[i, 'cg'] = num_good # cumulative good\n",
    "        dataframe.loc[i, 'cb'] = num_bad # cumulative bad\n",
    "\n",
    "        if i != 0:\n",
    "            dataframe.loc[i, '#g'] = num_good - dataframe.loc[i-1, 'cg'] # marginal good\n",
    "            dataframe.loc[i, '#b'] = num_bad - dataframe.loc[i-1, 'cb'] # marginal bad\n",
    "            dataframe.loc[i,'#recs'] = dataframe.loc[i, '#g'] + dataframe.loc[i, '#b']\n",
    "            \n",
    "            dataframe.loc[i, '%g'] = 100 * (dataframe.loc[i, '#g']) / (num_tot - dataframe.loc[i-1, 'tot'])\n",
    "            dataframe.loc[i, '%b'] = 100 - dataframe.loc[i, '%g']\n",
    "            \n",
    "            dataframe.loc[i, '%cg'] = 100 * num_good / good_tot\n",
    "            dataframe.loc[i, 'FDR'] = 100 * num_bad / bad_tot\n",
    "            dataframe.loc[i, 'KS'] = dataframe.loc[i, 'FDR'] - dataframe.loc[i, '%cg']\n",
    "            dataframe.loc[i, 'FPR'] = num_good / num_bad\n",
    "\n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "FDR_trn = FDR_eval(dataframe = FDR_trn, X = X_trn_eval)\n",
    "FDR_tst = FDR_eval(dataframe = FDR_tst, X = X_tst_eval)\n",
    "FDR_oot = FDR_eval(dataframe = FDR_oot, X = X_oot_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bin</th>\n",
       "      <th>#recs</th>\n",
       "      <th>#g</th>\n",
       "      <th>#b</th>\n",
       "      <th>%g</th>\n",
       "      <th>%b</th>\n",
       "      <th>tot</th>\n",
       "      <th>cg</th>\n",
       "      <th>cb</th>\n",
       "      <th>%cg</th>\n",
       "      <th>FDR</th>\n",
       "      <th>KS</th>\n",
       "      <th>FPR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1665.0</td>\n",
       "      <td>509.0</td>\n",
       "      <td>1156.0</td>\n",
       "      <td>30.570571</td>\n",
       "      <td>69.429429</td>\n",
       "      <td>1665.0</td>\n",
       "      <td>509.0</td>\n",
       "      <td>1156.0</td>\n",
       "      <td>0.310163</td>\n",
       "      <td>48.449288</td>\n",
       "      <td>48.139124</td>\n",
       "      <td>0.440311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1665.0</td>\n",
       "      <td>1641.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>98.558559</td>\n",
       "      <td>1.441441</td>\n",
       "      <td>3330.0</td>\n",
       "      <td>2150.0</td>\n",
       "      <td>1180.0</td>\n",
       "      <td>1.310121</td>\n",
       "      <td>49.455155</td>\n",
       "      <td>48.145034</td>\n",
       "      <td>1.822034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.0</td>\n",
       "      <td>1665.0</td>\n",
       "      <td>1633.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>98.078078</td>\n",
       "      <td>1.921922</td>\n",
       "      <td>4995.0</td>\n",
       "      <td>3783.0</td>\n",
       "      <td>1212.0</td>\n",
       "      <td>2.305203</td>\n",
       "      <td>50.796312</td>\n",
       "      <td>48.491109</td>\n",
       "      <td>3.121287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.0</td>\n",
       "      <td>1665.0</td>\n",
       "      <td>1650.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>99.099099</td>\n",
       "      <td>0.900901</td>\n",
       "      <td>6660.0</td>\n",
       "      <td>5433.0</td>\n",
       "      <td>1227.0</td>\n",
       "      <td>3.310645</td>\n",
       "      <td>51.424979</td>\n",
       "      <td>48.114334</td>\n",
       "      <td>4.427873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>96.0</td>\n",
       "      <td>1665.0</td>\n",
       "      <td>1651.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>99.159159</td>\n",
       "      <td>0.840841</td>\n",
       "      <td>159833.0</td>\n",
       "      <td>157487.0</td>\n",
       "      <td>2346.0</td>\n",
       "      <td>95.966047</td>\n",
       "      <td>98.323554</td>\n",
       "      <td>2.357508</td>\n",
       "      <td>67.130009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>97.0</td>\n",
       "      <td>1665.0</td>\n",
       "      <td>1658.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>99.579580</td>\n",
       "      <td>0.420420</td>\n",
       "      <td>161498.0</td>\n",
       "      <td>159145.0</td>\n",
       "      <td>2353.0</td>\n",
       "      <td>96.976363</td>\n",
       "      <td>98.616932</td>\n",
       "      <td>1.640569</td>\n",
       "      <td>67.634934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>98.0</td>\n",
       "      <td>1665.0</td>\n",
       "      <td>1654.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>99.339339</td>\n",
       "      <td>0.660661</td>\n",
       "      <td>163163.0</td>\n",
       "      <td>160799.0</td>\n",
       "      <td>2364.0</td>\n",
       "      <td>97.984242</td>\n",
       "      <td>99.077955</td>\n",
       "      <td>1.093713</td>\n",
       "      <td>68.019882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>99.0</td>\n",
       "      <td>1665.0</td>\n",
       "      <td>1655.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>99.399399</td>\n",
       "      <td>0.600601</td>\n",
       "      <td>164828.0</td>\n",
       "      <td>162454.0</td>\n",
       "      <td>2374.0</td>\n",
       "      <td>98.992730</td>\n",
       "      <td>99.497066</td>\n",
       "      <td>0.504336</td>\n",
       "      <td>68.430497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>100.0</td>\n",
       "      <td>1665.0</td>\n",
       "      <td>1653.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>99.279279</td>\n",
       "      <td>0.720721</td>\n",
       "      <td>166493.0</td>\n",
       "      <td>164107.0</td>\n",
       "      <td>2386.0</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>68.779128</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>101 rows Ã— 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       bin   #recs      #g      #b         %g         %b       tot        cg  \\\n",
       "0      0.0     0.0     0.0     0.0   0.000000   0.000000       0.0       0.0   \n",
       "1      1.0  1665.0   509.0  1156.0  30.570571  69.429429    1665.0     509.0   \n",
       "2      2.0  1665.0  1641.0    24.0  98.558559   1.441441    3330.0    2150.0   \n",
       "3      3.0  1665.0  1633.0    32.0  98.078078   1.921922    4995.0    3783.0   \n",
       "4      4.0  1665.0  1650.0    15.0  99.099099   0.900901    6660.0    5433.0   \n",
       "..     ...     ...     ...     ...        ...        ...       ...       ...   \n",
       "96    96.0  1665.0  1651.0    14.0  99.159159   0.840841  159833.0  157487.0   \n",
       "97    97.0  1665.0  1658.0     7.0  99.579580   0.420420  161498.0  159145.0   \n",
       "98    98.0  1665.0  1654.0    11.0  99.339339   0.660661  163163.0  160799.0   \n",
       "99    99.0  1665.0  1655.0    10.0  99.399399   0.600601  164828.0  162454.0   \n",
       "100  100.0  1665.0  1653.0    12.0  99.279279   0.720721  166493.0  164107.0   \n",
       "\n",
       "         cb         %cg         FDR         KS        FPR  \n",
       "0       0.0    0.000000    0.000000   0.000000   0.000000  \n",
       "1    1156.0    0.310163   48.449288  48.139124   0.440311  \n",
       "2    1180.0    1.310121   49.455155  48.145034   1.822034  \n",
       "3    1212.0    2.305203   50.796312  48.491109   3.121287  \n",
       "4    1227.0    3.310645   51.424979  48.114334   4.427873  \n",
       "..      ...         ...         ...        ...        ...  \n",
       "96   2346.0   95.966047   98.323554   2.357508  67.130009  \n",
       "97   2353.0   96.976363   98.616932   1.640569  67.634934  \n",
       "98   2364.0   97.984242   99.077955   1.093713  68.019882  \n",
       "99   2374.0   98.992730   99.497066   0.504336  68.430497  \n",
       "100  2386.0  100.000000  100.000000   0.000000  68.779128  \n",
       "\n",
       "[101 rows x 13 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FDR_oot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "FDR3.to_csv('FDR3.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "FDR_trn.to_csv('FDR_trn.csv', index=False)\n",
    "FDR_tst.to_csv('FDR_tst.csv', index=False)\n",
    "FDR_oot.to_csv('FDR_oot.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "duration:  0:03:00.001687\n"
     ]
    }
   ],
   "source": [
    "print(\"duration: \", datetime.now() - start_time)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "320px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
