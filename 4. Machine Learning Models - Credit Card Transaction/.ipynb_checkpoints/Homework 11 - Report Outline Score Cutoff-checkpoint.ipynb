{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook uses a wide variety of modeling algorithms for a binary classification problem. It reads a file created from a feature selection process that has a reasonably small number of good variables, and we know their order of multivariate importance because we used a proper wrapper method. We can explore # input variables, model algorithms and tune model hyperparameters. At the end we can select our favorite algorithm, run it again and build the final model performace score percentile tables.\n",
    "\n",
    "Here we call the larger fraction population the goods and the smaller fraction the bads. This notebook was originally\n",
    "written for fraud detection but can be used for any binary classification. It uses detection rate as an appropriate measure of goodness.\n",
    "\n",
    "Rather than use a built-in CV, we do a \"manual CV\" by running each model multiple (nitermax) times and average the performance on the training (trn), testing (tst) and out of time (oot) data sets.\n",
    "\n",
    "Some of the ML algorithms are very fast and some are slow. Feel free to comment out any cells/models you want. At the bottom of the notebook you can select your final model/hyperparameters to run one time only and then make the business perfoemance tables for that final model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Things to add: better calculation of FDR@3% when building a model using sampled training data. Right now I just approximate it by using the entire population trntst for a model built with sampled data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "start_time = datetime.now()\n",
    "\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "import gc\n",
    "import lightgbm as lgb\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(96397, 27)\n",
      "CPU times: total: 62.5 ms\n",
      "Wall time: 314 ms\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>card_Merch_num_state_total_14</th>\n",
       "      <th>card_Merchnum_max_30</th>\n",
       "      <th>card_Merch_des_zip_total_1</th>\n",
       "      <th>Merch_description_total_0</th>\n",
       "      <th>card_Merch_state_zip_total_14</th>\n",
       "      <th>card_Merch_des_state_max_30</th>\n",
       "      <th>card_Merch_des_zip_max_30</th>\n",
       "      <th>card_Merch_des_state_zip_max_30</th>\n",
       "      <th>card_Merch_num_des_zip_total_0</th>\n",
       "      <th>card_Merch_des_state_zip_total_30</th>\n",
       "      <th>...</th>\n",
       "      <th>Merch_state_zip_variability_avg_14</th>\n",
       "      <th>card_Merch_num_des_total_0</th>\n",
       "      <th>card_Merch_des_state_total_30</th>\n",
       "      <th>card_Merch_des_state_total_0</th>\n",
       "      <th>card_Merch_description_total_0</th>\n",
       "      <th>card_Merch_zip_total_0</th>\n",
       "      <th>card_Merch_num_des_zip_total_14</th>\n",
       "      <th>card_Merch_description_total_30</th>\n",
       "      <th>Recnum</th>\n",
       "      <th>Fraud</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.62</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.62</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.62</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>31.42</td>\n",
       "      <td>31.42</td>\n",
       "      <td>31.42</td>\n",
       "      <td>31.42</td>\n",
       "      <td>31.42</td>\n",
       "      <td>31.42</td>\n",
       "      <td>31.42</td>\n",
       "      <td>31.42</td>\n",
       "      <td>31.42</td>\n",
       "      <td>31.42</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>31.42</td>\n",
       "      <td>31.42</td>\n",
       "      <td>31.42</td>\n",
       "      <td>31.42</td>\n",
       "      <td>31.42</td>\n",
       "      <td>31.42</td>\n",
       "      <td>31.42</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>178.49</td>\n",
       "      <td>178.49</td>\n",
       "      <td>178.49</td>\n",
       "      <td>178.49</td>\n",
       "      <td>178.49</td>\n",
       "      <td>178.49</td>\n",
       "      <td>178.49</td>\n",
       "      <td>178.49</td>\n",
       "      <td>178.49</td>\n",
       "      <td>178.49</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>178.49</td>\n",
       "      <td>178.49</td>\n",
       "      <td>178.49</td>\n",
       "      <td>178.49</td>\n",
       "      <td>178.49</td>\n",
       "      <td>178.49</td>\n",
       "      <td>178.49</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.62</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.62</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.62</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.24</td>\n",
       "      <td>3.62</td>\n",
       "      <td>7.24</td>\n",
       "      <td>7.24</td>\n",
       "      <td>7.24</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.62</td>\n",
       "      <td>7.24</td>\n",
       "      <td>7.24</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.24</td>\n",
       "      <td>7.24</td>\n",
       "      <td>7.24</td>\n",
       "      <td>7.24</td>\n",
       "      <td>7.24</td>\n",
       "      <td>7.24</td>\n",
       "      <td>7.24</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   card_Merch_num_state_total_14  card_Merchnum_max_30  \\\n",
       "0                           3.62                  3.62   \n",
       "1                          31.42                 31.42   \n",
       "2                         178.49                178.49   \n",
       "3                           3.62                  3.62   \n",
       "4                           7.24                  3.62   \n",
       "\n",
       "   card_Merch_des_zip_total_1  Merch_description_total_0  \\\n",
       "0                        3.62                       3.62   \n",
       "1                       31.42                      31.42   \n",
       "2                      178.49                     178.49   \n",
       "3                        3.62                       3.62   \n",
       "4                        7.24                       7.24   \n",
       "\n",
       "   card_Merch_state_zip_total_14  card_Merch_des_state_max_30  \\\n",
       "0                           3.62                         3.62   \n",
       "1                          31.42                        31.42   \n",
       "2                         178.49                       178.49   \n",
       "3                           3.62                         3.62   \n",
       "4                           7.24                         3.62   \n",
       "\n",
       "   card_Merch_des_zip_max_30  card_Merch_des_state_zip_max_30  \\\n",
       "0                       3.62                             3.62   \n",
       "1                      31.42                            31.42   \n",
       "2                     178.49                           178.49   \n",
       "3                       3.62                             3.62   \n",
       "4                       3.62                             3.62   \n",
       "\n",
       "   card_Merch_num_des_zip_total_0  card_Merch_des_state_zip_total_30  ...  \\\n",
       "0                            3.62                               3.62  ...   \n",
       "1                           31.42                              31.42  ...   \n",
       "2                          178.49                             178.49  ...   \n",
       "3                            3.62                               3.62  ...   \n",
       "4                            7.24                               7.24  ...   \n",
       "\n",
       "   Merch_state_zip_variability_avg_14  card_Merch_num_des_total_0  \\\n",
       "0                                 0.0                        3.62   \n",
       "1                                 0.0                       31.42   \n",
       "2                                 0.0                      178.49   \n",
       "3                                 0.0                        3.62   \n",
       "4                                 0.0                        7.24   \n",
       "\n",
       "   card_Merch_des_state_total_30  card_Merch_des_state_total_0  \\\n",
       "0                           3.62                          3.62   \n",
       "1                          31.42                         31.42   \n",
       "2                         178.49                        178.49   \n",
       "3                           3.62                          3.62   \n",
       "4                           7.24                          7.24   \n",
       "\n",
       "   card_Merch_description_total_0  card_Merch_zip_total_0  \\\n",
       "0                            3.62                    3.62   \n",
       "1                           31.42                   31.42   \n",
       "2                          178.49                  178.49   \n",
       "3                            3.62                    3.62   \n",
       "4                            7.24                    7.24   \n",
       "\n",
       "   card_Merch_num_des_zip_total_14  card_Merch_description_total_30  Recnum  \\\n",
       "0                             3.62                             3.62       1   \n",
       "1                            31.42                            31.42       2   \n",
       "2                           178.49                           178.49       3   \n",
       "3                             3.62                             3.62       4   \n",
       "4                             7.24                             7.24       5   \n",
       "\n",
       "   Fraud  \n",
       "0      0  \n",
       "1      0  \n",
       "2      0  \n",
       "3      0  \n",
       "4      0  \n",
       "\n",
       "[5 rows x 27 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "vars_all = pd.read_csv('2_df_final_with_Y.csv').sort_values(\"Recnum\").reset_index(drop=True)\n",
    "vars_all.rename(columns={'Recnum':'Recnum'},inplace=True)\n",
    "vars_all.rename(columns={'Fraud':'Fraud'},inplace=True)\n",
    "\n",
    "print(vars_all.shape)\n",
    "vars_all.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NVAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Recnum',\n",
       " 'Fraud',\n",
       " 'card_Merch_num_state_total_14',\n",
       " 'card_Merchnum_max_30',\n",
       " 'card_Merch_des_zip_total_1',\n",
       " 'Merch_description_total_0',\n",
       " 'card_Merch_state_zip_total_14',\n",
       " 'card_Merch_des_state_max_30',\n",
       " 'card_Merch_des_zip_max_30',\n",
       " 'card_Merch_des_state_zip_max_30',\n",
       " 'card_Merch_num_des_zip_total_0',\n",
       " 'card_Merch_des_state_zip_total_30']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# set the number of variables desired here, and set the names of the y and record number properly\n",
    "NVARS = 10\n",
    "numvars = min(NVARS,len(vars_all)-2) # 10\n",
    "final_vars_list = ['Recnum','Fraud']\n",
    "for i in range(numvars):\n",
    "    final_vars_list.append(vars_all.columns[i])\n",
    "    \n",
    "final_vars_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "vars = vars_all.filter(final_vars_list,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Fraud</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Fraud\n",
       "0      0\n",
       "1      0\n",
       "2      0\n",
       "3      0\n",
       "4      0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "record_save = vars['Recnum']\n",
    "Y_save = pd.DataFrame(vars.loc[:,'Fraud'])\n",
    "Y_save.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scale and truncate field values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>card_Merch_num_state_total_14</th>\n",
       "      <th>card_Merchnum_max_30</th>\n",
       "      <th>card_Merch_des_zip_total_1</th>\n",
       "      <th>Merch_description_total_0</th>\n",
       "      <th>card_Merch_state_zip_total_14</th>\n",
       "      <th>card_Merch_des_state_max_30</th>\n",
       "      <th>card_Merch_des_zip_max_30</th>\n",
       "      <th>card_Merch_des_state_zip_max_30</th>\n",
       "      <th>card_Merch_num_des_zip_total_0</th>\n",
       "      <th>card_Merch_des_state_zip_total_30</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>96397.000000</td>\n",
       "      <td>96397.000000</td>\n",
       "      <td>96397.000000</td>\n",
       "      <td>96397.000000</td>\n",
       "      <td>96397.000000</td>\n",
       "      <td>96397.000000</td>\n",
       "      <td>96397.000000</td>\n",
       "      <td>96397.000000</td>\n",
       "      <td>96397.000000</td>\n",
       "      <td>96397.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>770.509236</td>\n",
       "      <td>517.704051</td>\n",
       "      <td>593.666588</td>\n",
       "      <td>761.885095</td>\n",
       "      <td>803.336711</td>\n",
       "      <td>514.700728</td>\n",
       "      <td>513.497615</td>\n",
       "      <td>513.491474</td>\n",
       "      <td>523.805769</td>\n",
       "      <td>903.627845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>4168.658888</td>\n",
       "      <td>1084.028924</td>\n",
       "      <td>4010.097366</td>\n",
       "      <td>2872.816671</td>\n",
       "      <td>4185.964751</td>\n",
       "      <td>1074.829349</td>\n",
       "      <td>1074.519504</td>\n",
       "      <td>1074.520672</td>\n",
       "      <td>2616.296248</td>\n",
       "      <td>4312.348251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.010000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>77.090000</td>\n",
       "      <td>53.430000</td>\n",
       "      <td>45.900000</td>\n",
       "      <td>66.850000</td>\n",
       "      <td>84.450000</td>\n",
       "      <td>49.100000</td>\n",
       "      <td>48.850000</td>\n",
       "      <td>48.850000</td>\n",
       "      <td>43.350000</td>\n",
       "      <td>63.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>237.210000</td>\n",
       "      <td>201.050000</td>\n",
       "      <td>162.740000</td>\n",
       "      <td>225.000000</td>\n",
       "      <td>255.000000</td>\n",
       "      <td>200.550000</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>155.000000</td>\n",
       "      <td>246.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>678.000000</td>\n",
       "      <td>597.510000</td>\n",
       "      <td>509.320000</td>\n",
       "      <td>735.000000</td>\n",
       "      <td>713.010000</td>\n",
       "      <td>595.000000</td>\n",
       "      <td>593.230000</td>\n",
       "      <td>593.230000</td>\n",
       "      <td>490.860000</td>\n",
       "      <td>796.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>306633.410000</td>\n",
       "      <td>47900.000000</td>\n",
       "      <td>306633.410000</td>\n",
       "      <td>217467.180000</td>\n",
       "      <td>306633.410000</td>\n",
       "      <td>47900.000000</td>\n",
       "      <td>47900.000000</td>\n",
       "      <td>47900.000000</td>\n",
       "      <td>217467.180000</td>\n",
       "      <td>306633.410000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       card_Merch_num_state_total_14  card_Merchnum_max_30  \\\n",
       "count                   96397.000000          96397.000000   \n",
       "mean                      770.509236            517.704051   \n",
       "std                      4168.658888           1084.028924   \n",
       "min                         0.010000              0.010000   \n",
       "25%                        77.090000             53.430000   \n",
       "50%                       237.210000            201.050000   \n",
       "75%                       678.000000            597.510000   \n",
       "max                    306633.410000          47900.000000   \n",
       "\n",
       "       card_Merch_des_zip_total_1  Merch_description_total_0  \\\n",
       "count                96397.000000               96397.000000   \n",
       "mean                   593.666588                 761.885095   \n",
       "std                   4010.097366                2872.816671   \n",
       "min                      0.010000                   0.010000   \n",
       "25%                     45.900000                  66.850000   \n",
       "50%                    162.740000                 225.000000   \n",
       "75%                    509.320000                 735.000000   \n",
       "max                 306633.410000              217467.180000   \n",
       "\n",
       "       card_Merch_state_zip_total_14  card_Merch_des_state_max_30  \\\n",
       "count                   96397.000000                 96397.000000   \n",
       "mean                      803.336711                   514.700728   \n",
       "std                      4185.964751                  1074.829349   \n",
       "min                         0.010000                     0.010000   \n",
       "25%                        84.450000                    49.100000   \n",
       "50%                       255.000000                   200.550000   \n",
       "75%                       713.010000                   595.000000   \n",
       "max                    306633.410000                 47900.000000   \n",
       "\n",
       "       card_Merch_des_zip_max_30  card_Merch_des_state_zip_max_30  \\\n",
       "count               96397.000000                     96397.000000   \n",
       "mean                  513.497615                       513.491474   \n",
       "std                  1074.519504                      1074.520672   \n",
       "min                     0.010000                         0.010000   \n",
       "25%                    48.850000                        48.850000   \n",
       "50%                   200.000000                       200.000000   \n",
       "75%                   593.230000                       593.230000   \n",
       "max                 47900.000000                     47900.000000   \n",
       "\n",
       "       card_Merch_num_des_zip_total_0  card_Merch_des_state_zip_total_30  \n",
       "count                    96397.000000                       96397.000000  \n",
       "mean                       523.805769                         903.627845  \n",
       "std                       2616.296248                        4312.348251  \n",
       "min                          0.010000                           0.010000  \n",
       "25%                         43.350000                          63.500000  \n",
       "50%                        155.000000                         246.750000  \n",
       "75%                        490.860000                         796.000000  \n",
       "max                     217467.180000                      306633.410000  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_no_scaling = vars.drop(columns = ['Recnum','Fraud'])\n",
    "X_no_scaling.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>card_Merch_num_state_total_14</th>\n",
       "      <th>card_Merchnum_max_30</th>\n",
       "      <th>card_Merch_des_zip_total_1</th>\n",
       "      <th>Merch_description_total_0</th>\n",
       "      <th>card_Merch_state_zip_total_14</th>\n",
       "      <th>card_Merch_des_state_max_30</th>\n",
       "      <th>card_Merch_des_zip_max_30</th>\n",
       "      <th>card_Merch_des_state_zip_max_30</th>\n",
       "      <th>card_Merch_num_des_zip_total_0</th>\n",
       "      <th>card_Merch_des_state_zip_total_30</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>9.639700e+04</td>\n",
       "      <td>9.639700e+04</td>\n",
       "      <td>9.639700e+04</td>\n",
       "      <td>9.639700e+04</td>\n",
       "      <td>9.639700e+04</td>\n",
       "      <td>9.639700e+04</td>\n",
       "      <td>9.639700e+04</td>\n",
       "      <td>9.639700e+04</td>\n",
       "      <td>9.639700e+04</td>\n",
       "      <td>9.639700e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.632861e-15</td>\n",
       "      <td>-2.943088e-16</td>\n",
       "      <td>-3.105266e-15</td>\n",
       "      <td>9.543076e-16</td>\n",
       "      <td>2.475414e-16</td>\n",
       "      <td>-1.357099e-15</td>\n",
       "      <td>-3.832563e-15</td>\n",
       "      <td>3.024862e-15</td>\n",
       "      <td>-5.718466e-16</td>\n",
       "      <td>1.812779e-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-3.531577e-01</td>\n",
       "      <td>-6.064073e-01</td>\n",
       "      <td>-3.173814e-01</td>\n",
       "      <td>-4.352501e-01</td>\n",
       "      <td>-3.623744e-01</td>\n",
       "      <td>-6.023596e-01</td>\n",
       "      <td>-6.012590e-01</td>\n",
       "      <td>-6.012505e-01</td>\n",
       "      <td>-3.933519e-01</td>\n",
       "      <td>-3.649256e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-3.153007e-01</td>\n",
       "      <td>-5.422421e-01</td>\n",
       "      <td>-2.905632e-01</td>\n",
       "      <td>-3.953644e-01</td>\n",
       "      <td>-3.216869e-01</td>\n",
       "      <td>-5.434950e-01</td>\n",
       "      <td>-5.426602e-01</td>\n",
       "      <td>-5.426519e-01</td>\n",
       "      <td>-3.587629e-01</td>\n",
       "      <td>-3.377712e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-2.366597e-01</td>\n",
       "      <td>-3.649292e-01</td>\n",
       "      <td>-2.222817e-01</td>\n",
       "      <td>-3.009909e-01</td>\n",
       "      <td>-2.395073e-01</td>\n",
       "      <td>-3.618889e-01</td>\n",
       "      <td>-3.613088e-01</td>\n",
       "      <td>-3.613008e-01</td>\n",
       "      <td>-2.696569e-01</td>\n",
       "      <td>-2.593960e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>-2.017084e-02</td>\n",
       "      <td>1.112766e-01</td>\n",
       "      <td>-1.973979e-02</td>\n",
       "      <td>3.343646e-03</td>\n",
       "      <td>-1.881494e-02</td>\n",
       "      <td>1.111025e-01</td>\n",
       "      <td>1.104928e-01</td>\n",
       "      <td>1.105000e-01</td>\n",
       "      <td>-1.612438e-03</td>\n",
       "      <td>-2.448431e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2.049914e+01</td>\n",
       "      <td>1.303617e+01</td>\n",
       "      <td>2.346463e+01</td>\n",
       "      <td>1.716247e+01</td>\n",
       "      <td>2.019480e+01</td>\n",
       "      <td>1.290327e+01</td>\n",
       "      <td>1.290703e+01</td>\n",
       "      <td>1.290702e+01</td>\n",
       "      <td>2.090492e+01</td>\n",
       "      <td>1.846526e+01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       card_Merch_num_state_total_14  card_Merchnum_max_30  \\\n",
       "count                   9.639700e+04          9.639700e+04   \n",
       "mean                    1.632861e-15         -2.943088e-16   \n",
       "std                     1.000000e+00          1.000000e+00   \n",
       "min                    -3.531577e-01         -6.064073e-01   \n",
       "25%                    -3.153007e-01         -5.422421e-01   \n",
       "50%                    -2.366597e-01         -3.649292e-01   \n",
       "75%                    -2.017084e-02          1.112766e-01   \n",
       "max                     2.049914e+01          1.303617e+01   \n",
       "\n",
       "       card_Merch_des_zip_total_1  Merch_description_total_0  \\\n",
       "count                9.639700e+04               9.639700e+04   \n",
       "mean                -3.105266e-15               9.543076e-16   \n",
       "std                  1.000000e+00               1.000000e+00   \n",
       "min                 -3.173814e-01              -4.352501e-01   \n",
       "25%                 -2.905632e-01              -3.953644e-01   \n",
       "50%                 -2.222817e-01              -3.009909e-01   \n",
       "75%                 -1.973979e-02               3.343646e-03   \n",
       "max                  2.346463e+01               1.716247e+01   \n",
       "\n",
       "       card_Merch_state_zip_total_14  card_Merch_des_state_max_30  \\\n",
       "count                   9.639700e+04                 9.639700e+04   \n",
       "mean                    2.475414e-16                -1.357099e-15   \n",
       "std                     1.000000e+00                 1.000000e+00   \n",
       "min                    -3.623744e-01                -6.023596e-01   \n",
       "25%                    -3.216869e-01                -5.434950e-01   \n",
       "50%                    -2.395073e-01                -3.618889e-01   \n",
       "75%                    -1.881494e-02                 1.111025e-01   \n",
       "max                     2.019480e+01                 1.290327e+01   \n",
       "\n",
       "       card_Merch_des_zip_max_30  card_Merch_des_state_zip_max_30  \\\n",
       "count               9.639700e+04                     9.639700e+04   \n",
       "mean               -3.832563e-15                     3.024862e-15   \n",
       "std                 1.000000e+00                     1.000000e+00   \n",
       "min                -6.012590e-01                    -6.012505e-01   \n",
       "25%                -5.426602e-01                    -5.426519e-01   \n",
       "50%                -3.613088e-01                    -3.613008e-01   \n",
       "75%                 1.104928e-01                     1.105000e-01   \n",
       "max                 1.290703e+01                     1.290702e+01   \n",
       "\n",
       "       card_Merch_num_des_zip_total_0  card_Merch_des_state_zip_total_30  \n",
       "count                    9.639700e+04                       9.639700e+04  \n",
       "mean                    -5.718466e-16                       1.812779e-15  \n",
       "std                      1.000000e+00                       1.000000e+00  \n",
       "min                     -3.933519e-01                      -3.649256e-01  \n",
       "25%                     -3.587629e-01                      -3.377712e-01  \n",
       "50%                     -2.696569e-01                      -2.593960e-01  \n",
       "75%                     -1.612438e-03                      -2.448431e-02  \n",
       "max                      2.090492e+01                       1.846526e+01  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = (X_no_scaling - X_no_scaling.mean()) / X_no_scaling.std()\n",
    "\n",
    "# use this to cap variables. For some problems it helps\n",
    "Clip = 10\n",
    "\n",
    "# push in any outlier values, then rescale\n",
    "X.clip(-1*Clip, Clip, inplace=True)\n",
    "\n",
    "# Now redo the zscaling after clipping\n",
    "X = (X - X.mean()) / X.std()\n",
    "X.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# separate data into modeling (traintest) and out of time. Here I'm using the record number to do this separation.\n",
    "# you need to change this oot record number to whatever is appropriate for your data\n",
    "oot_recnum = 84299\n",
    "\n",
    "X_trntst = X[0:oot_recnum]\n",
    "Y_trntst = Y_save[0:oot_recnum]\n",
    "\n",
    "X_oot = X[oot_recnum:]\n",
    "Y_oot = Y_save[oot_recnum:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_oot_orig = X_oot.copy()\n",
    "pd.options.mode.chained_assignment = None  # default='warn'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can comment in/out any of these model cells and just explore one model type. You can also just rerun that single cell multiple times (hit shift-enter on that cell) as you manually explore different model hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "340\n",
      "32\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>NVARS</th>\n",
       "      <th>Parameters</th>\n",
       "      <th>Trn</th>\n",
       "      <th>Tst</th>\n",
       "      <th>OOT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>log reg</td>\n",
       "      <td>10.0</td>\n",
       "      <td>penalty='none'</td>\n",
       "      <td>0.608696</td>\n",
       "      <td>0.671815</td>\n",
       "      <td>0.251397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>log reg</td>\n",
       "      <td>10.0</td>\n",
       "      <td>penalty='none'</td>\n",
       "      <td>0.632166</td>\n",
       "      <td>0.634921</td>\n",
       "      <td>0.346369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>log reg</td>\n",
       "      <td>10.0</td>\n",
       "      <td>penalty='none'</td>\n",
       "      <td>0.625600</td>\n",
       "      <td>0.647059</td>\n",
       "      <td>0.284916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>log reg</td>\n",
       "      <td>10.0</td>\n",
       "      <td>penalty='none'</td>\n",
       "      <td>0.635922</td>\n",
       "      <td>0.622137</td>\n",
       "      <td>0.357542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>log reg</td>\n",
       "      <td>10.0</td>\n",
       "      <td>penalty='none'</td>\n",
       "      <td>0.643087</td>\n",
       "      <td>0.608527</td>\n",
       "      <td>0.279330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2995</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2996</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2997</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2998</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2999</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3000 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Model  NVARS      Parameters       Trn       Tst       OOT\n",
       "0     log reg   10.0  penalty='none'  0.608696  0.671815  0.251397\n",
       "1     log reg   10.0  penalty='none'  0.632166  0.634921  0.346369\n",
       "2     log reg   10.0  penalty='none'  0.625600  0.647059  0.284916\n",
       "3     log reg   10.0  penalty='none'  0.635922  0.622137  0.357542\n",
       "4     log reg   10.0  penalty='none'  0.643087  0.608527  0.279330\n",
       "...       ...    ...             ...       ...       ...       ...\n",
       "2995      NaN    NaN             NaN       NaN       NaN       NaN\n",
       "2996      NaN    NaN             NaN       NaN       NaN       NaN\n",
       "2997      NaN    NaN             NaN       NaN       NaN       NaN\n",
       "2998      NaN    NaN             NaN       NaN       NaN       NaN\n",
       "2999      NaN    NaN             NaN       NaN       NaN       NaN\n",
       "\n",
       "[3000 rows x 6 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "try:\n",
    "    Modeling_output = pd.read_csv('Modeling_output.csv').iloc[:, 1:]\n",
    "    counter = Modeling_output[Modeling_output['Model'].isnull()].index[0]\n",
    "    model_counter = len(Modeling_output[['Model', 'NVARS', 'Parameters']].drop_duplicates().dropna(subset='Model'))\n",
    "    print(counter)\n",
    "    print(model_counter)\n",
    "\n",
    "except:\n",
    "    Modeling_output = pd.DataFrame(columns=['Model', 'NVARS', 'Parameters', 'Trn','Tst','OOT'],index=range(3000))\n",
    "    counter = 0\n",
    "    model_counter = 0\n",
    "\n",
    "Modeling_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def model_execution(model_name, algorithm, X, Y, X_oot, Y_oot, test_size = .3, nitermax = 10, Parameters_setting = \"\",\n",
    "                    print_bool = True):\n",
    "    \n",
    "    global Modeling_output, counter, model_counter, NVARS, output\n",
    "\n",
    "    FDR3 = pd.DataFrame(np.zeros((nitermax, 3)), columns=('trn', 'tst', 'oot'))\n",
    "    \n",
    "    if Parameters_setting == \"\": Parameters_setting = str(algorithm)\n",
    "    Parameters_setting = Parameters_setting.replace(' ', '').replace('\\n', '').replace(',', ', ')\n",
    "    Parameters_setting = Parameters_setting.split('(', 1)[1][:-1]\n",
    "    \n",
    "    for niter in range(nitermax):\n",
    "        X_trn, X_tst, Y_trn, Y_tst = train_test_split(X, Y, test_size = test_size)\n",
    "\n",
    "        model = algorithm\n",
    "\n",
    "        X_oot_copied = X_oot.copy()\n",
    "        X_trn_save = X_trn.copy()\n",
    "        Y_trn_save = Y_trn.copy()\n",
    "\n",
    "        model.fit(X_trn, Y_trn.values.ravel())\n",
    "\n",
    "        def prediction_function(X_splited, y_splited, name):\n",
    "\n",
    "            predictions = model.predict_proba(X_splited)[:,1]\n",
    "            X_splited['predicted'] = predictions\n",
    "            X_splited['Fraud'] = y_splited['Fraud']\n",
    "            topRows = int(round(X_splited.shape[0]*0.03))\n",
    "            temp = X_splited.sort_values('predicted',ascending=False).head(topRows)\n",
    "            needed = temp.loc[:,'Fraud']\n",
    "            FDR3.loc[niter, name] = sum(needed)/sum(X_splited.loc[:,'Fraud'])\n",
    "            \n",
    "            return X_splited\n",
    "\n",
    "        X_trn = prediction_function(X_trn, Y_trn_save, 'trn')\n",
    "        X_tst = prediction_function(X_tst, Y_tst, 'tst')\n",
    "        X_oot_copied = prediction_function(X_oot_copied, Y_oot, 'oot')\n",
    "\n",
    "        if print_bool == True: print(niter,\n",
    "                                     FDR3.loc[niter, 'trn'],\n",
    "                                     FDR3.loc[niter, 'tst'],\n",
    "                                     FDR3.loc[niter, 'oot'])\n",
    "\n",
    "        Modeling_output.iloc[counter] = [model_name,\n",
    "                                         NVARS,\n",
    "                                         Parameters_setting,\n",
    "                                         FDR3.loc[niter, 'trn'],\n",
    "                                         FDR3.loc[niter, 'tst'],\n",
    "                                         FDR3.loc[niter, 'oot']]\n",
    "        counter = counter + 1\n",
    "        Modeling_output.to_csv('Modeling_output.csv') # KK: save my progress\n",
    "\n",
    "    if print_bool == True: print(FDR3.mean())\n",
    "    model_counter = model_counter + 1\n",
    "    \n",
    "    df = Modeling_output.dropna()\n",
    "    output = (df.groupby(['Model', 'NVARS', 'Parameters'])\n",
    "              .agg({'Trn':['mean','std'],'Tst':['mean','std'],'OOT':['mean','std']}))\n",
    "    output = output.sort_values(by=['Model', ('Trn', 'mean'), 'NVARS'])\n",
    "    \n",
    "    return output.loc[model_name], {'X_trn': X_trn, 'X_tst': X_tst, 'X_oot': X_oot_copied, 'FDR3': FDR3}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.7657232704402516 0.7336065573770492 0.553072625698324\n",
      "1 0.757328990228013 0.7330827067669173 0.5195530726256983\n",
      "2 0.7439613526570048 0.7335907335907336 0.5307262569832403\n",
      "3 0.7615894039735099 0.6811594202898551 0.5418994413407822\n",
      "4 0.7738287560581584 0.7318007662835249 0.547486033519553\n",
      "5 0.7658536585365854 0.7358490566037735 0.5642458100558659\n",
      "6 0.7594108019639935 0.7063197026022305 0.553072625698324\n",
      "7 0.7554438860971524 0.7314487632508834 0.5027932960893855\n",
      "8 0.7568438003220612 0.7644787644787645 0.5754189944134078\n",
      "9 0.7339743589743589 0.74609375 0.5642458100558659\n",
      "trn    0.757396\n",
      "tst    0.729743\n",
      "oot    0.545251\n",
      "dtype: float64\n",
      "CPU times: total: 17.6 s\n",
      "Wall time: 18.1 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">Trn</th>\n",
       "      <th colspan=\"2\" halign=\"left\">Tst</th>\n",
       "      <th colspan=\"2\" halign=\"left\">OOT</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NVARS</th>\n",
       "      <th>Parameters</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"18\" valign=\"top\">10</th>\n",
       "      <th>min_impurity_decrease=0.001, n_estimators=20</th>\n",
       "      <td>0.607578</td>\n",
       "      <td>0.020832</td>\n",
       "      <td>0.599715</td>\n",
       "      <td>0.028385</td>\n",
       "      <td>0.370950</td>\n",
       "      <td>0.061323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min_impurity_decrease=0.0005, n_estimators=20</th>\n",
       "      <td>0.610582</td>\n",
       "      <td>0.023764</td>\n",
       "      <td>0.599603</td>\n",
       "      <td>0.025967</td>\n",
       "      <td>0.355307</td>\n",
       "      <td>0.059834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min_impurity_decrease=0.0002, n_estimators=20</th>\n",
       "      <td>0.663884</td>\n",
       "      <td>0.016461</td>\n",
       "      <td>0.668574</td>\n",
       "      <td>0.044979</td>\n",
       "      <td>0.477095</td>\n",
       "      <td>0.061323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min_impurity_decrease=0.0001, n_estimators=20</th>\n",
       "      <td>0.689549</td>\n",
       "      <td>0.013010</td>\n",
       "      <td>0.697797</td>\n",
       "      <td>0.021039</td>\n",
       "      <td>0.525698</td>\n",
       "      <td>0.020476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min_impurity_decrease=5e-05, n_estimators=20</th>\n",
       "      <td>0.730438</td>\n",
       "      <td>0.007634</td>\n",
       "      <td>0.699448</td>\n",
       "      <td>0.021043</td>\n",
       "      <td>0.533520</td>\n",
       "      <td>0.027652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min_impurity_decrease=3e-05, min_samples_leaf=30, min_samples_split=60, n_estimators=20</th>\n",
       "      <td>0.744927</td>\n",
       "      <td>0.014208</td>\n",
       "      <td>0.723578</td>\n",
       "      <td>0.025869</td>\n",
       "      <td>0.548603</td>\n",
       "      <td>0.022928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min_impurity_decrease=2e-05, min_samples_leaf=30, min_samples_split=60, n_estimators=20</th>\n",
       "      <td>0.753169</td>\n",
       "      <td>0.017687</td>\n",
       "      <td>0.736335</td>\n",
       "      <td>0.019346</td>\n",
       "      <td>0.539665</td>\n",
       "      <td>0.017706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min_impurity_decrease=3e-05, min_samples_leaf=15, min_samples_split=30, n_estimators=20</th>\n",
       "      <td>0.754914</td>\n",
       "      <td>0.017924</td>\n",
       "      <td>0.719545</td>\n",
       "      <td>0.033259</td>\n",
       "      <td>0.540223</td>\n",
       "      <td>0.013948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min_impurity_decrease=1e-05, min_samples_leaf=60, min_samples_split=120, n_estimators=20</th>\n",
       "      <td>0.757396</td>\n",
       "      <td>0.011381</td>\n",
       "      <td>0.729743</td>\n",
       "      <td>0.022282</td>\n",
       "      <td>0.545251</td>\n",
       "      <td>0.022222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min_impurity_decrease=3e-05, n_estimators=20</th>\n",
       "      <td>0.764049</td>\n",
       "      <td>0.013384</td>\n",
       "      <td>0.744989</td>\n",
       "      <td>0.033854</td>\n",
       "      <td>0.524581</td>\n",
       "      <td>0.022723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min_impurity_decrease=5e-06, min_samples_leaf=60, min_samples_split=120, n_estimators=20</th>\n",
       "      <td>0.772599</td>\n",
       "      <td>0.009908</td>\n",
       "      <td>0.734021</td>\n",
       "      <td>0.018847</td>\n",
       "      <td>0.558659</td>\n",
       "      <td>0.009854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min_impurity_decrease=1e-05, min_samples_leaf=30, min_samples_split=60, n_estimators=20</th>\n",
       "      <td>0.778692</td>\n",
       "      <td>0.014256</td>\n",
       "      <td>0.760464</td>\n",
       "      <td>0.025871</td>\n",
       "      <td>0.549162</td>\n",
       "      <td>0.017479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min_impurity_decrease=5e-06, min_samples_leaf=30, min_samples_split=60, n_estimators=20</th>\n",
       "      <td>0.794411</td>\n",
       "      <td>0.009152</td>\n",
       "      <td>0.758528</td>\n",
       "      <td>0.021228</td>\n",
       "      <td>0.529609</td>\n",
       "      <td>0.025506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min_impurity_decrease=2e-05, n_estimators=20</th>\n",
       "      <td>0.801828</td>\n",
       "      <td>0.017241</td>\n",
       "      <td>0.735747</td>\n",
       "      <td>0.029652</td>\n",
       "      <td>0.536313</td>\n",
       "      <td>0.019708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min_impurity_decrease=1e-05, n_estimators=20</th>\n",
       "      <td>0.836526</td>\n",
       "      <td>0.010512</td>\n",
       "      <td>0.769749</td>\n",
       "      <td>0.034543</td>\n",
       "      <td>0.532402</td>\n",
       "      <td>0.015812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min_impurity_decrease=5e-06, n_estimators=20</th>\n",
       "      <td>0.873371</td>\n",
       "      <td>0.009299</td>\n",
       "      <td>0.761807</td>\n",
       "      <td>0.025555</td>\n",
       "      <td>0.530168</td>\n",
       "      <td>0.032517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min_impurity_decrease=3e-06, n_estimators=20</th>\n",
       "      <td>0.904986</td>\n",
       "      <td>0.007784</td>\n",
       "      <td>0.776628</td>\n",
       "      <td>0.012723</td>\n",
       "      <td>0.528492</td>\n",
       "      <td>0.019388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min_impurity_decrease=1e-06, n_estimators=20</th>\n",
       "      <td>0.958759</td>\n",
       "      <td>0.008489</td>\n",
       "      <td>0.770538</td>\n",
       "      <td>0.012618</td>\n",
       "      <td>0.515642</td>\n",
       "      <td>0.030718</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                               Trn            \\\n",
       "                                                              mean       std   \n",
       "NVARS Parameters                                                               \n",
       "10    min_impurity_decrease=0.001, n_estimators=20        0.607578  0.020832   \n",
       "      min_impurity_decrease=0.0005, n_estimators=20       0.610582  0.023764   \n",
       "      min_impurity_decrease=0.0002, n_estimators=20       0.663884  0.016461   \n",
       "      min_impurity_decrease=0.0001, n_estimators=20       0.689549  0.013010   \n",
       "      min_impurity_decrease=5e-05, n_estimators=20        0.730438  0.007634   \n",
       "      min_impurity_decrease=3e-05, min_samples_leaf=3...  0.744927  0.014208   \n",
       "      min_impurity_decrease=2e-05, min_samples_leaf=3...  0.753169  0.017687   \n",
       "      min_impurity_decrease=3e-05, min_samples_leaf=1...  0.754914  0.017924   \n",
       "      min_impurity_decrease=1e-05, min_samples_leaf=6...  0.757396  0.011381   \n",
       "      min_impurity_decrease=3e-05, n_estimators=20        0.764049  0.013384   \n",
       "      min_impurity_decrease=5e-06, min_samples_leaf=6...  0.772599  0.009908   \n",
       "      min_impurity_decrease=1e-05, min_samples_leaf=3...  0.778692  0.014256   \n",
       "      min_impurity_decrease=5e-06, min_samples_leaf=3...  0.794411  0.009152   \n",
       "      min_impurity_decrease=2e-05, n_estimators=20        0.801828  0.017241   \n",
       "      min_impurity_decrease=1e-05, n_estimators=20        0.836526  0.010512   \n",
       "      min_impurity_decrease=5e-06, n_estimators=20        0.873371  0.009299   \n",
       "      min_impurity_decrease=3e-06, n_estimators=20        0.904986  0.007784   \n",
       "      min_impurity_decrease=1e-06, n_estimators=20        0.958759  0.008489   \n",
       "\n",
       "                                                               Tst            \\\n",
       "                                                              mean       std   \n",
       "NVARS Parameters                                                               \n",
       "10    min_impurity_decrease=0.001, n_estimators=20        0.599715  0.028385   \n",
       "      min_impurity_decrease=0.0005, n_estimators=20       0.599603  0.025967   \n",
       "      min_impurity_decrease=0.0002, n_estimators=20       0.668574  0.044979   \n",
       "      min_impurity_decrease=0.0001, n_estimators=20       0.697797  0.021039   \n",
       "      min_impurity_decrease=5e-05, n_estimators=20        0.699448  0.021043   \n",
       "      min_impurity_decrease=3e-05, min_samples_leaf=3...  0.723578  0.025869   \n",
       "      min_impurity_decrease=2e-05, min_samples_leaf=3...  0.736335  0.019346   \n",
       "      min_impurity_decrease=3e-05, min_samples_leaf=1...  0.719545  0.033259   \n",
       "      min_impurity_decrease=1e-05, min_samples_leaf=6...  0.729743  0.022282   \n",
       "      min_impurity_decrease=3e-05, n_estimators=20        0.744989  0.033854   \n",
       "      min_impurity_decrease=5e-06, min_samples_leaf=6...  0.734021  0.018847   \n",
       "      min_impurity_decrease=1e-05, min_samples_leaf=3...  0.760464  0.025871   \n",
       "      min_impurity_decrease=5e-06, min_samples_leaf=3...  0.758528  0.021228   \n",
       "      min_impurity_decrease=2e-05, n_estimators=20        0.735747  0.029652   \n",
       "      min_impurity_decrease=1e-05, n_estimators=20        0.769749  0.034543   \n",
       "      min_impurity_decrease=5e-06, n_estimators=20        0.761807  0.025555   \n",
       "      min_impurity_decrease=3e-06, n_estimators=20        0.776628  0.012723   \n",
       "      min_impurity_decrease=1e-06, n_estimators=20        0.770538  0.012618   \n",
       "\n",
       "                                                               OOT            \n",
       "                                                              mean       std  \n",
       "NVARS Parameters                                                              \n",
       "10    min_impurity_decrease=0.001, n_estimators=20        0.370950  0.061323  \n",
       "      min_impurity_decrease=0.0005, n_estimators=20       0.355307  0.059834  \n",
       "      min_impurity_decrease=0.0002, n_estimators=20       0.477095  0.061323  \n",
       "      min_impurity_decrease=0.0001, n_estimators=20       0.525698  0.020476  \n",
       "      min_impurity_decrease=5e-05, n_estimators=20        0.533520  0.027652  \n",
       "      min_impurity_decrease=3e-05, min_samples_leaf=3...  0.548603  0.022928  \n",
       "      min_impurity_decrease=2e-05, min_samples_leaf=3...  0.539665  0.017706  \n",
       "      min_impurity_decrease=3e-05, min_samples_leaf=1...  0.540223  0.013948  \n",
       "      min_impurity_decrease=1e-05, min_samples_leaf=6...  0.545251  0.022222  \n",
       "      min_impurity_decrease=3e-05, n_estimators=20        0.524581  0.022723  \n",
       "      min_impurity_decrease=5e-06, min_samples_leaf=6...  0.558659  0.009854  \n",
       "      min_impurity_decrease=1e-05, min_samples_leaf=3...  0.549162  0.017479  \n",
       "      min_impurity_decrease=5e-06, min_samples_leaf=3...  0.529609  0.025506  \n",
       "      min_impurity_decrease=2e-05, n_estimators=20        0.536313  0.019708  \n",
       "      min_impurity_decrease=1e-05, n_estimators=20        0.532402  0.015812  \n",
       "      min_impurity_decrease=5e-06, n_estimators=20        0.530168  0.032517  \n",
       "      min_impurity_decrease=3e-06, n_estimators=20        0.528492  0.019388  \n",
       "      min_impurity_decrease=1e-06, n_estimators=20        0.515642  0.030718  "
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# RF\n",
    "model_execution(model_name = 'RF',\n",
    "                algorithm = RandomForestClassifier(n_estimators=20, min_impurity_decrease=0.00001,\n",
    "                                                  min_samples_leaf=30, min_samples_split=60),\n",
    "                X = X_trntst, Y = Y_trntst,\n",
    "                X_oot = X_oot_orig, Y_oot = Y_oot)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loop trn tst oot 1 0.6972129146638586 0.6760813424563341 0.5189944134078213\n",
      "loop trn tst oot 2 0.699227659512366 0.6870963708691395 0.5033519553072626\n",
      "loop trn tst oot 3 0.6987705379114497 0.695152131142775 0.5139664804469274\n",
      "loop trn tst oot 4 0.7101820953599175 0.6893919032807113 0.5145251396648044\n",
      "loop trn tst oot 5 0.7129081024701606 0.6877916383663998 0.5318435754189945\n",
      "loop trn tst oot 6 0.7215336003406353 0.7105916080660671 0.5268156424581005\n",
      "loop trn tst oot 7 0.743085267448987 0.7124376358279348 0.5374301675977655\n",
      "loop trn tst oot 8 0.7692985274277016 0.7281438297119807 0.5195530726256985\n",
      "loop trn tst oot 9 0.7962425254618154 0.7664751209174913 0.5329608938547485\n",
      "loop trn tst oot 10 0.8350979561323928 0.772015904979008 0.5312849162011173\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "training = []\n",
    "testing = []\n",
    "oot = []\n",
    "for i in range(1,11,1):\n",
    "    \n",
    "    min_imp_decrease = 0.00011 - (i*0.00001)\n",
    "    model_output = model_execution(model_name = 'RF',\n",
    "                                   algorithm = RandomForestClassifier(min_impurity_decrease = min_imp_decrease,\n",
    "                                                                      n_estimators=20),\n",
    "                                   X = X_trntst, Y = Y_trntst,\n",
    "                                   X_oot = X_oot_orig, Y_oot = Y_oot,\n",
    "                                   print_bool=False)\n",
    "    results = model_output[1]['FDR3']\n",
    "\n",
    "    results_mean_trn = results['trn'].mean()\n",
    "    results_mean_tst = results['tst'].mean()\n",
    "    results_mean_oot = results['oot'].mean()\n",
    "    print('loop', 'trn', 'tst', 'oot', i, results_mean_trn, results_mean_tst, results_mean_oot)\n",
    "    training.append(results_mean_trn)\n",
    "    testing.append(results_mean_tst)\n",
    "    oot.append(results_mean_oot)\n",
    "\n",
    "table=pd.DataFrame({'min_impurity_decrease * 10,000': range(1,len(training)+1),'training':training,'testing':testing,'oot':oot})\n",
    "table['min_impurity_decrease * 10,000'] = (0.00011 - (table['min_impurity_decrease * 10,000']*0.00001)) * 10_000\n",
    "table.set_index('min_impurity_decrease * 10,000',inplace=True)\n",
    "table.plot().invert_xaxis()\n",
    "plt.savefig('RandomForest_min_impurity_decrease.pdf', format='pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model comparison plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>NVARS</th>\n",
       "      <th>Parameters</th>\n",
       "      <th>Trn</th>\n",
       "      <th>Tst</th>\n",
       "      <th>OOT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>log reg</td>\n",
       "      <td>10.0</td>\n",
       "      <td>penalty='none'</td>\n",
       "      <td>0.608696</td>\n",
       "      <td>0.671815</td>\n",
       "      <td>0.251397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>log reg</td>\n",
       "      <td>10.0</td>\n",
       "      <td>penalty='none'</td>\n",
       "      <td>0.632166</td>\n",
       "      <td>0.634921</td>\n",
       "      <td>0.346369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>log reg</td>\n",
       "      <td>10.0</td>\n",
       "      <td>penalty='none'</td>\n",
       "      <td>0.625600</td>\n",
       "      <td>0.647059</td>\n",
       "      <td>0.284916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>log reg</td>\n",
       "      <td>10.0</td>\n",
       "      <td>penalty='none'</td>\n",
       "      <td>0.635922</td>\n",
       "      <td>0.622137</td>\n",
       "      <td>0.357542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>log reg</td>\n",
       "      <td>10.0</td>\n",
       "      <td>penalty='none'</td>\n",
       "      <td>0.643087</td>\n",
       "      <td>0.608527</td>\n",
       "      <td>0.279330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>log reg</td>\n",
       "      <td>10.0</td>\n",
       "      <td>penalty='none'</td>\n",
       "      <td>0.631173</td>\n",
       "      <td>0.612069</td>\n",
       "      <td>0.279330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>log reg</td>\n",
       "      <td>10.0</td>\n",
       "      <td>penalty='none'</td>\n",
       "      <td>0.609477</td>\n",
       "      <td>0.671642</td>\n",
       "      <td>0.340782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>log reg</td>\n",
       "      <td>10.0</td>\n",
       "      <td>penalty='none'</td>\n",
       "      <td>0.650641</td>\n",
       "      <td>0.585938</td>\n",
       "      <td>0.307263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>log reg</td>\n",
       "      <td>10.0</td>\n",
       "      <td>penalty='none'</td>\n",
       "      <td>0.608280</td>\n",
       "      <td>0.686508</td>\n",
       "      <td>0.256983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>log reg</td>\n",
       "      <td>10.0</td>\n",
       "      <td>penalty='none'</td>\n",
       "      <td>0.617845</td>\n",
       "      <td>0.615385</td>\n",
       "      <td>0.245810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>DT</td>\n",
       "      <td>10.0</td>\n",
       "      <td>min_impurity_decrease=5e-05</td>\n",
       "      <td>0.679549</td>\n",
       "      <td>0.656371</td>\n",
       "      <td>0.497207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>DT</td>\n",
       "      <td>10.0</td>\n",
       "      <td>min_impurity_decrease=5e-05</td>\n",
       "      <td>0.681518</td>\n",
       "      <td>0.653285</td>\n",
       "      <td>0.324022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>DT</td>\n",
       "      <td>10.0</td>\n",
       "      <td>min_impurity_decrease=5e-05</td>\n",
       "      <td>0.681818</td>\n",
       "      <td>0.602273</td>\n",
       "      <td>0.407821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>DT</td>\n",
       "      <td>10.0</td>\n",
       "      <td>min_impurity_decrease=5e-05</td>\n",
       "      <td>0.678797</td>\n",
       "      <td>0.689516</td>\n",
       "      <td>0.296089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>DT</td>\n",
       "      <td>10.0</td>\n",
       "      <td>min_impurity_decrease=5e-05</td>\n",
       "      <td>0.677578</td>\n",
       "      <td>0.654275</td>\n",
       "      <td>0.351955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>DT</td>\n",
       "      <td>10.0</td>\n",
       "      <td>min_impurity_decrease=5e-05</td>\n",
       "      <td>0.686275</td>\n",
       "      <td>0.667910</td>\n",
       "      <td>0.379888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>DT</td>\n",
       "      <td>10.0</td>\n",
       "      <td>min_impurity_decrease=5e-05</td>\n",
       "      <td>0.666139</td>\n",
       "      <td>0.633065</td>\n",
       "      <td>0.458101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>DT</td>\n",
       "      <td>10.0</td>\n",
       "      <td>min_impurity_decrease=5e-05</td>\n",
       "      <td>0.646382</td>\n",
       "      <td>0.610294</td>\n",
       "      <td>0.458101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>DT</td>\n",
       "      <td>10.0</td>\n",
       "      <td>min_impurity_decrease=5e-05</td>\n",
       "      <td>0.660287</td>\n",
       "      <td>0.656126</td>\n",
       "      <td>0.307263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>DT</td>\n",
       "      <td>10.0</td>\n",
       "      <td>min_impurity_decrease=5e-05</td>\n",
       "      <td>0.675325</td>\n",
       "      <td>0.643939</td>\n",
       "      <td>0.385475</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Model  NVARS                   Parameters       Trn       Tst       OOT\n",
       "0   log reg   10.0               penalty='none'  0.608696  0.671815  0.251397\n",
       "1   log reg   10.0               penalty='none'  0.632166  0.634921  0.346369\n",
       "2   log reg   10.0               penalty='none'  0.625600  0.647059  0.284916\n",
       "3   log reg   10.0               penalty='none'  0.635922  0.622137  0.357542\n",
       "4   log reg   10.0               penalty='none'  0.643087  0.608527  0.279330\n",
       "5   log reg   10.0               penalty='none'  0.631173  0.612069  0.279330\n",
       "6   log reg   10.0               penalty='none'  0.609477  0.671642  0.340782\n",
       "7   log reg   10.0               penalty='none'  0.650641  0.585938  0.307263\n",
       "8   log reg   10.0               penalty='none'  0.608280  0.686508  0.256983\n",
       "9   log reg   10.0               penalty='none'  0.617845  0.615385  0.245810\n",
       "20       DT   10.0  min_impurity_decrease=5e-05  0.679549  0.656371  0.497207\n",
       "21       DT   10.0  min_impurity_decrease=5e-05  0.681518  0.653285  0.324022\n",
       "22       DT   10.0  min_impurity_decrease=5e-05  0.681818  0.602273  0.407821\n",
       "23       DT   10.0  min_impurity_decrease=5e-05  0.678797  0.689516  0.296089\n",
       "24       DT   10.0  min_impurity_decrease=5e-05  0.677578  0.654275  0.351955\n",
       "25       DT   10.0  min_impurity_decrease=5e-05  0.686275  0.667910  0.379888\n",
       "26       DT   10.0  min_impurity_decrease=5e-05  0.666139  0.633065  0.458101\n",
       "27       DT   10.0  min_impurity_decrease=5e-05  0.646382  0.610294  0.458101\n",
       "28       DT   10.0  min_impurity_decrease=5e-05  0.660287  0.656126  0.307263\n",
       "29       DT   10.0  min_impurity_decrease=5e-05  0.675325  0.643939  0.385475"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = Modeling_output.dropna()\n",
    "df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(330, 6)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Type</th>\n",
       "      <th>Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>log reg</td>\n",
       "      <td>Trn</td>\n",
       "      <td>0.608696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>log reg</td>\n",
       "      <td>Trn</td>\n",
       "      <td>0.632166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>log reg</td>\n",
       "      <td>Trn</td>\n",
       "      <td>0.625600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>log reg</td>\n",
       "      <td>Trn</td>\n",
       "      <td>0.635922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>log reg</td>\n",
       "      <td>Trn</td>\n",
       "      <td>0.643087</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Model Type     Value\n",
       "0  log reg  Trn  0.608696\n",
       "1  log reg  Trn  0.632166\n",
       "2  log reg  Trn  0.625600\n",
       "3  log reg  Trn  0.635922\n",
       "4  log reg  Trn  0.643087"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_unpivot = df.melt( id_vars='Model', value_vars=['Trn','Tst','OOT'], var_name=['Type'], value_name='Value')\n",
    "df_compare = df_unpivot[(df_unpivot['Type']=='Trn') | (df_unpivot['Type']=='Tst') | (df_unpivot['Type']=='OOT')]\n",
    "df_compare.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = df.groupby(['Model', 'NVARS', 'Parameters']).agg({'Trn':['mean','std'],'Tst':['mean','std'],'OOT':['mean','std']})\n",
    "output.reset_index().to_excel('output.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">Trn</th>\n",
       "      <th colspan=\"2\" halign=\"left\">Tst</th>\n",
       "      <th colspan=\"2\" halign=\"left\">OOT</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <th>NVARS</th>\n",
       "      <th>Parameters</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">DT</th>\n",
       "      <th rowspan=\"6\" valign=\"top\">10.0</th>\n",
       "      <th>min_impurity_decrease=1e-05</th>\n",
       "      <td>0.744013</td>\n",
       "      <td>0.020672</td>\n",
       "      <td>0.596342</td>\n",
       "      <td>0.018899</td>\n",
       "      <td>0.335754</td>\n",
       "      <td>0.087442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min_impurity_decrease=2.5e-05</th>\n",
       "      <td>0.703388</td>\n",
       "      <td>0.011972</td>\n",
       "      <td>0.645009</td>\n",
       "      <td>0.032123</td>\n",
       "      <td>0.355866</td>\n",
       "      <td>0.075965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min_impurity_decrease=2e-05</th>\n",
       "      <td>0.710625</td>\n",
       "      <td>0.017125</td>\n",
       "      <td>0.648441</td>\n",
       "      <td>0.018670</td>\n",
       "      <td>0.389944</td>\n",
       "      <td>0.071193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min_impurity_decrease=3.5e-05</th>\n",
       "      <td>0.695014</td>\n",
       "      <td>0.010661</td>\n",
       "      <td>0.654384</td>\n",
       "      <td>0.026308</td>\n",
       "      <td>0.379330</td>\n",
       "      <td>0.071079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min_impurity_decrease=3e-05</th>\n",
       "      <td>0.695579</td>\n",
       "      <td>0.010757</td>\n",
       "      <td>0.667114</td>\n",
       "      <td>0.020939</td>\n",
       "      <td>0.397765</td>\n",
       "      <td>0.087456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min_impurity_decrease=5e-05</th>\n",
       "      <td>0.673367</td>\n",
       "      <td>0.012226</td>\n",
       "      <td>0.646705</td>\n",
       "      <td>0.025946</td>\n",
       "      <td>0.386592</td>\n",
       "      <td>0.068765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"11\" valign=\"top\">LGBM</th>\n",
       "      <th rowspan=\"11\" valign=\"top\">10.0</th>\n",
       "      <th>min_child_samples=1000, min_split_gain=1</th>\n",
       "      <td>0.825497</td>\n",
       "      <td>0.004667</td>\n",
       "      <td>0.779005</td>\n",
       "      <td>0.010796</td>\n",
       "      <td>0.441341</td>\n",
       "      <td>0.009854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min_child_samples=1000, min_split_gain=5</th>\n",
       "      <td>0.770569</td>\n",
       "      <td>0.016328</td>\n",
       "      <td>0.730580</td>\n",
       "      <td>0.016959</td>\n",
       "      <td>0.397207</td>\n",
       "      <td>0.015680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min_child_samples=500, min_split_gain=1</th>\n",
       "      <td>0.850522</td>\n",
       "      <td>0.008528</td>\n",
       "      <td>0.785728</td>\n",
       "      <td>0.021914</td>\n",
       "      <td>0.461453</td>\n",
       "      <td>0.039696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min_child_samples=500, min_split_gain=1, n_estimators=10</th>\n",
       "      <td>0.758200</td>\n",
       "      <td>0.009633</td>\n",
       "      <td>0.719070</td>\n",
       "      <td>0.021037</td>\n",
       "      <td>0.413408</td>\n",
       "      <td>0.010534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min_child_samples=500, min_split_gain=1, n_estimators=50, num_leaves=15</th>\n",
       "      <td>0.811324</td>\n",
       "      <td>0.010840</td>\n",
       "      <td>0.781816</td>\n",
       "      <td>0.026023</td>\n",
       "      <td>0.454190</td>\n",
       "      <td>0.031055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min_child_samples=500, min_split_gain=1, n_estimators=50, num_leaves=19</th>\n",
       "      <td>0.834033</td>\n",
       "      <td>0.012280</td>\n",
       "      <td>0.784640</td>\n",
       "      <td>0.020491</td>\n",
       "      <td>0.459777</td>\n",
       "      <td>0.036874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min_child_samples=500, min_split_gain=1, n_estimators=50, num_leaves=30</th>\n",
       "      <td>0.850847</td>\n",
       "      <td>0.014004</td>\n",
       "      <td>0.788391</td>\n",
       "      <td>0.030050</td>\n",
       "      <td>0.458659</td>\n",
       "      <td>0.038745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min_child_samples=500, min_split_gain=5</th>\n",
       "      <td>0.782929</td>\n",
       "      <td>0.009246</td>\n",
       "      <td>0.755920</td>\n",
       "      <td>0.025779</td>\n",
       "      <td>0.422905</td>\n",
       "      <td>0.023266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min_split_gain=10</th>\n",
       "      <td>0.797722</td>\n",
       "      <td>0.011248</td>\n",
       "      <td>0.736992</td>\n",
       "      <td>0.031277</td>\n",
       "      <td>0.444134</td>\n",
       "      <td>0.022540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min_split_gain=20</th>\n",
       "      <td>0.762184</td>\n",
       "      <td>0.015578</td>\n",
       "      <td>0.727802</td>\n",
       "      <td>0.029099</td>\n",
       "      <td>0.424022</td>\n",
       "      <td>0.068038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min_split_gain=50</th>\n",
       "      <td>0.729639</td>\n",
       "      <td>0.022413</td>\n",
       "      <td>0.709074</td>\n",
       "      <td>0.022424</td>\n",
       "      <td>0.412291</td>\n",
       "      <td>0.060331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">NN</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">10.0</th>\n",
       "      <th>alpha=0.01, hidden_layer_sizes=(10, 10)</th>\n",
       "      <td>0.710103</td>\n",
       "      <td>0.011161</td>\n",
       "      <td>0.709848</td>\n",
       "      <td>0.021295</td>\n",
       "      <td>0.528492</td>\n",
       "      <td>0.038812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha=0.01, hidden_layer_sizes=(15, 15), learning_rate_init=0.01</th>\n",
       "      <td>0.719660</td>\n",
       "      <td>0.009008</td>\n",
       "      <td>0.702218</td>\n",
       "      <td>0.021441</td>\n",
       "      <td>0.553073</td>\n",
       "      <td>0.008734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hidden_layer_sizes=(10, 10)</th>\n",
       "      <td>0.712017</td>\n",
       "      <td>0.013014</td>\n",
       "      <td>0.712086</td>\n",
       "      <td>0.020862</td>\n",
       "      <td>0.529330</td>\n",
       "      <td>0.026445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hidden_layer_sizes=(15, 15)</th>\n",
       "      <td>0.731442</td>\n",
       "      <td>0.014565</td>\n",
       "      <td>0.707038</td>\n",
       "      <td>0.018274</td>\n",
       "      <td>0.525698</td>\n",
       "      <td>0.033255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hidden_layer_sizes=(20, 20)</th>\n",
       "      <td>0.747975</td>\n",
       "      <td>0.017636</td>\n",
       "      <td>0.721336</td>\n",
       "      <td>0.022990</td>\n",
       "      <td>0.494972</td>\n",
       "      <td>0.056083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"8\" valign=\"top\">RF</th>\n",
       "      <th rowspan=\"8\" valign=\"top\">10.0</th>\n",
       "      <th>min_impurity_decrease=1e-05, min_samples_leaf=30, min_samples_split=60, n_estimators=20</th>\n",
       "      <td>0.778692</td>\n",
       "      <td>0.014256</td>\n",
       "      <td>0.760464</td>\n",
       "      <td>0.025871</td>\n",
       "      <td>0.549162</td>\n",
       "      <td>0.017479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min_impurity_decrease=1e-05, min_samples_leaf=60, min_samples_split=120, n_estimators=20</th>\n",
       "      <td>0.757396</td>\n",
       "      <td>0.011381</td>\n",
       "      <td>0.729743</td>\n",
       "      <td>0.022282</td>\n",
       "      <td>0.545251</td>\n",
       "      <td>0.022222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min_impurity_decrease=2e-05, min_samples_leaf=30, min_samples_split=60, n_estimators=20</th>\n",
       "      <td>0.753169</td>\n",
       "      <td>0.017687</td>\n",
       "      <td>0.736335</td>\n",
       "      <td>0.019346</td>\n",
       "      <td>0.539665</td>\n",
       "      <td>0.017706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min_impurity_decrease=2e-05, n_estimators=20</th>\n",
       "      <td>0.801828</td>\n",
       "      <td>0.017241</td>\n",
       "      <td>0.735747</td>\n",
       "      <td>0.029652</td>\n",
       "      <td>0.536313</td>\n",
       "      <td>0.019708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min_impurity_decrease=3e-05, min_samples_leaf=15, min_samples_split=30, n_estimators=20</th>\n",
       "      <td>0.754914</td>\n",
       "      <td>0.017924</td>\n",
       "      <td>0.719545</td>\n",
       "      <td>0.033259</td>\n",
       "      <td>0.540223</td>\n",
       "      <td>0.013948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min_impurity_decrease=3e-05, min_samples_leaf=30, min_samples_split=60, n_estimators=20</th>\n",
       "      <td>0.744927</td>\n",
       "      <td>0.014208</td>\n",
       "      <td>0.723578</td>\n",
       "      <td>0.025869</td>\n",
       "      <td>0.548603</td>\n",
       "      <td>0.022928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min_impurity_decrease=5e-06, min_samples_leaf=30, min_samples_split=60, n_estimators=20</th>\n",
       "      <td>0.794411</td>\n",
       "      <td>0.009152</td>\n",
       "      <td>0.758528</td>\n",
       "      <td>0.021228</td>\n",
       "      <td>0.529609</td>\n",
       "      <td>0.025506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min_impurity_decrease=5e-06, min_samples_leaf=60, min_samples_split=120, n_estimators=20</th>\n",
       "      <td>0.772599</td>\n",
       "      <td>0.009908</td>\n",
       "      <td>0.734021</td>\n",
       "      <td>0.018847</td>\n",
       "      <td>0.558659</td>\n",
       "      <td>0.009854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>log reg</th>\n",
       "      <th>10.0</th>\n",
       "      <th>penalty='none'</th>\n",
       "      <td>0.626289</td>\n",
       "      <td>0.014962</td>\n",
       "      <td>0.635600</td>\n",
       "      <td>0.032790</td>\n",
       "      <td>0.294972</td>\n",
       "      <td>0.041036</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                       Trn  \\\n",
       "                                                                      mean   \n",
       "Model   NVARS Parameters                                                     \n",
       "DT      10.0  min_impurity_decrease=1e-05                         0.744013   \n",
       "              min_impurity_decrease=2.5e-05                       0.703388   \n",
       "              min_impurity_decrease=2e-05                         0.710625   \n",
       "              min_impurity_decrease=3.5e-05                       0.695014   \n",
       "              min_impurity_decrease=3e-05                         0.695579   \n",
       "              min_impurity_decrease=5e-05                         0.673367   \n",
       "LGBM    10.0  min_child_samples=1000, min_split_gain=1            0.825497   \n",
       "              min_child_samples=1000, min_split_gain=5            0.770569   \n",
       "              min_child_samples=500, min_split_gain=1             0.850522   \n",
       "              min_child_samples=500, min_split_gain=1, n_esti...  0.758200   \n",
       "              min_child_samples=500, min_split_gain=1, n_esti...  0.811324   \n",
       "              min_child_samples=500, min_split_gain=1, n_esti...  0.834033   \n",
       "              min_child_samples=500, min_split_gain=1, n_esti...  0.850847   \n",
       "              min_child_samples=500, min_split_gain=5             0.782929   \n",
       "              min_split_gain=10                                   0.797722   \n",
       "              min_split_gain=20                                   0.762184   \n",
       "              min_split_gain=50                                   0.729639   \n",
       "NN      10.0  alpha=0.01, hidden_layer_sizes=(10, 10)             0.710103   \n",
       "              alpha=0.01, hidden_layer_sizes=(15, 15), learni...  0.719660   \n",
       "              hidden_layer_sizes=(10, 10)                         0.712017   \n",
       "              hidden_layer_sizes=(15, 15)                         0.731442   \n",
       "              hidden_layer_sizes=(20, 20)                         0.747975   \n",
       "RF      10.0  min_impurity_decrease=1e-05, min_samples_leaf=3...  0.778692   \n",
       "              min_impurity_decrease=1e-05, min_samples_leaf=6...  0.757396   \n",
       "              min_impurity_decrease=2e-05, min_samples_leaf=3...  0.753169   \n",
       "              min_impurity_decrease=2e-05, n_estimators=20        0.801828   \n",
       "              min_impurity_decrease=3e-05, min_samples_leaf=1...  0.754914   \n",
       "              min_impurity_decrease=3e-05, min_samples_leaf=3...  0.744927   \n",
       "              min_impurity_decrease=5e-06, min_samples_leaf=3...  0.794411   \n",
       "              min_impurity_decrease=5e-06, min_samples_leaf=6...  0.772599   \n",
       "log reg 10.0  penalty='none'                                      0.626289   \n",
       "\n",
       "                                                                            \\\n",
       "                                                                       std   \n",
       "Model   NVARS Parameters                                                     \n",
       "DT      10.0  min_impurity_decrease=1e-05                         0.020672   \n",
       "              min_impurity_decrease=2.5e-05                       0.011972   \n",
       "              min_impurity_decrease=2e-05                         0.017125   \n",
       "              min_impurity_decrease=3.5e-05                       0.010661   \n",
       "              min_impurity_decrease=3e-05                         0.010757   \n",
       "              min_impurity_decrease=5e-05                         0.012226   \n",
       "LGBM    10.0  min_child_samples=1000, min_split_gain=1            0.004667   \n",
       "              min_child_samples=1000, min_split_gain=5            0.016328   \n",
       "              min_child_samples=500, min_split_gain=1             0.008528   \n",
       "              min_child_samples=500, min_split_gain=1, n_esti...  0.009633   \n",
       "              min_child_samples=500, min_split_gain=1, n_esti...  0.010840   \n",
       "              min_child_samples=500, min_split_gain=1, n_esti...  0.012280   \n",
       "              min_child_samples=500, min_split_gain=1, n_esti...  0.014004   \n",
       "              min_child_samples=500, min_split_gain=5             0.009246   \n",
       "              min_split_gain=10                                   0.011248   \n",
       "              min_split_gain=20                                   0.015578   \n",
       "              min_split_gain=50                                   0.022413   \n",
       "NN      10.0  alpha=0.01, hidden_layer_sizes=(10, 10)             0.011161   \n",
       "              alpha=0.01, hidden_layer_sizes=(15, 15), learni...  0.009008   \n",
       "              hidden_layer_sizes=(10, 10)                         0.013014   \n",
       "              hidden_layer_sizes=(15, 15)                         0.014565   \n",
       "              hidden_layer_sizes=(20, 20)                         0.017636   \n",
       "RF      10.0  min_impurity_decrease=1e-05, min_samples_leaf=3...  0.014256   \n",
       "              min_impurity_decrease=1e-05, min_samples_leaf=6...  0.011381   \n",
       "              min_impurity_decrease=2e-05, min_samples_leaf=3...  0.017687   \n",
       "              min_impurity_decrease=2e-05, n_estimators=20        0.017241   \n",
       "              min_impurity_decrease=3e-05, min_samples_leaf=1...  0.017924   \n",
       "              min_impurity_decrease=3e-05, min_samples_leaf=3...  0.014208   \n",
       "              min_impurity_decrease=5e-06, min_samples_leaf=3...  0.009152   \n",
       "              min_impurity_decrease=5e-06, min_samples_leaf=6...  0.009908   \n",
       "log reg 10.0  penalty='none'                                      0.014962   \n",
       "\n",
       "                                                                       Tst  \\\n",
       "                                                                      mean   \n",
       "Model   NVARS Parameters                                                     \n",
       "DT      10.0  min_impurity_decrease=1e-05                         0.596342   \n",
       "              min_impurity_decrease=2.5e-05                       0.645009   \n",
       "              min_impurity_decrease=2e-05                         0.648441   \n",
       "              min_impurity_decrease=3.5e-05                       0.654384   \n",
       "              min_impurity_decrease=3e-05                         0.667114   \n",
       "              min_impurity_decrease=5e-05                         0.646705   \n",
       "LGBM    10.0  min_child_samples=1000, min_split_gain=1            0.779005   \n",
       "              min_child_samples=1000, min_split_gain=5            0.730580   \n",
       "              min_child_samples=500, min_split_gain=1             0.785728   \n",
       "              min_child_samples=500, min_split_gain=1, n_esti...  0.719070   \n",
       "              min_child_samples=500, min_split_gain=1, n_esti...  0.781816   \n",
       "              min_child_samples=500, min_split_gain=1, n_esti...  0.784640   \n",
       "              min_child_samples=500, min_split_gain=1, n_esti...  0.788391   \n",
       "              min_child_samples=500, min_split_gain=5             0.755920   \n",
       "              min_split_gain=10                                   0.736992   \n",
       "              min_split_gain=20                                   0.727802   \n",
       "              min_split_gain=50                                   0.709074   \n",
       "NN      10.0  alpha=0.01, hidden_layer_sizes=(10, 10)             0.709848   \n",
       "              alpha=0.01, hidden_layer_sizes=(15, 15), learni...  0.702218   \n",
       "              hidden_layer_sizes=(10, 10)                         0.712086   \n",
       "              hidden_layer_sizes=(15, 15)                         0.707038   \n",
       "              hidden_layer_sizes=(20, 20)                         0.721336   \n",
       "RF      10.0  min_impurity_decrease=1e-05, min_samples_leaf=3...  0.760464   \n",
       "              min_impurity_decrease=1e-05, min_samples_leaf=6...  0.729743   \n",
       "              min_impurity_decrease=2e-05, min_samples_leaf=3...  0.736335   \n",
       "              min_impurity_decrease=2e-05, n_estimators=20        0.735747   \n",
       "              min_impurity_decrease=3e-05, min_samples_leaf=1...  0.719545   \n",
       "              min_impurity_decrease=3e-05, min_samples_leaf=3...  0.723578   \n",
       "              min_impurity_decrease=5e-06, min_samples_leaf=3...  0.758528   \n",
       "              min_impurity_decrease=5e-06, min_samples_leaf=6...  0.734021   \n",
       "log reg 10.0  penalty='none'                                      0.635600   \n",
       "\n",
       "                                                                            \\\n",
       "                                                                       std   \n",
       "Model   NVARS Parameters                                                     \n",
       "DT      10.0  min_impurity_decrease=1e-05                         0.018899   \n",
       "              min_impurity_decrease=2.5e-05                       0.032123   \n",
       "              min_impurity_decrease=2e-05                         0.018670   \n",
       "              min_impurity_decrease=3.5e-05                       0.026308   \n",
       "              min_impurity_decrease=3e-05                         0.020939   \n",
       "              min_impurity_decrease=5e-05                         0.025946   \n",
       "LGBM    10.0  min_child_samples=1000, min_split_gain=1            0.010796   \n",
       "              min_child_samples=1000, min_split_gain=5            0.016959   \n",
       "              min_child_samples=500, min_split_gain=1             0.021914   \n",
       "              min_child_samples=500, min_split_gain=1, n_esti...  0.021037   \n",
       "              min_child_samples=500, min_split_gain=1, n_esti...  0.026023   \n",
       "              min_child_samples=500, min_split_gain=1, n_esti...  0.020491   \n",
       "              min_child_samples=500, min_split_gain=1, n_esti...  0.030050   \n",
       "              min_child_samples=500, min_split_gain=5             0.025779   \n",
       "              min_split_gain=10                                   0.031277   \n",
       "              min_split_gain=20                                   0.029099   \n",
       "              min_split_gain=50                                   0.022424   \n",
       "NN      10.0  alpha=0.01, hidden_layer_sizes=(10, 10)             0.021295   \n",
       "              alpha=0.01, hidden_layer_sizes=(15, 15), learni...  0.021441   \n",
       "              hidden_layer_sizes=(10, 10)                         0.020862   \n",
       "              hidden_layer_sizes=(15, 15)                         0.018274   \n",
       "              hidden_layer_sizes=(20, 20)                         0.022990   \n",
       "RF      10.0  min_impurity_decrease=1e-05, min_samples_leaf=3...  0.025871   \n",
       "              min_impurity_decrease=1e-05, min_samples_leaf=6...  0.022282   \n",
       "              min_impurity_decrease=2e-05, min_samples_leaf=3...  0.019346   \n",
       "              min_impurity_decrease=2e-05, n_estimators=20        0.029652   \n",
       "              min_impurity_decrease=3e-05, min_samples_leaf=1...  0.033259   \n",
       "              min_impurity_decrease=3e-05, min_samples_leaf=3...  0.025869   \n",
       "              min_impurity_decrease=5e-06, min_samples_leaf=3...  0.021228   \n",
       "              min_impurity_decrease=5e-06, min_samples_leaf=6...  0.018847   \n",
       "log reg 10.0  penalty='none'                                      0.032790   \n",
       "\n",
       "                                                                       OOT  \\\n",
       "                                                                      mean   \n",
       "Model   NVARS Parameters                                                     \n",
       "DT      10.0  min_impurity_decrease=1e-05                         0.335754   \n",
       "              min_impurity_decrease=2.5e-05                       0.355866   \n",
       "              min_impurity_decrease=2e-05                         0.389944   \n",
       "              min_impurity_decrease=3.5e-05                       0.379330   \n",
       "              min_impurity_decrease=3e-05                         0.397765   \n",
       "              min_impurity_decrease=5e-05                         0.386592   \n",
       "LGBM    10.0  min_child_samples=1000, min_split_gain=1            0.441341   \n",
       "              min_child_samples=1000, min_split_gain=5            0.397207   \n",
       "              min_child_samples=500, min_split_gain=1             0.461453   \n",
       "              min_child_samples=500, min_split_gain=1, n_esti...  0.413408   \n",
       "              min_child_samples=500, min_split_gain=1, n_esti...  0.454190   \n",
       "              min_child_samples=500, min_split_gain=1, n_esti...  0.459777   \n",
       "              min_child_samples=500, min_split_gain=1, n_esti...  0.458659   \n",
       "              min_child_samples=500, min_split_gain=5             0.422905   \n",
       "              min_split_gain=10                                   0.444134   \n",
       "              min_split_gain=20                                   0.424022   \n",
       "              min_split_gain=50                                   0.412291   \n",
       "NN      10.0  alpha=0.01, hidden_layer_sizes=(10, 10)             0.528492   \n",
       "              alpha=0.01, hidden_layer_sizes=(15, 15), learni...  0.553073   \n",
       "              hidden_layer_sizes=(10, 10)                         0.529330   \n",
       "              hidden_layer_sizes=(15, 15)                         0.525698   \n",
       "              hidden_layer_sizes=(20, 20)                         0.494972   \n",
       "RF      10.0  min_impurity_decrease=1e-05, min_samples_leaf=3...  0.549162   \n",
       "              min_impurity_decrease=1e-05, min_samples_leaf=6...  0.545251   \n",
       "              min_impurity_decrease=2e-05, min_samples_leaf=3...  0.539665   \n",
       "              min_impurity_decrease=2e-05, n_estimators=20        0.536313   \n",
       "              min_impurity_decrease=3e-05, min_samples_leaf=1...  0.540223   \n",
       "              min_impurity_decrease=3e-05, min_samples_leaf=3...  0.548603   \n",
       "              min_impurity_decrease=5e-06, min_samples_leaf=3...  0.529609   \n",
       "              min_impurity_decrease=5e-06, min_samples_leaf=6...  0.558659   \n",
       "log reg 10.0  penalty='none'                                      0.294972   \n",
       "\n",
       "                                                                            \n",
       "                                                                       std  \n",
       "Model   NVARS Parameters                                                    \n",
       "DT      10.0  min_impurity_decrease=1e-05                         0.087442  \n",
       "              min_impurity_decrease=2.5e-05                       0.075965  \n",
       "              min_impurity_decrease=2e-05                         0.071193  \n",
       "              min_impurity_decrease=3.5e-05                       0.071079  \n",
       "              min_impurity_decrease=3e-05                         0.087456  \n",
       "              min_impurity_decrease=5e-05                         0.068765  \n",
       "LGBM    10.0  min_child_samples=1000, min_split_gain=1            0.009854  \n",
       "              min_child_samples=1000, min_split_gain=5            0.015680  \n",
       "              min_child_samples=500, min_split_gain=1             0.039696  \n",
       "              min_child_samples=500, min_split_gain=1, n_esti...  0.010534  \n",
       "              min_child_samples=500, min_split_gain=1, n_esti...  0.031055  \n",
       "              min_child_samples=500, min_split_gain=1, n_esti...  0.036874  \n",
       "              min_child_samples=500, min_split_gain=1, n_esti...  0.038745  \n",
       "              min_child_samples=500, min_split_gain=5             0.023266  \n",
       "              min_split_gain=10                                   0.022540  \n",
       "              min_split_gain=20                                   0.068038  \n",
       "              min_split_gain=50                                   0.060331  \n",
       "NN      10.0  alpha=0.01, hidden_layer_sizes=(10, 10)             0.038812  \n",
       "              alpha=0.01, hidden_layer_sizes=(15, 15), learni...  0.008734  \n",
       "              hidden_layer_sizes=(10, 10)                         0.026445  \n",
       "              hidden_layer_sizes=(15, 15)                         0.033255  \n",
       "              hidden_layer_sizes=(20, 20)                         0.056083  \n",
       "RF      10.0  min_impurity_decrease=1e-05, min_samples_leaf=3...  0.017479  \n",
       "              min_impurity_decrease=1e-05, min_samples_leaf=6...  0.022222  \n",
       "              min_impurity_decrease=2e-05, min_samples_leaf=3...  0.017706  \n",
       "              min_impurity_decrease=2e-05, n_estimators=20        0.019708  \n",
       "              min_impurity_decrease=3e-05, min_samples_leaf=1...  0.013948  \n",
       "              min_impurity_decrease=3e-05, min_samples_leaf=3...  0.022928  \n",
       "              min_impurity_decrease=5e-06, min_samples_leaf=3...  0.025506  \n",
       "              min_impurity_decrease=5e-06, min_samples_leaf=6...  0.009854  \n",
       "log reg 10.0  penalty='none'                                      0.041036  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x1080 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(20,15))\n",
    "ax = sns.boxplot(x='Model',y='Value',hue='Type', data=df_compare, palette=['navy','r','g'])\n",
    "\n",
    "# plt.ylim(.4,.6)\n",
    "plt.ylabel('Score (FDR3%)')\n",
    "plt.grid(axis='y')\n",
    "plt.savefig('modeling.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "duration:  0:01:14.413006\n"
     ]
    }
   ],
   "source": [
    "print('duration: ', datetime.now() - start_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final model of choice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The rest of the notebook makes the tables for your final model of choice. You need to run that final model only once (no CV). If you want you can run the below cell over and over by itself until it gives you a model you like (due to the stochastic nature of some ML algorithms, but you can't change from your best hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.5261406844106464 0.529657477025898 0.5029337803855826\n",
      "1 0.5281856939838939 0.5248386191411731 0.5075440067057837\n",
      "2 0.5263659088203785 0.5302273987798114 0.5029337803855826\n",
      "3 0.5272619047619047 0.5284169670085944 0.5050293378038558\n",
      "4 0.5244349781090996 0.5306524184476941 0.5046102263202011\n",
      "5 0.5325606404588362 0.5167674546454095 0.5075440067057837\n",
      "6 0.5271327014218009 0.5273338940285954 0.5041911148365466\n",
      "7 0.528561270443233 0.5245166713365088 0.5088013411567477\n",
      "8 0.529138915318744 0.522645179216449 0.5029337803855826\n",
      "9 0.5311218335343788 0.519774011299435 0.5075440067057837\n",
      "10 0.5251038575667656 0.5318257956448911 0.5050293378038558\n",
      "11 0.5321888412017167 0.5169936446532192 0.5054484492875104\n",
      "12 0.5238262498536471 0.5377957299480669 0.5046102263202011\n",
      "13 0.5310868533459896 0.5183012014529198 0.5046102263202011\n",
      "14 0.522874251497006 0.5378725731473886 0.5062866722548198\n",
      "15 0.531945270672219 0.5172126596335369 0.5037720033528919\n",
      "16 0.5279770444763271 0.5264891572879495 0.5079631181894384\n",
      "17 0.5264032277204225 0.5290502793296089 0.5058675607711651\n",
      "18 0.5276131784783124 0.5264780050434296 0.5071248952221291\n",
      "19 0.5267878497966993 0.5289437585733882 0.5079631181894384\n",
      "20 0.5256926355671324 0.5310306093793878 0.5067057837384744\n",
      "21 0.5274803711634547 0.5273535129130797 0.5046102263202011\n",
      "22 0.5293282876064334 0.5215432272599267 0.5054484492875104\n",
      "23 0.5273311897106109 0.5282548476454294 0.5046102263202011\n",
      "24 0.5305637982195845 0.5189838079285315 0.5062866722548198\n",
      "25 0.5262271414821944 0.5299052774018944 0.5067057837384744\n",
      "26 0.5262778977681786 0.5298121426626735 0.5050293378038558\n",
      "27 0.5243204577968527 0.5332964907432992 0.5033528918692373\n",
      "28 0.5266666666666666 0.5281397283060715 0.5016764459346186\n",
      "29 0.5273076461409194 0.5277475516866159 0.5079631181894384\n",
      "trn    0.527597\n",
      "tst    0.526729\n",
      "oot    0.505504\n",
      "dtype: float64\n",
      "CPU times: total: 12min 40s\n",
      "Wall time: 51.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# LGBM\n",
    "result_final_model = model_execution(model_name = 'Final_LGBM',\n",
    "                                algorithm = lgb.LGBMClassifier(max_depth=5, n_estimators=200, num_leaves=4),\n",
    "                                X = X_trntst, Y = Y_trntst,\n",
    "                                X_oot = X_oot_orig, Y_oot = Y_oot,\n",
    "                                nitermax = 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_execution(model_name = 'Final',\n",
    "#                 algorithm = CatBoostClassifier(verbose=0, iterations=100), # here's where you put your final model of choice\n",
    "#                 X = X_trntst, Y = Y_trntst,\n",
    "#                 X_oot = X_oot_orig, Y_oot = Y_oot,\n",
    "#                 nitermax = 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fulladdress_day_since</th>\n",
       "      <th>name_dob_count_30</th>\n",
       "      <th>address_unique_count_for_name_homephone_60</th>\n",
       "      <th>fulladdress_unique_count_for_dob_homephone_3</th>\n",
       "      <th>address_unique_count_for_homephone_name_dob_30</th>\n",
       "      <th>address_unique_count_for_ssn_name_dob_14</th>\n",
       "      <th>address_day_since</th>\n",
       "      <th>address_count_14</th>\n",
       "      <th>address_count_7</th>\n",
       "      <th>address_count_0_by_30</th>\n",
       "      <th>predicted</th>\n",
       "      <th>Fraud</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>40287</th>\n",
       "      <td>0.403033</td>\n",
       "      <td>-0.132081</td>\n",
       "      <td>-0.113357</td>\n",
       "      <td>-0.06276</td>\n",
       "      <td>-0.101011</td>\n",
       "      <td>-0.084722</td>\n",
       "      <td>0.428121</td>\n",
       "      <td>-0.113383</td>\n",
       "      <td>-0.092352</td>\n",
       "      <td>0.200213</td>\n",
       "      <td>0.007183</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>699756</th>\n",
       "      <td>0.403033</td>\n",
       "      <td>-0.132081</td>\n",
       "      <td>-0.113357</td>\n",
       "      <td>-0.06276</td>\n",
       "      <td>-0.101011</td>\n",
       "      <td>-0.084722</td>\n",
       "      <td>0.428121</td>\n",
       "      <td>-0.113383</td>\n",
       "      <td>-0.092352</td>\n",
       "      <td>0.200213</td>\n",
       "      <td>0.007183</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>371640</th>\n",
       "      <td>0.403033</td>\n",
       "      <td>-0.132081</td>\n",
       "      <td>-0.113357</td>\n",
       "      <td>-0.06276</td>\n",
       "      <td>-0.101011</td>\n",
       "      <td>-0.084722</td>\n",
       "      <td>0.428121</td>\n",
       "      <td>-0.113383</td>\n",
       "      <td>-0.092352</td>\n",
       "      <td>0.200213</td>\n",
       "      <td>0.007183</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>647858</th>\n",
       "      <td>0.403033</td>\n",
       "      <td>-0.132081</td>\n",
       "      <td>-0.113357</td>\n",
       "      <td>-0.06276</td>\n",
       "      <td>-0.101011</td>\n",
       "      <td>-0.084722</td>\n",
       "      <td>0.428121</td>\n",
       "      <td>-0.113383</td>\n",
       "      <td>-0.092352</td>\n",
       "      <td>0.200213</td>\n",
       "      <td>0.007183</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129081</th>\n",
       "      <td>0.403033</td>\n",
       "      <td>-0.132081</td>\n",
       "      <td>-0.113357</td>\n",
       "      <td>-0.06276</td>\n",
       "      <td>-0.101011</td>\n",
       "      <td>-0.084722</td>\n",
       "      <td>0.428121</td>\n",
       "      <td>-0.113383</td>\n",
       "      <td>-0.092352</td>\n",
       "      <td>0.200213</td>\n",
       "      <td>0.007183</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>719783</th>\n",
       "      <td>0.403033</td>\n",
       "      <td>-0.132081</td>\n",
       "      <td>-0.113357</td>\n",
       "      <td>-0.06276</td>\n",
       "      <td>-0.101011</td>\n",
       "      <td>-0.084722</td>\n",
       "      <td>0.428121</td>\n",
       "      <td>-0.113383</td>\n",
       "      <td>-0.092352</td>\n",
       "      <td>0.200213</td>\n",
       "      <td>0.007183</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>529902</th>\n",
       "      <td>0.403033</td>\n",
       "      <td>-0.132081</td>\n",
       "      <td>-0.113357</td>\n",
       "      <td>-0.06276</td>\n",
       "      <td>-0.101011</td>\n",
       "      <td>-0.084722</td>\n",
       "      <td>0.428121</td>\n",
       "      <td>-0.113383</td>\n",
       "      <td>-0.092352</td>\n",
       "      <td>0.200213</td>\n",
       "      <td>0.007183</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>510490</th>\n",
       "      <td>0.403033</td>\n",
       "      <td>-0.132081</td>\n",
       "      <td>-0.113357</td>\n",
       "      <td>-0.06276</td>\n",
       "      <td>-0.101011</td>\n",
       "      <td>-0.084722</td>\n",
       "      <td>0.428121</td>\n",
       "      <td>-0.113383</td>\n",
       "      <td>-0.092352</td>\n",
       "      <td>0.200213</td>\n",
       "      <td>0.007183</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>739170</th>\n",
       "      <td>0.403033</td>\n",
       "      <td>-0.132081</td>\n",
       "      <td>-0.113357</td>\n",
       "      <td>-0.06276</td>\n",
       "      <td>-0.101011</td>\n",
       "      <td>-0.084722</td>\n",
       "      <td>0.428121</td>\n",
       "      <td>-0.113383</td>\n",
       "      <td>-0.092352</td>\n",
       "      <td>0.200213</td>\n",
       "      <td>0.007183</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22507</th>\n",
       "      <td>0.403033</td>\n",
       "      <td>-0.132081</td>\n",
       "      <td>-0.113357</td>\n",
       "      <td>-0.06276</td>\n",
       "      <td>-0.101011</td>\n",
       "      <td>-0.084722</td>\n",
       "      <td>0.428121</td>\n",
       "      <td>-0.113383</td>\n",
       "      <td>-0.092352</td>\n",
       "      <td>0.200213</td>\n",
       "      <td>0.007183</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>583454 rows Ã— 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        fulladdress_day_since  name_dob_count_30  \\\n",
       "40287                0.403033          -0.132081   \n",
       "699756               0.403033          -0.132081   \n",
       "371640               0.403033          -0.132081   \n",
       "647858               0.403033          -0.132081   \n",
       "129081               0.403033          -0.132081   \n",
       "...                       ...                ...   \n",
       "719783               0.403033          -0.132081   \n",
       "529902               0.403033          -0.132081   \n",
       "510490               0.403033          -0.132081   \n",
       "739170               0.403033          -0.132081   \n",
       "22507                0.403033          -0.132081   \n",
       "\n",
       "        address_unique_count_for_name_homephone_60  \\\n",
       "40287                                    -0.113357   \n",
       "699756                                   -0.113357   \n",
       "371640                                   -0.113357   \n",
       "647858                                   -0.113357   \n",
       "129081                                   -0.113357   \n",
       "...                                            ...   \n",
       "719783                                   -0.113357   \n",
       "529902                                   -0.113357   \n",
       "510490                                   -0.113357   \n",
       "739170                                   -0.113357   \n",
       "22507                                    -0.113357   \n",
       "\n",
       "        fulladdress_unique_count_for_dob_homephone_3  \\\n",
       "40287                                       -0.06276   \n",
       "699756                                      -0.06276   \n",
       "371640                                      -0.06276   \n",
       "647858                                      -0.06276   \n",
       "129081                                      -0.06276   \n",
       "...                                              ...   \n",
       "719783                                      -0.06276   \n",
       "529902                                      -0.06276   \n",
       "510490                                      -0.06276   \n",
       "739170                                      -0.06276   \n",
       "22507                                       -0.06276   \n",
       "\n",
       "        address_unique_count_for_homephone_name_dob_30  \\\n",
       "40287                                        -0.101011   \n",
       "699756                                       -0.101011   \n",
       "371640                                       -0.101011   \n",
       "647858                                       -0.101011   \n",
       "129081                                       -0.101011   \n",
       "...                                                ...   \n",
       "719783                                       -0.101011   \n",
       "529902                                       -0.101011   \n",
       "510490                                       -0.101011   \n",
       "739170                                       -0.101011   \n",
       "22507                                        -0.101011   \n",
       "\n",
       "        address_unique_count_for_ssn_name_dob_14  address_day_since  \\\n",
       "40287                                  -0.084722           0.428121   \n",
       "699756                                 -0.084722           0.428121   \n",
       "371640                                 -0.084722           0.428121   \n",
       "647858                                 -0.084722           0.428121   \n",
       "129081                                 -0.084722           0.428121   \n",
       "...                                          ...                ...   \n",
       "719783                                 -0.084722           0.428121   \n",
       "529902                                 -0.084722           0.428121   \n",
       "510490                                 -0.084722           0.428121   \n",
       "739170                                 -0.084722           0.428121   \n",
       "22507                                  -0.084722           0.428121   \n",
       "\n",
       "        address_count_14  address_count_7  address_count_0_by_30  predicted  \\\n",
       "40287          -0.113383        -0.092352               0.200213   0.007183   \n",
       "699756         -0.113383        -0.092352               0.200213   0.007183   \n",
       "371640         -0.113383        -0.092352               0.200213   0.007183   \n",
       "647858         -0.113383        -0.092352               0.200213   0.007183   \n",
       "129081         -0.113383        -0.092352               0.200213   0.007183   \n",
       "...                  ...              ...                    ...        ...   \n",
       "719783         -0.113383        -0.092352               0.200213   0.007183   \n",
       "529902         -0.113383        -0.092352               0.200213   0.007183   \n",
       "510490         -0.113383        -0.092352               0.200213   0.007183   \n",
       "739170         -0.113383        -0.092352               0.200213   0.007183   \n",
       "22507          -0.113383        -0.092352               0.200213   0.007183   \n",
       "\n",
       "        Fraud  \n",
       "40287     0.0  \n",
       "699756    0.0  \n",
       "371640    0.0  \n",
       "647858    0.0  \n",
       "129081    0.0  \n",
       "...       ...  \n",
       "719783    0.0  \n",
       "529902    0.0  \n",
       "510490    0.0  \n",
       "739170    0.0  \n",
       "22507     0.0  \n",
       "\n",
       "[583454 rows x 12 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_final_model[1]['X_trn']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_trn_eval = result_final_model[1]['X_trn'].copy()\n",
    "X_tst_eval = result_final_model[1]['X_tst'].copy()\n",
    "X_oot_eval = result_final_model[1]['X_oot'].copy()\n",
    "FDR3 = result_final_model[1]['FDR3'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fulladdress_day_since</th>\n",
       "      <th>name_dob_count_30</th>\n",
       "      <th>address_unique_count_for_name_homephone_60</th>\n",
       "      <th>fulladdress_unique_count_for_dob_homephone_3</th>\n",
       "      <th>address_unique_count_for_homephone_name_dob_30</th>\n",
       "      <th>address_unique_count_for_ssn_name_dob_14</th>\n",
       "      <th>address_day_since</th>\n",
       "      <th>address_count_14</th>\n",
       "      <th>address_count_7</th>\n",
       "      <th>address_count_0_by_30</th>\n",
       "      <th>predicted</th>\n",
       "      <th>Fraud</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>865961</th>\n",
       "      <td>-3.280209</td>\n",
       "      <td>-0.132081</td>\n",
       "      <td>14.584262</td>\n",
       "      <td>19.167299</td>\n",
       "      <td>15.749194</td>\n",
       "      <td>16.848748</td>\n",
       "      <td>-3.053486</td>\n",
       "      <td>16.160620</td>\n",
       "      <td>17.222145</td>\n",
       "      <td>0.200213</td>\n",
       "      <td>0.999924</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>835976</th>\n",
       "      <td>-3.280209</td>\n",
       "      <td>-0.132081</td>\n",
       "      <td>14.584262</td>\n",
       "      <td>19.167299</td>\n",
       "      <td>15.749194</td>\n",
       "      <td>16.848748</td>\n",
       "      <td>-3.053486</td>\n",
       "      <td>16.160620</td>\n",
       "      <td>17.222145</td>\n",
       "      <td>0.200213</td>\n",
       "      <td>0.999924</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>865765</th>\n",
       "      <td>-3.280209</td>\n",
       "      <td>-0.132081</td>\n",
       "      <td>14.584262</td>\n",
       "      <td>19.167299</td>\n",
       "      <td>15.749194</td>\n",
       "      <td>16.848748</td>\n",
       "      <td>-3.053486</td>\n",
       "      <td>16.160620</td>\n",
       "      <td>17.222145</td>\n",
       "      <td>0.200213</td>\n",
       "      <td>0.999924</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>884885</th>\n",
       "      <td>-3.280209</td>\n",
       "      <td>-0.132081</td>\n",
       "      <td>14.584262</td>\n",
       "      <td>19.167299</td>\n",
       "      <td>15.749194</td>\n",
       "      <td>16.848748</td>\n",
       "      <td>-3.053486</td>\n",
       "      <td>16.160620</td>\n",
       "      <td>17.222145</td>\n",
       "      <td>0.200213</td>\n",
       "      <td>0.999924</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>884916</th>\n",
       "      <td>-3.280209</td>\n",
       "      <td>-0.132081</td>\n",
       "      <td>14.584262</td>\n",
       "      <td>19.167299</td>\n",
       "      <td>15.749194</td>\n",
       "      <td>16.848748</td>\n",
       "      <td>-3.053486</td>\n",
       "      <td>16.160620</td>\n",
       "      <td>17.222145</td>\n",
       "      <td>0.200213</td>\n",
       "      <td>0.999924</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>884645</th>\n",
       "      <td>-3.280209</td>\n",
       "      <td>-0.132081</td>\n",
       "      <td>14.584262</td>\n",
       "      <td>19.167299</td>\n",
       "      <td>15.749194</td>\n",
       "      <td>16.848748</td>\n",
       "      <td>-3.053486</td>\n",
       "      <td>16.160620</td>\n",
       "      <td>17.222145</td>\n",
       "      <td>0.200213</td>\n",
       "      <td>0.999924</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>937013</th>\n",
       "      <td>-3.280209</td>\n",
       "      <td>-0.132081</td>\n",
       "      <td>14.584262</td>\n",
       "      <td>19.167299</td>\n",
       "      <td>15.749194</td>\n",
       "      <td>16.848748</td>\n",
       "      <td>-3.053486</td>\n",
       "      <td>16.160620</td>\n",
       "      <td>17.222145</td>\n",
       "      <td>0.200213</td>\n",
       "      <td>0.999924</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>865902</th>\n",
       "      <td>-3.280209</td>\n",
       "      <td>-0.132081</td>\n",
       "      <td>14.584262</td>\n",
       "      <td>19.167299</td>\n",
       "      <td>15.749194</td>\n",
       "      <td>16.848748</td>\n",
       "      <td>-3.053486</td>\n",
       "      <td>16.160620</td>\n",
       "      <td>17.222145</td>\n",
       "      <td>0.200213</td>\n",
       "      <td>0.999924</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>915077</th>\n",
       "      <td>-3.280209</td>\n",
       "      <td>-0.132081</td>\n",
       "      <td>14.584262</td>\n",
       "      <td>19.167299</td>\n",
       "      <td>15.749194</td>\n",
       "      <td>16.848748</td>\n",
       "      <td>-3.053486</td>\n",
       "      <td>16.160620</td>\n",
       "      <td>17.222145</td>\n",
       "      <td>0.200213</td>\n",
       "      <td>0.999924</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>957048</th>\n",
       "      <td>-3.270118</td>\n",
       "      <td>17.476308</td>\n",
       "      <td>14.584262</td>\n",
       "      <td>19.167299</td>\n",
       "      <td>15.749194</td>\n",
       "      <td>16.848748</td>\n",
       "      <td>-3.043947</td>\n",
       "      <td>16.160620</td>\n",
       "      <td>17.222145</td>\n",
       "      <td>-8.379301</td>\n",
       "      <td>0.999819</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>835909</th>\n",
       "      <td>-3.280209</td>\n",
       "      <td>3.377843</td>\n",
       "      <td>14.584262</td>\n",
       "      <td>19.167299</td>\n",
       "      <td>15.749194</td>\n",
       "      <td>16.848748</td>\n",
       "      <td>-3.053486</td>\n",
       "      <td>16.160620</td>\n",
       "      <td>17.222145</td>\n",
       "      <td>-1.671681</td>\n",
       "      <td>0.999806</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>880299</th>\n",
       "      <td>-3.209572</td>\n",
       "      <td>17.476308</td>\n",
       "      <td>-0.113357</td>\n",
       "      <td>-0.062760</td>\n",
       "      <td>-0.101011</td>\n",
       "      <td>-0.084722</td>\n",
       "      <td>-2.986715</td>\n",
       "      <td>12.935918</td>\n",
       "      <td>2.842077</td>\n",
       "      <td>-8.119316</td>\n",
       "      <td>0.999792</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>862046</th>\n",
       "      <td>-3.229754</td>\n",
       "      <td>17.476308</td>\n",
       "      <td>-0.113357</td>\n",
       "      <td>-0.062760</td>\n",
       "      <td>-0.101011</td>\n",
       "      <td>-0.084722</td>\n",
       "      <td>-3.005792</td>\n",
       "      <td>12.935918</td>\n",
       "      <td>11.645364</td>\n",
       "      <td>-8.119316</td>\n",
       "      <td>0.999722</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>943613</th>\n",
       "      <td>-3.229754</td>\n",
       "      <td>17.476308</td>\n",
       "      <td>-0.113357</td>\n",
       "      <td>-0.062760</td>\n",
       "      <td>-0.101011</td>\n",
       "      <td>-0.084722</td>\n",
       "      <td>-3.005792</td>\n",
       "      <td>7.716198</td>\n",
       "      <td>2.842077</td>\n",
       "      <td>-8.119316</td>\n",
       "      <td>0.999696</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>909416</th>\n",
       "      <td>-3.199481</td>\n",
       "      <td>17.476308</td>\n",
       "      <td>-0.113357</td>\n",
       "      <td>-0.062760</td>\n",
       "      <td>-0.101011</td>\n",
       "      <td>-0.084722</td>\n",
       "      <td>-2.977176</td>\n",
       "      <td>7.716198</td>\n",
       "      <td>-0.092352</td>\n",
       "      <td>-8.119316</td>\n",
       "      <td>0.999696</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>984814</th>\n",
       "      <td>-3.280209</td>\n",
       "      <td>-0.132081</td>\n",
       "      <td>14.584262</td>\n",
       "      <td>19.167299</td>\n",
       "      <td>15.749194</td>\n",
       "      <td>16.848748</td>\n",
       "      <td>-3.053486</td>\n",
       "      <td>16.160620</td>\n",
       "      <td>17.222145</td>\n",
       "      <td>-1.671681</td>\n",
       "      <td>0.999626</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>881950</th>\n",
       "      <td>-3.280209</td>\n",
       "      <td>-0.132081</td>\n",
       "      <td>14.584262</td>\n",
       "      <td>19.167299</td>\n",
       "      <td>15.749194</td>\n",
       "      <td>16.848748</td>\n",
       "      <td>-3.053486</td>\n",
       "      <td>16.160620</td>\n",
       "      <td>17.222145</td>\n",
       "      <td>-1.501508</td>\n",
       "      <td>0.999626</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>854173</th>\n",
       "      <td>-3.280209</td>\n",
       "      <td>-0.132081</td>\n",
       "      <td>14.584262</td>\n",
       "      <td>19.167299</td>\n",
       "      <td>15.749194</td>\n",
       "      <td>16.848748</td>\n",
       "      <td>-3.053486</td>\n",
       "      <td>16.160620</td>\n",
       "      <td>17.222145</td>\n",
       "      <td>-0.579742</td>\n",
       "      <td>0.999626</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>881968</th>\n",
       "      <td>-3.280209</td>\n",
       "      <td>-0.132081</td>\n",
       "      <td>14.584262</td>\n",
       "      <td>19.167299</td>\n",
       "      <td>15.749194</td>\n",
       "      <td>16.848748</td>\n",
       "      <td>-3.053486</td>\n",
       "      <td>16.160620</td>\n",
       "      <td>17.222145</td>\n",
       "      <td>-1.427521</td>\n",
       "      <td>0.999626</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>854763</th>\n",
       "      <td>-3.280209</td>\n",
       "      <td>-0.132081</td>\n",
       "      <td>14.584262</td>\n",
       "      <td>19.167299</td>\n",
       "      <td>15.749194</td>\n",
       "      <td>16.848748</td>\n",
       "      <td>-3.053486</td>\n",
       "      <td>16.160620</td>\n",
       "      <td>17.222145</td>\n",
       "      <td>-0.384753</td>\n",
       "      <td>0.999626</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        fulladdress_day_since  name_dob_count_30  \\\n",
       "865961              -3.280209          -0.132081   \n",
       "835976              -3.280209          -0.132081   \n",
       "865765              -3.280209          -0.132081   \n",
       "884885              -3.280209          -0.132081   \n",
       "884916              -3.280209          -0.132081   \n",
       "884645              -3.280209          -0.132081   \n",
       "937013              -3.280209          -0.132081   \n",
       "865902              -3.280209          -0.132081   \n",
       "915077              -3.280209          -0.132081   \n",
       "957048              -3.270118          17.476308   \n",
       "835909              -3.280209           3.377843   \n",
       "880299              -3.209572          17.476308   \n",
       "862046              -3.229754          17.476308   \n",
       "943613              -3.229754          17.476308   \n",
       "909416              -3.199481          17.476308   \n",
       "984814              -3.280209          -0.132081   \n",
       "881950              -3.280209          -0.132081   \n",
       "854173              -3.280209          -0.132081   \n",
       "881968              -3.280209          -0.132081   \n",
       "854763              -3.280209          -0.132081   \n",
       "\n",
       "        address_unique_count_for_name_homephone_60  \\\n",
       "865961                                   14.584262   \n",
       "835976                                   14.584262   \n",
       "865765                                   14.584262   \n",
       "884885                                   14.584262   \n",
       "884916                                   14.584262   \n",
       "884645                                   14.584262   \n",
       "937013                                   14.584262   \n",
       "865902                                   14.584262   \n",
       "915077                                   14.584262   \n",
       "957048                                   14.584262   \n",
       "835909                                   14.584262   \n",
       "880299                                   -0.113357   \n",
       "862046                                   -0.113357   \n",
       "943613                                   -0.113357   \n",
       "909416                                   -0.113357   \n",
       "984814                                   14.584262   \n",
       "881950                                   14.584262   \n",
       "854173                                   14.584262   \n",
       "881968                                   14.584262   \n",
       "854763                                   14.584262   \n",
       "\n",
       "        fulladdress_unique_count_for_dob_homephone_3  \\\n",
       "865961                                     19.167299   \n",
       "835976                                     19.167299   \n",
       "865765                                     19.167299   \n",
       "884885                                     19.167299   \n",
       "884916                                     19.167299   \n",
       "884645                                     19.167299   \n",
       "937013                                     19.167299   \n",
       "865902                                     19.167299   \n",
       "915077                                     19.167299   \n",
       "957048                                     19.167299   \n",
       "835909                                     19.167299   \n",
       "880299                                     -0.062760   \n",
       "862046                                     -0.062760   \n",
       "943613                                     -0.062760   \n",
       "909416                                     -0.062760   \n",
       "984814                                     19.167299   \n",
       "881950                                     19.167299   \n",
       "854173                                     19.167299   \n",
       "881968                                     19.167299   \n",
       "854763                                     19.167299   \n",
       "\n",
       "        address_unique_count_for_homephone_name_dob_30  \\\n",
       "865961                                       15.749194   \n",
       "835976                                       15.749194   \n",
       "865765                                       15.749194   \n",
       "884885                                       15.749194   \n",
       "884916                                       15.749194   \n",
       "884645                                       15.749194   \n",
       "937013                                       15.749194   \n",
       "865902                                       15.749194   \n",
       "915077                                       15.749194   \n",
       "957048                                       15.749194   \n",
       "835909                                       15.749194   \n",
       "880299                                       -0.101011   \n",
       "862046                                       -0.101011   \n",
       "943613                                       -0.101011   \n",
       "909416                                       -0.101011   \n",
       "984814                                       15.749194   \n",
       "881950                                       15.749194   \n",
       "854173                                       15.749194   \n",
       "881968                                       15.749194   \n",
       "854763                                       15.749194   \n",
       "\n",
       "        address_unique_count_for_ssn_name_dob_14  address_day_since  \\\n",
       "865961                                 16.848748          -3.053486   \n",
       "835976                                 16.848748          -3.053486   \n",
       "865765                                 16.848748          -3.053486   \n",
       "884885                                 16.848748          -3.053486   \n",
       "884916                                 16.848748          -3.053486   \n",
       "884645                                 16.848748          -3.053486   \n",
       "937013                                 16.848748          -3.053486   \n",
       "865902                                 16.848748          -3.053486   \n",
       "915077                                 16.848748          -3.053486   \n",
       "957048                                 16.848748          -3.043947   \n",
       "835909                                 16.848748          -3.053486   \n",
       "880299                                 -0.084722          -2.986715   \n",
       "862046                                 -0.084722          -3.005792   \n",
       "943613                                 -0.084722          -3.005792   \n",
       "909416                                 -0.084722          -2.977176   \n",
       "984814                                 16.848748          -3.053486   \n",
       "881950                                 16.848748          -3.053486   \n",
       "854173                                 16.848748          -3.053486   \n",
       "881968                                 16.848748          -3.053486   \n",
       "854763                                 16.848748          -3.053486   \n",
       "\n",
       "        address_count_14  address_count_7  address_count_0_by_30  predicted  \\\n",
       "865961         16.160620        17.222145               0.200213   0.999924   \n",
       "835976         16.160620        17.222145               0.200213   0.999924   \n",
       "865765         16.160620        17.222145               0.200213   0.999924   \n",
       "884885         16.160620        17.222145               0.200213   0.999924   \n",
       "884916         16.160620        17.222145               0.200213   0.999924   \n",
       "884645         16.160620        17.222145               0.200213   0.999924   \n",
       "937013         16.160620        17.222145               0.200213   0.999924   \n",
       "865902         16.160620        17.222145               0.200213   0.999924   \n",
       "915077         16.160620        17.222145               0.200213   0.999924   \n",
       "957048         16.160620        17.222145              -8.379301   0.999819   \n",
       "835909         16.160620        17.222145              -1.671681   0.999806   \n",
       "880299         12.935918         2.842077              -8.119316   0.999792   \n",
       "862046         12.935918        11.645364              -8.119316   0.999722   \n",
       "943613          7.716198         2.842077              -8.119316   0.999696   \n",
       "909416          7.716198        -0.092352              -8.119316   0.999696   \n",
       "984814         16.160620        17.222145              -1.671681   0.999626   \n",
       "881950         16.160620        17.222145              -1.501508   0.999626   \n",
       "854173         16.160620        17.222145              -0.579742   0.999626   \n",
       "881968         16.160620        17.222145              -1.427521   0.999626   \n",
       "854763         16.160620        17.222145              -0.384753   0.999626   \n",
       "\n",
       "        Fraud  \n",
       "865961    1.0  \n",
       "835976    1.0  \n",
       "865765    1.0  \n",
       "884885    1.0  \n",
       "884916    1.0  \n",
       "884645    1.0  \n",
       "937013    1.0  \n",
       "865902    1.0  \n",
       "915077    1.0  \n",
       "957048    0.0  \n",
       "835909    1.0  \n",
       "880299    1.0  \n",
       "862046    0.0  \n",
       "943613    1.0  \n",
       "909416    1.0  \n",
       "984814    1.0  \n",
       "881950    1.0  \n",
       "854173    1.0  \n",
       "881968    1.0  \n",
       "854763    1.0  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols = ['bin','#recs','#g','#b','%g','%b','tot','cg','cb','%cg','FDR','KS','FPR']\n",
    "\n",
    "FDR_trn = pd.DataFrame(np.zeros((101, 13)), columns = cols)\n",
    "FDR_tst = pd.DataFrame(np.zeros((101, 13)), columns = cols)\n",
    "FDR_oot = pd.DataFrame(np.zeros((101, 13)), columns = cols)\n",
    "\n",
    "trn_sorted = X_trn_eval.sort_values('predicted',ascending=False)\n",
    "tst_sorted = X_tst_eval.sort_values('predicted',ascending=False)\n",
    "oot_sorted = X_oot_eval.sort_values('predicted',ascending=False)\n",
    "\n",
    "oot_sorted.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FDR_eval(dataframe, X):\n",
    "    \n",
    "    bad_tot = sum(X.loc[:, 'Fraud'])\n",
    "    num_tot = len(X)\n",
    "    good_tot = num_tot - bad_tot\n",
    "    \n",
    "    X_sorted = X.sort_values('predicted',ascending=False)\n",
    "\n",
    "    for i in range(101):\n",
    "\n",
    "        percent_rows = int(round(X.shape[0]*0.01*i))\n",
    "        temp = X_sorted.head(percent_rows)\n",
    "        num_bad = sum(temp.loc[:,'Fraud'])\n",
    "        num_tot = len(temp)\n",
    "        num_good = num_tot - num_bad\n",
    "\n",
    "        dataframe.loc[i, 'bin'] = i\n",
    "        dataframe.loc[i,'#recs'] = 0\n",
    "        dataframe.loc[i, 'tot'] = num_tot\n",
    "        dataframe.loc[i, 'cg'] = num_good # cumulative good\n",
    "        dataframe.loc[i, 'cb'] = num_bad # cumulative bad\n",
    "\n",
    "        if i != 0:\n",
    "            dataframe.loc[i, '#g'] = num_good - dataframe.loc[i-1, 'cg'] # marginal good\n",
    "            dataframe.loc[i, '#b'] = num_bad - dataframe.loc[i-1, 'cb'] # marginal bad\n",
    "            dataframe.loc[i,'#recs'] = dataframe.loc[i, '#g'] + dataframe.loc[i, '#b']\n",
    "            \n",
    "            dataframe.loc[i, '%g'] = 100 * (dataframe.loc[i, '#g']) / (num_tot - dataframe.loc[i-1, 'tot'])\n",
    "            dataframe.loc[i, '%b'] = 100 - dataframe.loc[i, '%g']\n",
    "            \n",
    "            dataframe.loc[i, '%cg'] = 100 * num_good / good_tot\n",
    "            dataframe.loc[i, 'FDR'] = 100 * num_bad / bad_tot\n",
    "            dataframe.loc[i, 'KS'] = dataframe.loc[i, 'FDR'] - dataframe.loc[i, '%cg']\n",
    "            dataframe.loc[i, 'FPR'] = num_good / num_bad\n",
    "\n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "FDR_trn = FDR_eval(dataframe = FDR_trn, X = X_trn_eval)\n",
    "FDR_tst = FDR_eval(dataframe = FDR_tst, X = X_tst_eval)\n",
    "FDR_oot = FDR_eval(dataframe = FDR_oot, X = X_oot_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bin</th>\n",
       "      <th>#recs</th>\n",
       "      <th>#g</th>\n",
       "      <th>#b</th>\n",
       "      <th>%g</th>\n",
       "      <th>%b</th>\n",
       "      <th>tot</th>\n",
       "      <th>cg</th>\n",
       "      <th>cb</th>\n",
       "      <th>%cg</th>\n",
       "      <th>FDR</th>\n",
       "      <th>KS</th>\n",
       "      <th>FPR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1665.0</td>\n",
       "      <td>509.0</td>\n",
       "      <td>1156.0</td>\n",
       "      <td>30.570571</td>\n",
       "      <td>69.429429</td>\n",
       "      <td>1665.0</td>\n",
       "      <td>509.0</td>\n",
       "      <td>1156.0</td>\n",
       "      <td>0.310163</td>\n",
       "      <td>48.449288</td>\n",
       "      <td>48.139124</td>\n",
       "      <td>0.440311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1665.0</td>\n",
       "      <td>1641.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>98.558559</td>\n",
       "      <td>1.441441</td>\n",
       "      <td>3330.0</td>\n",
       "      <td>2150.0</td>\n",
       "      <td>1180.0</td>\n",
       "      <td>1.310121</td>\n",
       "      <td>49.455155</td>\n",
       "      <td>48.145034</td>\n",
       "      <td>1.822034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.0</td>\n",
       "      <td>1665.0</td>\n",
       "      <td>1633.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>98.078078</td>\n",
       "      <td>1.921922</td>\n",
       "      <td>4995.0</td>\n",
       "      <td>3783.0</td>\n",
       "      <td>1212.0</td>\n",
       "      <td>2.305203</td>\n",
       "      <td>50.796312</td>\n",
       "      <td>48.491109</td>\n",
       "      <td>3.121287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.0</td>\n",
       "      <td>1665.0</td>\n",
       "      <td>1650.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>99.099099</td>\n",
       "      <td>0.900901</td>\n",
       "      <td>6660.0</td>\n",
       "      <td>5433.0</td>\n",
       "      <td>1227.0</td>\n",
       "      <td>3.310645</td>\n",
       "      <td>51.424979</td>\n",
       "      <td>48.114334</td>\n",
       "      <td>4.427873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>96.0</td>\n",
       "      <td>1665.0</td>\n",
       "      <td>1651.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>99.159159</td>\n",
       "      <td>0.840841</td>\n",
       "      <td>159833.0</td>\n",
       "      <td>157487.0</td>\n",
       "      <td>2346.0</td>\n",
       "      <td>95.966047</td>\n",
       "      <td>98.323554</td>\n",
       "      <td>2.357508</td>\n",
       "      <td>67.130009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>97.0</td>\n",
       "      <td>1665.0</td>\n",
       "      <td>1658.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>99.579580</td>\n",
       "      <td>0.420420</td>\n",
       "      <td>161498.0</td>\n",
       "      <td>159145.0</td>\n",
       "      <td>2353.0</td>\n",
       "      <td>96.976363</td>\n",
       "      <td>98.616932</td>\n",
       "      <td>1.640569</td>\n",
       "      <td>67.634934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>98.0</td>\n",
       "      <td>1665.0</td>\n",
       "      <td>1654.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>99.339339</td>\n",
       "      <td>0.660661</td>\n",
       "      <td>163163.0</td>\n",
       "      <td>160799.0</td>\n",
       "      <td>2364.0</td>\n",
       "      <td>97.984242</td>\n",
       "      <td>99.077955</td>\n",
       "      <td>1.093713</td>\n",
       "      <td>68.019882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>99.0</td>\n",
       "      <td>1665.0</td>\n",
       "      <td>1655.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>99.399399</td>\n",
       "      <td>0.600601</td>\n",
       "      <td>164828.0</td>\n",
       "      <td>162454.0</td>\n",
       "      <td>2374.0</td>\n",
       "      <td>98.992730</td>\n",
       "      <td>99.497066</td>\n",
       "      <td>0.504336</td>\n",
       "      <td>68.430497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>100.0</td>\n",
       "      <td>1665.0</td>\n",
       "      <td>1653.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>99.279279</td>\n",
       "      <td>0.720721</td>\n",
       "      <td>166493.0</td>\n",
       "      <td>164107.0</td>\n",
       "      <td>2386.0</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>68.779128</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>101 rows Ã— 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       bin   #recs      #g      #b         %g         %b       tot        cg  \\\n",
       "0      0.0     0.0     0.0     0.0   0.000000   0.000000       0.0       0.0   \n",
       "1      1.0  1665.0   509.0  1156.0  30.570571  69.429429    1665.0     509.0   \n",
       "2      2.0  1665.0  1641.0    24.0  98.558559   1.441441    3330.0    2150.0   \n",
       "3      3.0  1665.0  1633.0    32.0  98.078078   1.921922    4995.0    3783.0   \n",
       "4      4.0  1665.0  1650.0    15.0  99.099099   0.900901    6660.0    5433.0   \n",
       "..     ...     ...     ...     ...        ...        ...       ...       ...   \n",
       "96    96.0  1665.0  1651.0    14.0  99.159159   0.840841  159833.0  157487.0   \n",
       "97    97.0  1665.0  1658.0     7.0  99.579580   0.420420  161498.0  159145.0   \n",
       "98    98.0  1665.0  1654.0    11.0  99.339339   0.660661  163163.0  160799.0   \n",
       "99    99.0  1665.0  1655.0    10.0  99.399399   0.600601  164828.0  162454.0   \n",
       "100  100.0  1665.0  1653.0    12.0  99.279279   0.720721  166493.0  164107.0   \n",
       "\n",
       "         cb         %cg         FDR         KS        FPR  \n",
       "0       0.0    0.000000    0.000000   0.000000   0.000000  \n",
       "1    1156.0    0.310163   48.449288  48.139124   0.440311  \n",
       "2    1180.0    1.310121   49.455155  48.145034   1.822034  \n",
       "3    1212.0    2.305203   50.796312  48.491109   3.121287  \n",
       "4    1227.0    3.310645   51.424979  48.114334   4.427873  \n",
       "..      ...         ...         ...        ...        ...  \n",
       "96   2346.0   95.966047   98.323554   2.357508  67.130009  \n",
       "97   2353.0   96.976363   98.616932   1.640569  67.634934  \n",
       "98   2364.0   97.984242   99.077955   1.093713  68.019882  \n",
       "99   2374.0   98.992730   99.497066   0.504336  68.430497  \n",
       "100  2386.0  100.000000  100.000000   0.000000  68.779128  \n",
       "\n",
       "[101 rows x 13 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FDR_oot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "FDR3.to_csv('FDR3.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "FDR_trn.to_csv('FDR_trn.csv', index=False)\n",
    "FDR_tst.to_csv('FDR_tst.csv', index=False)\n",
    "FDR_oot.to_csv('FDR_oot.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "duration:  0:03:00.001687\n"
     ]
    }
   ],
   "source": [
    "print(\"duration: \", datetime.now() - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "320px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
